{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sertifikat</th>\n",
       "      <th>tahun_dibangun</th>\n",
       "      <th>garasi</th>\n",
       "      <th>pemandangan</th>\n",
       "      <th>hadap</th>\n",
       "      <th>sumber_air</th>\n",
       "      <th>tahun_di_renovasi</th>\n",
       "      <th>konsep_dan_gaya_rumah</th>\n",
       "      <th>lebar_jalan</th>\n",
       "      <th>...</th>\n",
       "      <th>facility_masjid</th>\n",
       "      <th>facility_mezzanine</th>\n",
       "      <th>facility_musholla</th>\n",
       "      <th>facility_one_gate_system</th>\n",
       "      <th>facility_parkir</th>\n",
       "      <th>facility_playground</th>\n",
       "      <th>facility_shed</th>\n",
       "      <th>facility_taman</th>\n",
       "      <th>facility_wastafel</th>\n",
       "      <th>facility_water_tank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3300.0</td>\n",
       "      <td>SHM - Sertifikat Hak Milik</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pemukiman Warga</td>\n",
       "      <td>Timur</td>\n",
       "      <td>PAM atau PDAM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Minimalis Modern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>850.0</td>\n",
       "      <td>SHM - Sertifikat Hak Milik</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pegunungan</td>\n",
       "      <td>Timur</td>\n",
       "      <td>PAM atau PDAM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Minimalis Modern</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>SHM - Sertifikat Hak Milik</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pemukiman Warga</td>\n",
       "      <td>Timur</td>\n",
       "      <td>PAM atau PDAM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Minimalis Modern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>SHM - Sertifikat Hak Milik</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Pemukiman Warga</td>\n",
       "      <td>Timur</td>\n",
       "      <td>PAM atau PDAM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Minimalis Modern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>Lainnya (PPJB,Girik,Adat,dll)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pemukiman Warga</td>\n",
       "      <td>Timur</td>\n",
       "      <td>PAM atau PDAM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Minimalis Modern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    price                     sertifikat  tahun_dibangun  garasi  \\\n",
       "0  3300.0     SHM - Sertifikat Hak Milik          1000.0     0.0   \n",
       "1   850.0     SHM - Sertifikat Hak Milik          2016.0     4.0   \n",
       "2  1000.0     SHM - Sertifikat Hak Milik          2020.0     1.0   \n",
       "3  2500.0     SHM - Sertifikat Hak Milik          2013.0     3.0   \n",
       "4  3000.0  Lainnya (PPJB,Girik,Adat,dll)             0.0     0.0   \n",
       "\n",
       "       pemandangan  hadap     sumber_air  tahun_di_renovasi  \\\n",
       "0  Pemukiman Warga  Timur  PAM atau PDAM                0.0   \n",
       "1       Pegunungan  Timur  PAM atau PDAM                0.0   \n",
       "2  Pemukiman Warga  Timur  PAM atau PDAM                0.0   \n",
       "3  Pemukiman Warga  Timur  PAM atau PDAM                0.0   \n",
       "4  Pemukiman Warga  Timur  PAM atau PDAM                0.0   \n",
       "\n",
       "  konsep_dan_gaya_rumah  lebar_jalan  ... facility_masjid facility_mezzanine  \\\n",
       "0      Minimalis Modern          0.0  ...             0.0                0.0   \n",
       "1      Minimalis Modern          2.0  ...             1.0                0.0   \n",
       "2      Minimalis Modern          0.0  ...             0.0                0.0   \n",
       "3      Minimalis Modern          0.0  ...             0.0                0.0   \n",
       "4      Minimalis Modern          0.0  ...             0.0                0.0   \n",
       "\n",
       "   facility_musholla  facility_one_gate_system  facility_parkir  \\\n",
       "0                0.0                       0.0              0.0   \n",
       "1                0.0                       1.0              1.0   \n",
       "2                0.0                       0.0              0.0   \n",
       "3                0.0                       0.0              0.0   \n",
       "4                0.0                       0.0              0.0   \n",
       "\n",
       "   facility_playground  facility_shed  facility_taman  facility_wastafel  \\\n",
       "0                  0.0            0.0             0.0                0.0   \n",
       "1                  1.0            0.0             1.0                0.0   \n",
       "2                  0.0            0.0             0.0                0.0   \n",
       "3                  0.0            0.0             1.0                0.0   \n",
       "4                  0.0            0.0             0.0                0.0   \n",
       "\n",
       "   facility_water_tank  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../dataset/etl/L3.regression_train.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'sertifikat', 'tahun_dibangun', 'garasi', 'pemandangan',\n",
       "       'hadap', 'sumber_air', 'tahun_di_renovasi', 'konsep_dan_gaya_rumah',\n",
       "       'lebar_jalan', 'kondisi_properti', 'kondisi_perabotan', 'ruang_makan',\n",
       "       'ruang_tamu', 'terjangkau_internet', 'hook', 'tags_bisa_nego',\n",
       "       'tags_cash_bertahap', 'tags_cash_keras', 'tags_dijual_cepat',\n",
       "       'tags_komplek', 'tags_kpr', 'tags_masuk_gang', 'tags_one_gate_system',\n",
       "       'tags_pedesaan', 'tags_perumahan', 'tags_pinggir_jalan',\n",
       "       'house_mat_bata_hebel', 'house_mat_batako', 'house_mat_beton',\n",
       "       'floor_mat_granit', 'floor_mat_marmer', 'floor_mat_ubin',\n",
       "       'floor_mat_vinyl', 'facility_air_pam', 'facility_air_tanah',\n",
       "       'facility_aula', 'facility_balcony', 'facility_canopy',\n",
       "       'facility_carport', 'facility_dishwasher', 'facility_floorboards',\n",
       "       'facility_garasi', 'facility_gas', 'facility_gym', 'facility_halaman',\n",
       "       'facility_heating', 'facility_internet', 'facility_jalur_telepon',\n",
       "       'facility_keamanan', 'facility_kolam_ikan', 'facility_lapangan',\n",
       "       'facility_laundry', 'facility_lemari_pakaian', 'facility_lemari_sepatu',\n",
       "       'facility_masjid', 'facility_mezzanine', 'facility_musholla',\n",
       "       'facility_one_gate_system', 'facility_parkir', 'facility_playground',\n",
       "       'facility_shed', 'facility_taman', 'facility_wastafel',\n",
       "       'facility_water_tank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18240 entries, 0 to 20145\n",
      "Data columns (total 65 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   price                     18240 non-null  float64\n",
      " 1   sertifikat                18240 non-null  object \n",
      " 2   tahun_dibangun            18240 non-null  float64\n",
      " 3   garasi                    18240 non-null  float64\n",
      " 4   pemandangan               18240 non-null  object \n",
      " 5   hadap                     18240 non-null  object \n",
      " 6   sumber_air                18240 non-null  object \n",
      " 7   tahun_di_renovasi         18240 non-null  float64\n",
      " 8   konsep_dan_gaya_rumah     18240 non-null  object \n",
      " 9   lebar_jalan               18240 non-null  float64\n",
      " 10  kondisi_properti          18240 non-null  object \n",
      " 11  kondisi_perabotan         18240 non-null  object \n",
      " 12  ruang_makan               18240 non-null  float64\n",
      " 13  ruang_tamu                18240 non-null  float64\n",
      " 14  terjangkau_internet       18240 non-null  float64\n",
      " 15  hook                      18240 non-null  float64\n",
      " 16  tags_bisa_nego            18240 non-null  float64\n",
      " 17  tags_cash_bertahap        18240 non-null  float64\n",
      " 18  tags_cash_keras           18240 non-null  float64\n",
      " 19  tags_dijual_cepat         18240 non-null  float64\n",
      " 20  tags_komplek              18240 non-null  float64\n",
      " 21  tags_kpr                  18240 non-null  float64\n",
      " 22  tags_masuk_gang           18240 non-null  float64\n",
      " 23  tags_one_gate_system      18240 non-null  float64\n",
      " 24  tags_pedesaan             18240 non-null  float64\n",
      " 25  tags_perumahan            18240 non-null  float64\n",
      " 26  tags_pinggir_jalan        18240 non-null  float64\n",
      " 27  house_mat_bata_hebel      18240 non-null  float64\n",
      " 28  house_mat_batako          18240 non-null  float64\n",
      " 29  house_mat_beton           18240 non-null  float64\n",
      " 30  floor_mat_granit          18240 non-null  float64\n",
      " 31  floor_mat_marmer          18240 non-null  float64\n",
      " 32  floor_mat_ubin            18240 non-null  float64\n",
      " 33  floor_mat_vinyl           18240 non-null  float64\n",
      " 34  facility_air_pam          18240 non-null  float64\n",
      " 35  facility_air_tanah        18240 non-null  float64\n",
      " 36  facility_aula             18240 non-null  float64\n",
      " 37  facility_balcony          18240 non-null  float64\n",
      " 38  facility_canopy           18240 non-null  float64\n",
      " 39  facility_carport          18240 non-null  float64\n",
      " 40  facility_dishwasher       18240 non-null  float64\n",
      " 41  facility_floorboards      18240 non-null  float64\n",
      " 42  facility_garasi           18240 non-null  float64\n",
      " 43  facility_gas              18240 non-null  float64\n",
      " 44  facility_gym              18240 non-null  float64\n",
      " 45  facility_halaman          18240 non-null  float64\n",
      " 46  facility_heating          18240 non-null  float64\n",
      " 47  facility_internet         18240 non-null  float64\n",
      " 48  facility_jalur_telepon    18240 non-null  float64\n",
      " 49  facility_keamanan         18240 non-null  float64\n",
      " 50  facility_kolam_ikan       18240 non-null  float64\n",
      " 51  facility_lapangan         18240 non-null  float64\n",
      " 52  facility_laundry          18240 non-null  float64\n",
      " 53  facility_lemari_pakaian   18240 non-null  float64\n",
      " 54  facility_lemari_sepatu    18240 non-null  float64\n",
      " 55  facility_masjid           18240 non-null  float64\n",
      " 56  facility_mezzanine        18240 non-null  float64\n",
      " 57  facility_musholla         18240 non-null  float64\n",
      " 58  facility_one_gate_system  18240 non-null  float64\n",
      " 59  facility_parkir           18240 non-null  float64\n",
      " 60  facility_playground       18240 non-null  float64\n",
      " 61  facility_shed             18240 non-null  float64\n",
      " 62  facility_taman            18240 non-null  float64\n",
      " 63  facility_wastafel         18240 non-null  float64\n",
      " 64  facility_water_tank       18240 non-null  float64\n",
      "dtypes: float64(58), object(7)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_mat_cols = [col for col in df.columns if col.startswith(\"floor_mat_\")]\n",
    "house_mat_cols = [col for col in df.columns if col.startswith(\"house_mat_\")]\n",
    "tags_cols = [col for col in df.columns if col.startswith(\"tags_\")] + [\"hook_available\", \"ruang_tamu_available\", \"ruang_makan_available\", \"terjangkau_internet_available\"]\n",
    "\n",
    "cat_cols = [\"kondisi_perabotan_norm\", \"kondisi_properti_norm\", \"konsep_dan_gaya_rumah\", \"sumber_air\", \"pemandangan\", \"sertifikat\"]\n",
    "num_cols = [\"lebar_jalan_num\", \"daya_listrik_num\", \"luas_bangunan_num\", \"luas_tanah_num\", \"carport\", \"garasi\", \"dapur\", \"jumlah_lantai\", \"kamar_mandi_pembantu\", \"kamar_pembantu\", \"kamar_mandi\", \"kamar_tidur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_ex(model, X, y, category, name):\n",
    "    # create cross-validation param\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=21)\n",
    "\n",
    "    # define scoring\n",
    "    scoring = [\"r2\", \"neg_mean_squared_error\", \"neg_mean_absolute_error\", \"neg_mean_absolute_percentage_error\"]\n",
    "\n",
    "    # cross-validate\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=4, verbose=1)\n",
    "\n",
    "    # change into record-wise\n",
    "    score_records = []\n",
    "    for i in range(10):\n",
    "        score_records.append({\n",
    "            \"fit_time\": scores[\"fit_time\"][i],\n",
    "            \"score_time\": scores[\"score_time\"][i],\n",
    "            \"r2\": scores[\"test_r2\"][i],\n",
    "            \"mse\": -scores[\"test_neg_mean_squared_error\"][i],\n",
    "            \"mae\": -scores[\"test_neg_mean_absolute_error\"][i],\n",
    "            \"mape\": -scores[\"test_neg_mean_absolute_percentage_error\"][i],\n",
    "            \"category\": category,\n",
    "            \"name\": name\n",
    "        })\n",
    "    \n",
    "    return score_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;tags_bisa_nego&#x27;, &#x27;tags_cash_bertahap&#x27;,\n",
       "                                  &#x27;tags_cash_keras&#x27;, &#x27;tags_dijual_cepat&#x27;,\n",
       "                                  &#x27;tags_komplek&#x27;, &#x27;tags_kpr&#x27;, &#x27;tags_masuk_gang&#x27;,\n",
       "                                  &#x27;tags_one_gate_system&#x27;, &#x27;tags_pedesaan&#x27;,\n",
       "                                  &#x27;tags_perumahan&#x27;, &#x27;tags_pinggir_jalan&#x27;,\n",
       "                                  &#x27;hook_available&#x27;, &#x27;ruang_tamu_available&#x27;,\n",
       "                                  &#x27;ruang_makan_available&#x27;,\n",
       "                                  &#x27;terjangkau_internet_availa...\n",
       "                                 [&#x27;kondisi_perabotan_norm&#x27;,\n",
       "                                  &#x27;kondisi_properti_norm&#x27;,\n",
       "                                  &#x27;konsep_dan_gaya_rumah&#x27;, &#x27;sumber_air&#x27;,\n",
       "                                  &#x27;pemandangan&#x27;, &#x27;sertifikat&#x27;]),\n",
       "                                (&#x27;numerical_encoder&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 [&#x27;lebar_jalan_num&#x27;, &#x27;daya_listrik_num&#x27;,\n",
       "                                  &#x27;luas_bangunan_num&#x27;, &#x27;luas_tanah_num&#x27;,\n",
       "                                  &#x27;carport&#x27;, &#x27;garasi&#x27;, &#x27;dapur&#x27;, &#x27;jumlah_lantai&#x27;,\n",
       "                                  &#x27;kamar_mandi_pembantu&#x27;, &#x27;kamar_pembantu&#x27;,\n",
       "                                  &#x27;kamar_mandi&#x27;, &#x27;kamar_tidur&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;tags_bisa_nego&#x27;, &#x27;tags_cash_bertahap&#x27;,\n",
       "                                  &#x27;tags_cash_keras&#x27;, &#x27;tags_dijual_cepat&#x27;,\n",
       "                                  &#x27;tags_komplek&#x27;, &#x27;tags_kpr&#x27;, &#x27;tags_masuk_gang&#x27;,\n",
       "                                  &#x27;tags_one_gate_system&#x27;, &#x27;tags_pedesaan&#x27;,\n",
       "                                  &#x27;tags_perumahan&#x27;, &#x27;tags_pinggir_jalan&#x27;,\n",
       "                                  &#x27;hook_available&#x27;, &#x27;ruang_tamu_available&#x27;,\n",
       "                                  &#x27;ruang_makan_available&#x27;,\n",
       "                                  &#x27;terjangkau_internet_availa...\n",
       "                                 [&#x27;kondisi_perabotan_norm&#x27;,\n",
       "                                  &#x27;kondisi_properti_norm&#x27;,\n",
       "                                  &#x27;konsep_dan_gaya_rumah&#x27;, &#x27;sumber_air&#x27;,\n",
       "                                  &#x27;pemandangan&#x27;, &#x27;sertifikat&#x27;]),\n",
       "                                (&#x27;numerical_encoder&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 [&#x27;lebar_jalan_num&#x27;, &#x27;daya_listrik_num&#x27;,\n",
       "                                  &#x27;luas_bangunan_num&#x27;, &#x27;luas_tanah_num&#x27;,\n",
       "                                  &#x27;carport&#x27;, &#x27;garasi&#x27;, &#x27;dapur&#x27;, &#x27;jumlah_lantai&#x27;,\n",
       "                                  &#x27;kamar_mandi_pembantu&#x27;, &#x27;kamar_pembantu&#x27;,\n",
       "                                  &#x27;kamar_mandi&#x27;, &#x27;kamar_tidur&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tags_bisa_nego&#x27;, &#x27;tags_cash_bertahap&#x27;, &#x27;tags_cash_keras&#x27;, &#x27;tags_dijual_cepat&#x27;, &#x27;tags_komplek&#x27;, &#x27;tags_kpr&#x27;, &#x27;tags_masuk_gang&#x27;, &#x27;tags_one_gate_system&#x27;, &#x27;tags_pedesaan&#x27;, &#x27;tags_perumahan&#x27;, &#x27;tags_pinggir_jalan&#x27;, &#x27;hook_available&#x27;, &#x27;ruang_tamu_available&#x27;, &#x27;ruang_makan_available&#x27;, &#x27;terjangkau_internet_available&#x27;, &#x27;floor_mat_granit&#x27;, &#x27;floor_mat_keramik&#x27;, &#x27;floor_mat_marmer&#x27;, &#x27;floor_mat_ubin&#x27;, &#x27;floor_mat_vinyl&#x27;, &#x27;house_mat_bata_hebel&#x27;, &#x27;house_mat_bata_merah&#x27;, &#x27;house_mat_batako&#x27;, &#x27;house_mat_beton&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">catergorical_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;kondisi_perabotan_norm&#x27;, &#x27;kondisi_properti_norm&#x27;, &#x27;konsep_dan_gaya_rumah&#x27;, &#x27;sumber_air&#x27;, &#x27;pemandangan&#x27;, &#x27;sertifikat&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;lebar_jalan_num&#x27;, &#x27;daya_listrik_num&#x27;, &#x27;luas_bangunan_num&#x27;, &#x27;luas_tanah_num&#x27;, &#x27;carport&#x27;, &#x27;garasi&#x27;, &#x27;dapur&#x27;, &#x27;jumlah_lantai&#x27;, &#x27;kamar_mandi_pembantu&#x27;, &#x27;kamar_pembantu&#x27;, &#x27;kamar_mandi&#x27;, &#x27;kamar_tidur&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('passthrough', 'passthrough',\n",
       "                                 ['tags_bisa_nego', 'tags_cash_bertahap',\n",
       "                                  'tags_cash_keras', 'tags_dijual_cepat',\n",
       "                                  'tags_komplek', 'tags_kpr', 'tags_masuk_gang',\n",
       "                                  'tags_one_gate_system', 'tags_pedesaan',\n",
       "                                  'tags_perumahan', 'tags_pinggir_jalan',\n",
       "                                  'hook_available', 'ruang_tamu_available',\n",
       "                                  'ruang_makan_available',\n",
       "                                  'terjangkau_internet_availa...\n",
       "                                 ['kondisi_perabotan_norm',\n",
       "                                  'kondisi_properti_norm',\n",
       "                                  'konsep_dan_gaya_rumah', 'sumber_air',\n",
       "                                  'pemandangan', 'sertifikat']),\n",
       "                                ('numerical_encoder',\n",
       "                                 Pipeline(steps=[('scaler', MinMaxScaler())]),\n",
       "                                 ['lebar_jalan_num', 'daya_listrik_num',\n",
       "                                  'luas_bangunan_num', 'luas_tanah_num',\n",
       "                                  'carport', 'garasi', 'dapur', 'jumlah_lantai',\n",
       "                                  'kamar_mandi_pembantu', 'kamar_pembantu',\n",
       "                                  'kamar_mandi', 'kamar_tidur'])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_encoder = Pipeline(\n",
    "  steps=[\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "  ]\n",
    ")\n",
    "\n",
    "numerical_encoder = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "compose_transformers = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"passthrough\", \"passthrough\", tags_cols + floor_mat_cols + house_mat_cols),\n",
    "        (\"catergorical_encoder\", categorical_encoder, cat_cols),\n",
    "        (\"numerical_encoder\", numerical_encoder, num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "compose_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to hold CV results\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear/LinearRegression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear/Lasso model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear/Ridge model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear/BayesianRidge model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Tree/DecisionTreeRegressor model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN/KNeighborsRegressor model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Neural Network/MLPRegressor model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/fahmi/.mambaforge/envs/scraping/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   54.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Ensemble/RandomForestRegressor model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   30.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Ensemble/GradientBoostingRegressor model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   10.8s finished\n"
     ]
    }
   ],
   "source": [
    "# define models\n",
    "models = [\n",
    "    (\"Linear\", \"LinearRegression\", LinearRegression()),\n",
    "    (\"Linear\", \"Lasso\", Lasso()),\n",
    "    (\"Linear\", \"Ridge\", Ridge()), \n",
    "    (\"Linear\", \"BayesianRidge\", BayesianRidge()),\n",
    "    (\"Tree\", \"DecisionTreeRegressor\", DecisionTreeRegressor()),\n",
    "    (\"KNN\", \"KNeighborsRegressor\", KNeighborsRegressor()),\n",
    "    # (\"SVM\", \"SVR\", SVR()),\n",
    "    (\"Neural Network\", \"MLPRegressor\", MLPRegressor()),\n",
    "    (\"Ensemble\", \"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"Ensemble\", \"GradientBoostingRegressor\", GradientBoostingRegressor()),\n",
    "]\n",
    "\n",
    "# evaluate each model\n",
    "for category, name, model in models:\n",
    "    print(f\"Evaluating {category}/{name} model\")\n",
    "\n",
    "    # create classifier pipeline\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", compose_transformers),\n",
    "            (\"regressor\", model),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # run cross validation\n",
    "    cv_results.extend(cross_validate_ex(clf, X, y, category, name))\n",
    "\n",
    "# with pd.option_context('display.float_format', '{:0.4f}'.format):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kondisi_perabotan_norm</th>\n",
       "      <th>kondisi_properti_norm</th>\n",
       "      <th>konsep_dan_gaya_rumah</th>\n",
       "      <th>sumber_air</th>\n",
       "      <th>pemandangan</th>\n",
       "      <th>sertifikat</th>\n",
       "      <th>lebar_jalan_num</th>\n",
       "      <th>daya_listrik_num</th>\n",
       "      <th>luas_bangunan_num</th>\n",
       "      <th>luas_tanah_num</th>\n",
       "      <th>...</th>\n",
       "      <th>garasi</th>\n",
       "      <th>dapur</th>\n",
       "      <th>jumlah_lantai</th>\n",
       "      <th>kamar_mandi_pembantu</th>\n",
       "      <th>kamar_pembantu</th>\n",
       "      <th>kamar_mandi</th>\n",
       "      <th>kamar_tidur</th>\n",
       "      <th>tags</th>\n",
       "      <th>floor_mat</th>\n",
       "      <th>house_mat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unfurnished</td>\n",
       "      <td>furnished</td>\n",
       "      <td>Minimalis Modern</td>\n",
       "      <td>PAM atau PDAM</td>\n",
       "      <td>Pemukiman Warga</td>\n",
       "      <td>SHM - Sertifikat Hak Milik</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>semi furnished</td>\n",
       "      <td>furnished</td>\n",
       "      <td>Minimalis Modern</td>\n",
       "      <td>PAM atau PDAM</td>\n",
       "      <td>Pegunungan</td>\n",
       "      <td>SHM - Sertifikat Hak Milik</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  kondisi_perabotan_norm kondisi_properti_norm konsep_dan_gaya_rumah  \\\n",
       "0            unfurnished             furnished      Minimalis Modern   \n",
       "1         semi furnished             furnished      Minimalis Modern   \n",
       "\n",
       "      sumber_air      pemandangan                  sertifikat  \\\n",
       "0  PAM atau PDAM  Pemukiman Warga  SHM - Sertifikat Hak Milik   \n",
       "1  PAM atau PDAM       Pegunungan  SHM - Sertifikat Hak Milik   \n",
       "\n",
       "   lebar_jalan_num  daya_listrik_num  luas_bangunan_num  luas_tanah_num  ...  \\\n",
       "0              2.0            2200.0              180.0           300.0  ...   \n",
       "1              2.0            2200.0              270.0           385.0  ...   \n",
       "\n",
       "   garasi  dapur  jumlah_lantai  kamar_mandi_pembantu  kamar_pembantu  \\\n",
       "0     0.0    1.0            1.0                   1.0             1.0   \n",
       "1     4.0    1.0            1.0                   1.0             4.0   \n",
       "\n",
       "   kamar_mandi  kamar_tidur  \\\n",
       "0          3.0          3.0   \n",
       "1          3.0          4.0   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "\n",
       "                   floor_mat             house_mat  \n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0]  \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0]  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select colums to use\n",
    "X_catboost = df[cat_cols + num_cols].copy()\n",
    "\n",
    "# convert multihot columns to list\n",
    "X_catboost[\"tags\"] = df[tags_cols].values.tolist()\n",
    "X_catboost[\"floor_mat\"] = df[floor_mat_cols].values.tolist()\n",
    "X_catboost[\"house_mat\"] = df[house_mat_cols].values.tolist()\n",
    "\n",
    "cbembedding = [\"tags\", \"floor_mat\", \"house_mat\"]\n",
    "\n",
    "X_catboost.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Training fold 6\n",
      "Training fold 7\n",
      "Training fold 8\n",
      "Training fold 9\n",
      "Training fold 10\n"
     ]
    }
   ],
   "source": [
    "# run training\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=21)\n",
    "for fold_i, (train_idx, test_idx) in enumerate(cv.split(X_catboost, y)):\n",
    "    print(f\"Training fold {fold_i + 1}\")\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test = X_catboost.iloc[train_idx], X_catboost.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # create pool\n",
    "    train_pool = Pool(data=X_train, label=y_train, cat_features=cat_cols, embedding_features=cbembedding)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_cols, embedding_features=cbembedding)\n",
    "    \n",
    "    # train model\n",
    "    model = CatBoostRegressor(loss_function=\"MAE\", verbose=0, random_seed=21)\n",
    "\n",
    "    fit_time_start = time.time()\n",
    "    model.fit(train_pool, eval_set=test_pool, verbose=0)\n",
    "    fit_time_end = time.time()\n",
    "\n",
    "    # run predictions\n",
    "    score_time_start = time.time()\n",
    "    y_pred = model.predict(test_pool)\n",
    "    score_time_end = time.time()\n",
    "\n",
    "    # store metrics\n",
    "    cv_results.append({\n",
    "        \"fit_time\": fit_time_end - fit_time_start,\n",
    "        \"score_time\":score_time_end - score_time_start,\n",
    "        \"r2\": r2_score(y_test, y_pred),\n",
    "        \"mse\": mean_squared_error(y_test, y_pred),\n",
    "        \"mae\": mean_absolute_error(y_test, y_pred),\n",
    "        \"mape\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"category\": \"CatBoost\",\n",
    "        \"name\": \"CatBoostRegressor V4\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Training fold 6\n",
      "Training fold 7\n",
      "Training fold 8\n",
      "Training fold 9\n",
      "Training fold 10\n"
     ]
    }
   ],
   "source": [
    "# run training\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=21)\n",
    "for fold_i, (train_idx, test_idx) in enumerate(cv.split(X_catboost, y)):\n",
    "    print(f\"Training fold {fold_i + 1}\")\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # create pool\n",
    "    train_pool = Pool(data=X_train.drop(columns=[\"city\"]), label=y_train, cat_features=cat_cols + [\"district\"])\n",
    "    test_pool = Pool(data=X_test.drop(columns=[\"city\"]), label=y_test, cat_features=cat_cols + [\"district\"])\n",
    "    \n",
    "    # train model\n",
    "    model = CatBoostRegressor(loss_function=\"RMSE\", verbose=0, random_seed=21)\n",
    "\n",
    "    fit_time_start = time.time()\n",
    "    model.fit(train_pool, eval_set=test_pool, verbose=0)\n",
    "    fit_time_end = time.time()\n",
    "\n",
    "    # run predictions\n",
    "    score_time_start = time.time()\n",
    "    y_pred = model.predict(test_pool)\n",
    "    score_time_end = time.time()\n",
    "\n",
    "    # store metrics\n",
    "    cv_results.append({\n",
    "        \"fit_time\": fit_time_end - fit_time_start,\n",
    "        \"score_time\": score_time_end - score_time_start,\n",
    "        \"r2\": r2_score(y_test, y_pred),\n",
    "        \"mse\": mean_squared_error(y_test, y_pred),\n",
    "        \"mae\": mean_absolute_error(y_test, y_pred),\n",
    "        \"mape\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"category\": \"CatBoost MultiHot\",\n",
    "        \"name\": \"CatBoostRegressor with City\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 15:36:47.276092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator to convert dataframe to tf dataset\n",
    "def tf_df_row_gen(df):\n",
    "  for row in df.itertuples(index=False):\n",
    "    values = []\n",
    "\n",
    "    # map multihot columns\n",
    "    for name, cols in zip([\"floor_mat\", \"house_mat\", \"tags\"], [floor_mat_cols, house_mat_cols, tags_cols]):\n",
    "        cvals = []\n",
    "        for col in cols:\n",
    "            cvals.append(getattr(row, col))\n",
    "        \n",
    "        values.append(tf.constant(cvals, dtype=tf.float32, name=name))\n",
    "\n",
    "    # map categorical columns\n",
    "    for col in cat_cols:\n",
    "        values.append(tf.constant(getattr(row, col), dtype=tf.string, name=col))\n",
    "\n",
    "    # map numerical columns\n",
    "    for col in num_cols:\n",
    "        values.append(tf.constant(getattr(row, col), dtype=tf.float32, name=col))\n",
    "    \n",
    "    yield tuple(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tf_dataset(X, y):\n",
    "    # tensor specs\n",
    "    num_cols_spec = [tf.TensorSpec(shape=(), dtype=tf.float32, name=col) for col in num_cols]\n",
    "    cat_cols_spec = [tf.TensorSpec(shape=(), dtype=tf.string, name=col) for col in cat_cols]\n",
    "    embedding_cols_spec = [\n",
    "        tf.TensorSpec(shape=(5,), dtype=tf.float32, name=\"floor_mat\"),\n",
    "        tf.TensorSpec(shape=(4,), dtype=tf.float32, name=\"house_mat\"),\n",
    "        tf.TensorSpec(shape=(15,), dtype=tf.float32, name=\"tags\"),\n",
    "    ]\n",
    "\n",
    "    # create dataset\n",
    "    ds_labels = tf.data.Dataset.from_tensor_slices(y.values, name=\"price\")\n",
    "    ds_features = tf.data.Dataset.from_generator(\n",
    "        lambda: tf_df_row_gen(X),\n",
    "        output_signature=tuple(embedding_cols_spec + cat_cols_spec + num_cols_spec)\n",
    "    )\n",
    "\n",
    "    return tf.data.Dataset.zip((ds_features, ds_labels))\\\n",
    "        .batch(64) \\\n",
    "        .cache() \\\n",
    "        .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numeric_norm_layer(index, dataset):\n",
    "    # Create a Normalization layer for our feature.\n",
    "    normalizer = tf.keras.layers.Normalization(axis=None)\n",
    "    normalizer.adapt(dataset.map(lambda x, _: x[index]))\n",
    "    \n",
    "    return normalizer\n",
    "\n",
    "def create_categorical_norm_layer(index, dataset):\n",
    "    # Create a layer that turns strings into integer indices.\n",
    "    indexer = tf.keras.layers.StringLookup(max_tokens=None)\n",
    "    indexer.adapt(dataset.map(lambda x, _: x[index]))\n",
    "    \n",
    "    # Encode the integer indices.\n",
    "    encoder = tf.keras.layers.CategoryEncoding(num_tokens=indexer.vocabulary_size())\n",
    "    \n",
    "    # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "    # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "    return lambda feature: encoder(indexer(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_model(ds: tf.data.Dataset) -> tf.keras.Model:\n",
    "    tf_inputs = []\n",
    "    tf_layers = []\n",
    "\n",
    "    for i, (col, col_len) in enumerate([(\"floor_mat\", 5), (\"house_mat\", 4), (\"tags\", 15)]):\n",
    "        input_layer = tf.keras.Input(shape=(col_len,), name=col)\n",
    "        normalizer = tf.keras.layers.Dense(10, activation=\"relu\")(input_layer)\n",
    "\n",
    "        tf_inputs.append(input_layer)\n",
    "        tf_layers.append(normalizer)\n",
    "\n",
    "    for i, col in enumerate(cat_cols):\n",
    "        input_layer = tf.keras.Input(shape=(1,), name=col, dtype=tf.string)\n",
    "        normalizer = create_categorical_norm_layer(i + 3, ds)\n",
    "\n",
    "        tf_inputs.append(input_layer)\n",
    "        tf_layers.append(normalizer(input_layer))\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        input_layer = tf.keras.Input(shape=(1,), name=col)\n",
    "        normalizer = create_numeric_norm_layer(i + 9, ds)\n",
    "\n",
    "        tf_inputs.append(input_layer)\n",
    "        tf_layers.append(normalizer(input_layer))\n",
    "\n",
    "    # concatenate all layers\n",
    "    x = tf.keras.layers.concatenate(tf_layers)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    output = tf.keras.layers.Dense(1, name=\"price\")(x)\n",
    "\n",
    "    # create model\n",
    "    model = tf.keras.Model(inputs=tf_inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 10ms/step - loss: 2590441.5000 - mae: 1165.0354 - mse: 2590441.5000 - val_loss: 1264593.1250 - val_mae: 871.8628 - val_mse: 1264593.1250\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 950735.1875 - mae: 705.8456 - mse: 950735.1875 - val_loss: 806854.3750 - val_mae: 639.4821 - val_mse: 806854.3750\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 743840.3750 - mae: 581.5065 - mse: 743840.3750 - val_loss: 767575.3125 - val_mae: 579.2120 - val_mse: 767575.3125\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 698786.8750 - mae: 551.5208 - mse: 698786.8750 - val_loss: 770141.6875 - val_mae: 559.5584 - val_mse: 770141.6875\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 671784.3750 - mae: 538.2142 - mse: 671784.3750 - val_loss: 776011.6250 - val_mae: 548.4213 - val_mse: 776011.6250\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 650384.5000 - mae: 529.1739 - mse: 650384.5000 - val_loss: 782152.1250 - val_mae: 539.9864 - val_mse: 782152.1250\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 632656.8750 - mae: 521.9041 - mse: 632656.8750 - val_loss: 787747.8125 - val_mae: 533.1871 - val_mse: 787747.8125\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 617362.5000 - mae: 515.6625 - mse: 617362.5000 - val_loss: 791998.1250 - val_mae: 527.3322 - val_mse: 791998.1250\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 603897.9375 - mae: 510.1509 - mse: 603897.9375 - val_loss: 794536.3750 - val_mae: 522.2970 - val_mse: 794536.3750\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 591852.5625 - mae: 505.1108 - mse: 591852.5625 - val_loss: 795105.1250 - val_mae: 517.5223 - val_mse: 795105.1250\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 580753.1875 - mae: 500.3930 - mse: 580753.1875 - val_loss: 793586.6250 - val_mae: 513.0054 - val_mse: 793586.6250\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 570158.5000 - mae: 495.9149 - mse: 570158.5000 - val_loss: 789599.3125 - val_mae: 508.8251 - val_mse: 789599.3125\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 560051.9375 - mae: 491.6181 - mse: 560051.9375 - val_loss: 783540.8125 - val_mae: 504.8547 - val_mse: 783540.8125\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 550394.5625 - mae: 487.5161 - mse: 550394.5625 - val_loss: 775316.6250 - val_mae: 500.9254 - val_mse: 775316.6250\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 541179.0000 - mae: 483.6323 - mse: 541179.0000 - val_loss: 765160.1250 - val_mae: 497.2699 - val_mse: 765160.1250\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 532246.3750 - mae: 479.9259 - mse: 532246.3750 - val_loss: 753013.6875 - val_mae: 493.6782 - val_mse: 753013.6875\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 523699.0938 - mae: 476.3958 - mse: 523699.0938 - val_loss: 739529.9375 - val_mae: 490.2522 - val_mse: 739529.9375\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 515461.8750 - mae: 472.9977 - mse: 515461.8750 - val_loss: 724814.4375 - val_mae: 486.7407 - val_mse: 724814.4375\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 507593.6250 - mae: 469.7986 - mse: 507593.6250 - val_loss: 708996.5625 - val_mae: 483.4174 - val_mse: 708996.5625\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 500095.0000 - mae: 466.8135 - mse: 500095.0000 - val_loss: 692419.0625 - val_mae: 480.2125 - val_mse: 692419.0625\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 493016.4062 - mae: 464.0371 - mse: 493016.4062 - val_loss: 675390.1250 - val_mae: 477.0738 - val_mse: 675390.1250\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 486224.8750 - mae: 461.5069 - mse: 486224.8750 - val_loss: 657158.0625 - val_mae: 474.2929 - val_mse: 657158.0625\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 479931.1875 - mae: 459.1900 - mse: 479931.1875 - val_loss: 639734.5625 - val_mae: 471.6261 - val_mse: 639734.5625\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 474113.2500 - mae: 457.1194 - mse: 474113.2500 - val_loss: 622664.1250 - val_mae: 469.2190 - val_mse: 622664.1250\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 468747.1562 - mae: 455.2631 - mse: 468747.1562 - val_loss: 606247.0000 - val_mae: 467.0955 - val_mse: 606247.0000\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 463816.8125 - mae: 453.6388 - mse: 463816.8125 - val_loss: 590630.5000 - val_mae: 465.2390 - val_mse: 590630.5000\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 459308.6250 - mae: 452.2089 - mse: 459308.6250 - val_loss: 575838.0000 - val_mae: 463.4725 - val_mse: 575838.0000\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 455128.9062 - mae: 450.9312 - mse: 455128.9062 - val_loss: 562027.9375 - val_mae: 461.8461 - val_mse: 562027.9375\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 451275.0312 - mae: 449.7440 - mse: 451275.0312 - val_loss: 548662.3750 - val_mae: 460.3140 - val_mse: 548662.3750\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 447709.2188 - mae: 448.6617 - mse: 447709.2188 - val_loss: 536472.3750 - val_mae: 458.7051 - val_mse: 536472.3750\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 444371.7188 - mae: 447.5239 - mse: 444371.7188 - val_loss: 524982.1875 - val_mae: 457.2070 - val_mse: 524982.1875\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 441280.9375 - mae: 446.5157 - mse: 441280.9375 - val_loss: 514271.4688 - val_mae: 455.7805 - val_mse: 514271.4688\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438412.5000 - mae: 445.5077 - mse: 438412.5000 - val_loss: 504329.7188 - val_mae: 454.3973 - val_mse: 504329.7188\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 435770.9688 - mae: 444.5621 - mse: 435770.9688 - val_loss: 494998.4688 - val_mae: 452.9915 - val_mse: 494998.4688\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433199.0625 - mae: 443.5552 - mse: 433199.0625 - val_loss: 486564.3750 - val_mae: 451.6416 - val_mse: 486564.3750\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 430830.0625 - mae: 442.6258 - mse: 430830.0625 - val_loss: 478807.8750 - val_mae: 450.3671 - val_mse: 478807.8750\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 428627.8125 - mae: 441.7480 - mse: 428627.8125 - val_loss: 471926.5938 - val_mae: 449.2632 - val_mse: 471926.5938\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 426549.9375 - mae: 440.8940 - mse: 426549.9375 - val_loss: 465780.0312 - val_mae: 448.1603 - val_mse: 465780.0312\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 424608.5625 - mae: 440.0425 - mse: 424608.5625 - val_loss: 460350.8438 - val_mae: 447.1259 - val_mse: 460350.8438\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 422772.5000 - mae: 439.1994 - mse: 422772.5000 - val_loss: 455504.6250 - val_mae: 446.0739 - val_mse: 455504.6250\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 421014.0625 - mae: 438.3478 - mse: 421014.0625 - val_loss: 451021.8750 - val_mae: 444.9580 - val_mse: 451021.8750\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 419356.5625 - mae: 437.5331 - mse: 419356.5625 - val_loss: 447159.7188 - val_mae: 443.8997 - val_mse: 447159.7188\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 417783.0000 - mae: 436.6763 - mse: 417783.0000 - val_loss: 443765.0312 - val_mae: 442.8592 - val_mse: 443765.0312\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 416281.1875 - mae: 435.8096 - mse: 416281.1875 - val_loss: 440681.2188 - val_mae: 441.7316 - val_mse: 440681.2188\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 414786.3125 - mae: 434.8425 - mse: 414786.3125 - val_loss: 437798.6250 - val_mae: 440.3969 - val_mse: 437798.6250\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 413327.9062 - mae: 433.8789 - mse: 413327.9062 - val_loss: 435479.7188 - val_mae: 439.4758 - val_mse: 435479.7188\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 411976.4688 - mae: 433.0303 - mse: 411976.4688 - val_loss: 433656.4688 - val_mae: 438.7483 - val_mse: 433656.4688\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 410720.2188 - mae: 432.2331 - mse: 410720.2188 - val_loss: 432033.2812 - val_mae: 438.0556 - val_mse: 432033.2812\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 409517.2188 - mae: 431.4389 - mse: 409517.2188 - val_loss: 430577.5938 - val_mae: 437.2133 - val_mse: 430577.5938\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 408348.8125 - mae: 430.5773 - mse: 408348.8125 - val_loss: 429195.2500 - val_mae: 436.3293 - val_mse: 429195.2500\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 407152.8750 - mae: 429.6695 - mse: 407152.8750 - val_loss: 428012.2500 - val_mae: 435.3889 - val_mse: 428012.2500\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 406011.5625 - mae: 428.8062 - mse: 406011.5625 - val_loss: 427045.5000 - val_mae: 434.5616 - val_mse: 427045.5000\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 404942.6250 - mae: 428.0629 - mse: 404942.6250 - val_loss: 426425.0938 - val_mae: 434.0089 - val_mse: 426425.0938\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 403959.4062 - mae: 427.4180 - mse: 403959.4062 - val_loss: 425945.7188 - val_mae: 433.7342 - val_mse: 425945.7188\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 403040.6250 - mae: 426.7831 - mse: 403040.6250 - val_loss: 425421.4688 - val_mae: 433.4321 - val_mse: 425421.4688\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 402156.5000 - mae: 426.1870 - mse: 402156.5000 - val_loss: 424988.0938 - val_mae: 433.1861 - val_mse: 424988.0938\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 401313.0938 - mae: 425.5865 - mse: 401313.0938 - val_loss: 424665.3750 - val_mae: 432.9778 - val_mse: 424665.3750\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 400494.4688 - mae: 425.0081 - mse: 400494.4688 - val_loss: 424283.1562 - val_mae: 432.7304 - val_mse: 424283.1562\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 399682.5625 - mae: 424.4556 - mse: 399682.5625 - val_loss: 423928.9375 - val_mae: 432.5250 - val_mse: 423928.9375\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 398899.2188 - mae: 423.8981 - mse: 398899.2188 - val_loss: 423631.7500 - val_mae: 432.2382 - val_mse: 423631.7500\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 398140.9375 - mae: 423.3573 - mse: 398140.9375 - val_loss: 423223.7500 - val_mae: 431.9109 - val_mse: 423223.7500\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 397393.2188 - mae: 422.8164 - mse: 397393.2188 - val_loss: 422763.7188 - val_mae: 431.5968 - val_mse: 422763.7188\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 396619.5000 - mae: 422.2748 - mse: 396619.5000 - val_loss: 422358.9375 - val_mae: 431.3072 - val_mse: 422358.9375\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 395879.6250 - mae: 421.7604 - mse: 395879.6250 - val_loss: 421993.5000 - val_mae: 431.0113 - val_mse: 421993.5000\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 395149.2188 - mae: 421.2443 - mse: 395149.2188 - val_loss: 421678.9688 - val_mae: 430.8096 - val_mse: 421678.9688\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 394409.6562 - mae: 420.7361 - mse: 394409.6562 - val_loss: 421385.7812 - val_mae: 430.5375 - val_mse: 421385.7812\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 393690.8750 - mae: 420.2753 - mse: 393690.8750 - val_loss: 421011.4688 - val_mae: 430.3118 - val_mse: 421011.4688\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 393006.8125 - mae: 419.8254 - mse: 393006.8125 - val_loss: 420572.7812 - val_mae: 429.9938 - val_mse: 420572.7812\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 392316.6562 - mae: 419.3957 - mse: 392316.6562 - val_loss: 420220.5312 - val_mae: 429.7077 - val_mse: 420220.5312\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 391617.8125 - mae: 418.9457 - mse: 391617.8125 - val_loss: 419946.4688 - val_mae: 429.4347 - val_mse: 419946.4688\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 390937.5312 - mae: 418.5311 - mse: 390937.5312 - val_loss: 419550.1250 - val_mae: 429.1620 - val_mse: 419550.1250\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 390261.5938 - mae: 418.0888 - mse: 390261.5938 - val_loss: 419058.6250 - val_mae: 428.7814 - val_mse: 419058.6250\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 389580.7500 - mae: 417.6413 - mse: 389580.7500 - val_loss: 418613.9062 - val_mae: 428.4397 - val_mse: 418613.9062\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 388908.0000 - mae: 417.2103 - mse: 388908.0000 - val_loss: 418124.8750 - val_mae: 428.0413 - val_mse: 418124.8750\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 388204.6562 - mae: 416.7777 - mse: 388204.6562 - val_loss: 417718.9062 - val_mae: 427.7144 - val_mse: 417718.9062\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 387512.4688 - mae: 416.3168 - mse: 387512.4688 - val_loss: 417292.0000 - val_mae: 427.3018 - val_mse: 417292.0000\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 386828.9688 - mae: 415.8918 - mse: 386828.9688 - val_loss: 416754.2500 - val_mae: 426.9443 - val_mse: 416754.2500\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 386149.2188 - mae: 415.4646 - mse: 386149.2188 - val_loss: 416278.9375 - val_mae: 426.5797 - val_mse: 416278.9375\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 385468.4688 - mae: 415.0699 - mse: 385468.4688 - val_loss: 415919.6562 - val_mae: 426.3243 - val_mse: 415919.6562\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 384843.5312 - mae: 414.6966 - mse: 384843.5312 - val_loss: 415292.8125 - val_mae: 425.9254 - val_mse: 415292.8125\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 384191.3438 - mae: 414.3099 - mse: 384191.3438 - val_loss: 414782.5625 - val_mae: 425.5538 - val_mse: 414782.5625\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 383507.9062 - mae: 413.8952 - mse: 383507.9062 - val_loss: 414323.5938 - val_mae: 425.2007 - val_mse: 414323.5938\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 382858.5312 - mae: 413.5060 - mse: 382858.5312 - val_loss: 413841.0000 - val_mae: 424.9214 - val_mse: 413841.0000\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 382218.0938 - mae: 413.1172 - mse: 382218.0938 - val_loss: 413452.9062 - val_mae: 424.5784 - val_mse: 413452.9062\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 381563.0938 - mae: 412.7416 - mse: 381563.0938 - val_loss: 412882.9688 - val_mae: 424.1084 - val_mse: 412882.9688\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 380920.0625 - mae: 412.3595 - mse: 380920.0625 - val_loss: 412537.2188 - val_mae: 423.8182 - val_mse: 412537.2188\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 380231.7188 - mae: 411.9777 - mse: 380231.7188 - val_loss: 411877.6875 - val_mae: 423.3411 - val_mse: 411877.6875\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 379528.4688 - mae: 411.5841 - mse: 379528.4688 - val_loss: 411523.2812 - val_mae: 423.0653 - val_mse: 411523.2812\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 378785.8750 - mae: 411.1646 - mse: 378785.8750 - val_loss: 410946.5938 - val_mae: 422.6509 - val_mse: 410946.5938\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 378067.7812 - mae: 410.7225 - mse: 378067.7812 - val_loss: 410621.3438 - val_mae: 422.3543 - val_mse: 410621.3438\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 377350.9688 - mae: 410.3278 - mse: 377350.9688 - val_loss: 410033.7188 - val_mae: 421.9106 - val_mse: 410033.7188\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 376620.6250 - mae: 409.8829 - mse: 376620.6250 - val_loss: 409560.6875 - val_mae: 421.5104 - val_mse: 409560.6875\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 375880.6250 - mae: 409.4657 - mse: 375880.6250 - val_loss: 409009.0312 - val_mae: 421.1092 - val_mse: 409009.0312\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 375147.7500 - mae: 409.0107 - mse: 375147.7500 - val_loss: 408408.7812 - val_mae: 420.7385 - val_mse: 408408.7812\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 374419.3125 - mae: 408.5942 - mse: 374419.3125 - val_loss: 407922.1250 - val_mae: 420.4166 - val_mse: 407922.1250\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 373720.0312 - mae: 408.1639 - mse: 373720.0312 - val_loss: 407381.4062 - val_mae: 420.0138 - val_mse: 407381.4062\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 373001.8125 - mae: 407.7594 - mse: 373001.8125 - val_loss: 406881.9688 - val_mae: 419.6500 - val_mse: 406881.9688\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 372295.0000 - mae: 407.3452 - mse: 372295.0000 - val_loss: 406287.0000 - val_mae: 419.1930 - val_mse: 406287.0000\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 371597.7500 - mae: 406.9720 - mse: 371597.7500 - val_loss: 405808.6875 - val_mae: 418.8665 - val_mse: 405808.6875\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 370892.1562 - mae: 406.5516 - mse: 370892.1562 - val_loss: 405206.2812 - val_mae: 418.5027 - val_mse: 405206.2812\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Training fold 2\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 10ms/step - loss: 2426253.2500 - mae: 1119.8273 - mse: 2426253.2500 - val_loss: 1647236.5000 - val_mae: 848.2001 - val_mse: 1647236.5000\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 890488.9375 - mae: 660.9114 - mse: 890488.9375 - val_loss: 1507159.6250 - val_mae: 639.2900 - val_mse: 1507159.6250\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 760669.0625 - mae: 571.8807 - mse: 760669.0625 - val_loss: 1446833.7500 - val_mae: 606.2732 - val_mse: 1446833.7500\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 729576.1875 - mae: 552.0364 - mse: 729576.1875 - val_loss: 1367197.1250 - val_mae: 594.0912 - val_mse: 1367197.1250\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 709977.3125 - mae: 543.6758 - mse: 709977.3125 - val_loss: 1294446.2500 - val_mae: 587.4333 - val_mse: 1294446.2500\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 695697.3125 - mae: 539.1036 - mse: 695697.3125 - val_loss: 1230905.0000 - val_mae: 582.8123 - val_mse: 1230905.0000\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 684645.0625 - mae: 535.9893 - mse: 684645.0625 - val_loss: 1175047.1250 - val_mae: 579.1804 - val_mse: 1175047.1250\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 675628.5625 - mae: 533.6420 - mse: 675628.5625 - val_loss: 1125362.8750 - val_mae: 576.1260 - val_mse: 1125362.8750\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 667958.1250 - mae: 531.6357 - mse: 667958.1250 - val_loss: 1080978.2500 - val_mae: 573.3956 - val_mse: 1080978.2500\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 661318.7500 - mae: 529.9570 - mse: 661318.7500 - val_loss: 1040932.6250 - val_mae: 571.0547 - val_mse: 1040932.6250\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 655439.6250 - mae: 528.5116 - mse: 655439.6250 - val_loss: 1003709.6250 - val_mae: 568.9490 - val_mse: 1003709.6250\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 650089.0625 - mae: 527.1659 - mse: 650089.0625 - val_loss: 967530.0625 - val_mae: 566.8788 - val_mse: 967530.0625\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 644914.7500 - mae: 525.8965 - mse: 644914.7500 - val_loss: 934912.8125 - val_mae: 564.8968 - val_mse: 934912.8125\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 640215.8125 - mae: 524.6401 - mse: 640215.8125 - val_loss: 904997.3750 - val_mae: 562.9484 - val_mse: 904997.3750\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 635870.0625 - mae: 523.4182 - mse: 635870.0625 - val_loss: 877468.3750 - val_mae: 561.0424 - val_mse: 877468.3750\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 631830.1250 - mae: 522.2222 - mse: 631830.1250 - val_loss: 848885.3125 - val_mae: 559.0640 - val_mse: 848885.3125\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 627665.5625 - mae: 520.9989 - mse: 627665.5625 - val_loss: 823314.9375 - val_mae: 557.1083 - val_mse: 823314.9375\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 623830.1875 - mae: 519.7868 - mse: 623830.1875 - val_loss: 800094.0000 - val_mae: 555.1282 - val_mse: 800094.0000\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 620261.6875 - mae: 518.6006 - mse: 620261.6875 - val_loss: 778900.0000 - val_mae: 553.2812 - val_mse: 778900.0000\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 616874.8750 - mae: 517.4103 - mse: 616874.8750 - val_loss: 759591.8125 - val_mae: 551.4434 - val_mse: 759591.8125\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 613697.5625 - mae: 516.2689 - mse: 613697.5625 - val_loss: 742113.2500 - val_mae: 549.6135 - val_mse: 742113.2500\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 610674.0625 - mae: 515.1344 - mse: 610674.0625 - val_loss: 726327.6875 - val_mae: 547.8675 - val_mse: 726327.6875\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 607766.3125 - mae: 514.0081 - mse: 607766.3125 - val_loss: 712146.8125 - val_mae: 546.1381 - val_mse: 712146.8125\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 605001.7500 - mae: 512.8923 - mse: 605001.7500 - val_loss: 699538.2500 - val_mae: 544.4919 - val_mse: 699538.2500\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 602317.8750 - mae: 511.7401 - mse: 602317.8750 - val_loss: 688670.7500 - val_mae: 542.9220 - val_mse: 688670.7500\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 599755.0000 - mae: 510.5761 - mse: 599755.0000 - val_loss: 678845.9375 - val_mae: 541.4083 - val_mse: 678845.9375\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 597219.9375 - mae: 509.4202 - mse: 597219.9375 - val_loss: 670175.8750 - val_mae: 539.8751 - val_mse: 670175.8750\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 594725.5625 - mae: 508.2745 - mse: 594725.5625 - val_loss: 662389.2500 - val_mae: 538.4332 - val_mse: 662389.2500\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 592251.0625 - mae: 507.1254 - mse: 592251.0625 - val_loss: 655284.3750 - val_mae: 536.9821 - val_mse: 655284.3750\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 589732.4375 - mae: 505.9407 - mse: 589732.4375 - val_loss: 649143.4375 - val_mae: 535.5604 - val_mse: 649143.4375\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 587249.3125 - mae: 504.7849 - mse: 587249.3125 - val_loss: 643417.5000 - val_mae: 534.2315 - val_mse: 643417.5000\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 584685.5625 - mae: 503.6182 - mse: 584685.5625 - val_loss: 638207.5000 - val_mae: 532.9026 - val_mse: 638207.5000\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 582077.2500 - mae: 502.4438 - mse: 582077.2500 - val_loss: 633434.9375 - val_mae: 531.6039 - val_mse: 633434.9375\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 579402.4375 - mae: 501.2674 - mse: 579402.4375 - val_loss: 628962.1250 - val_mae: 530.2380 - val_mse: 628962.1250\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 576660.8750 - mae: 500.0855 - mse: 576660.8750 - val_loss: 624737.1250 - val_mae: 528.8694 - val_mse: 624737.1250\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 573851.9375 - mae: 498.8832 - mse: 573851.9375 - val_loss: 620617.5000 - val_mae: 527.5437 - val_mse: 620617.5000\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 570973.6875 - mae: 497.6873 - mse: 570973.6875 - val_loss: 616593.0000 - val_mae: 526.1688 - val_mse: 616593.0000\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 568010.6250 - mae: 496.4585 - mse: 568010.6250 - val_loss: 612653.5625 - val_mae: 524.7938 - val_mse: 612653.5625\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 564978.0000 - mae: 495.2181 - mse: 564978.0000 - val_loss: 608724.5625 - val_mae: 523.3367 - val_mse: 608724.5625\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 561833.3750 - mae: 493.9580 - mse: 561833.3750 - val_loss: 604841.5625 - val_mae: 521.9146 - val_mse: 604841.5625\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 558664.3750 - mae: 492.6929 - mse: 558664.3750 - val_loss: 600972.6875 - val_mae: 520.4290 - val_mse: 600972.6875\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 555358.1250 - mae: 491.3953 - mse: 555358.1250 - val_loss: 597103.1875 - val_mae: 518.9488 - val_mse: 597103.1875\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 552066.6250 - mae: 490.1250 - mse: 552066.6250 - val_loss: 593239.8125 - val_mae: 517.3804 - val_mse: 593239.8125\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 548595.4375 - mae: 488.7515 - mse: 548595.4375 - val_loss: 589330.8125 - val_mae: 515.7731 - val_mse: 589330.8125\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 545199.8125 - mae: 487.4735 - mse: 545199.8125 - val_loss: 585422.2500 - val_mae: 514.2075 - val_mse: 585422.2500\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 541529.6250 - mae: 486.0265 - mse: 541529.6250 - val_loss: 581531.6250 - val_mae: 512.6146 - val_mse: 581531.6250\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 537917.0000 - mae: 484.6971 - mse: 537917.0000 - val_loss: 577669.9375 - val_mae: 511.0395 - val_mse: 577669.9375\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 534159.3125 - mae: 483.2378 - mse: 534159.3125 - val_loss: 573842.3750 - val_mae: 509.3658 - val_mse: 573842.3750\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 530471.7500 - mae: 481.8497 - mse: 530471.7500 - val_loss: 570017.1875 - val_mae: 507.6931 - val_mse: 570017.1875\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 526593.3125 - mae: 480.3507 - mse: 526593.3125 - val_loss: 566315.3750 - val_mae: 505.9174 - val_mse: 566315.3750\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 522813.4375 - mae: 478.9501 - mse: 522813.4375 - val_loss: 562632.6875 - val_mae: 504.1957 - val_mse: 562632.6875\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 518892.6875 - mae: 477.4055 - mse: 518892.6875 - val_loss: 559115.3125 - val_mae: 502.4850 - val_mse: 559115.3125\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 515118.5000 - mae: 475.9743 - mse: 515118.5000 - val_loss: 555632.0625 - val_mae: 500.7806 - val_mse: 555632.0625\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 511194.2812 - mae: 474.4177 - mse: 511194.2812 - val_loss: 552225.7500 - val_mae: 499.1118 - val_mse: 552225.7500\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 507408.1562 - mae: 472.9111 - mse: 507408.1562 - val_loss: 549098.5625 - val_mae: 497.4091 - val_mse: 549098.5625\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 503553.8438 - mae: 471.3497 - mse: 503553.8438 - val_loss: 545451.5000 - val_mae: 495.6802 - val_mse: 545451.5000\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 499694.0312 - mae: 469.7937 - mse: 499694.0312 - val_loss: 542734.8750 - val_mae: 494.0379 - val_mse: 542734.8750\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 495941.6875 - mae: 468.2032 - mse: 495941.6875 - val_loss: 539476.3125 - val_mae: 492.3102 - val_mse: 539476.3125\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 492257.5938 - mae: 466.6692 - mse: 492257.5938 - val_loss: 536391.8125 - val_mae: 490.5678 - val_mse: 536391.8125\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 488472.2188 - mae: 465.0009 - mse: 488472.2188 - val_loss: 533477.9375 - val_mae: 488.8116 - val_mse: 533477.9375\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 484878.2500 - mae: 463.4431 - mse: 484878.2500 - val_loss: 530398.8750 - val_mae: 487.0687 - val_mse: 530398.8750\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 481156.0312 - mae: 461.7226 - mse: 481156.0312 - val_loss: 527943.0000 - val_mae: 485.3328 - val_mse: 527943.0000\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 477786.5625 - mae: 460.2181 - mse: 477786.5625 - val_loss: 524011.5625 - val_mae: 483.5551 - val_mse: 524011.5625\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 473948.5938 - mae: 458.3782 - mse: 473948.5938 - val_loss: 523093.8438 - val_mae: 482.0725 - val_mse: 523093.8438\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 470974.4688 - mae: 457.0973 - mse: 470974.4688 - val_loss: 517077.6875 - val_mae: 480.0529 - val_mse: 517077.6875\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 466830.2500 - mae: 454.9368 - mse: 466830.2500 - val_loss: 521085.7812 - val_mae: 479.1412 - val_mse: 521085.7812\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 464843.3125 - mae: 454.3002 - mse: 464843.3125 - val_loss: 509714.3438 - val_mae: 476.2829 - val_mse: 509714.3438\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 459921.6250 - mae: 451.4817 - mse: 459921.6250 - val_loss: 521244.2188 - val_mae: 476.4552 - val_mse: 521244.2188\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 459246.0938 - mae: 451.6828 - mse: 459246.0938 - val_loss: 504756.4062 - val_mae: 473.2411 - val_mse: 504756.4062\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 453866.4688 - mae: 448.5856 - mse: 453866.4688 - val_loss: 508839.7812 - val_mae: 472.8497 - val_mse: 508839.7812\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 452022.7812 - mae: 448.0432 - mse: 452022.7812 - val_loss: 499671.8750 - val_mae: 470.2900 - val_mse: 499671.8750\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 448175.3125 - mae: 445.8195 - mse: 448175.3125 - val_loss: 503358.6250 - val_mae: 469.8380 - val_mse: 503358.6250\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 446478.1250 - mae: 445.2743 - mse: 446478.1250 - val_loss: 494085.5312 - val_mae: 467.2393 - val_mse: 494085.5312\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 443055.0938 - mae: 443.1800 - mse: 443055.0938 - val_loss: 499628.5000 - val_mae: 467.4818 - val_mse: 499628.5000\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 441720.5938 - mae: 442.8877 - mse: 441720.5938 - val_loss: 489182.0312 - val_mae: 464.6969 - val_mse: 489182.0312\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438129.9688 - mae: 440.5030 - mse: 438129.9688 - val_loss: 492550.7188 - val_mae: 464.7205 - val_mse: 492550.7188\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 436789.6875 - mae: 440.1563 - mse: 436789.6875 - val_loss: 484285.7500 - val_mae: 462.2080 - val_mse: 484285.7500\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433961.5938 - mae: 438.2431 - mse: 433961.5938 - val_loss: 486215.4062 - val_mae: 462.1650 - val_mse: 486215.4062\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 432661.5312 - mae: 437.8448 - mse: 432661.5312 - val_loss: 479881.0000 - val_mae: 459.6315 - val_mse: 479881.0000\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 430339.7500 - mae: 436.1760 - mse: 430339.7500 - val_loss: 482861.9688 - val_mae: 460.0502 - val_mse: 482861.9688\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 429350.8438 - mae: 435.9614 - mse: 429350.8438 - val_loss: 476641.8750 - val_mae: 457.9419 - val_mse: 476641.8750\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 427268.6250 - mae: 434.3376 - mse: 427268.6250 - val_loss: 479980.1562 - val_mae: 458.2640 - val_mse: 479980.1562\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 426546.5625 - mae: 434.3281 - mse: 426546.5625 - val_loss: 473994.8438 - val_mae: 456.5530 - val_mse: 473994.8438\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 424655.7188 - mae: 432.7688 - mse: 424655.7188 - val_loss: 478081.0312 - val_mae: 456.8428 - val_mse: 478081.0312\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 424265.3750 - mae: 433.1219 - mse: 424265.3750 - val_loss: 472139.6875 - val_mae: 455.5278 - val_mse: 472139.6875\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 422440.3125 - mae: 431.4650 - mse: 422440.3125 - val_loss: 473188.4062 - val_mae: 455.1494 - val_mse: 473188.4062\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 421707.1562 - mae: 431.4428 - mse: 421707.1562 - val_loss: 468764.9375 - val_mae: 453.8564 - val_mse: 468764.9375\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 420298.9688 - mae: 430.2830 - mse: 420298.9688 - val_loss: 470186.5938 - val_mae: 453.7984 - val_mse: 470186.5938\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 419773.8750 - mae: 430.3349 - mse: 419773.8750 - val_loss: 467621.7812 - val_mae: 453.0093 - val_mse: 467621.7812\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 418709.9688 - mae: 429.2598 - mse: 418709.9688 - val_loss: 468838.6250 - val_mae: 452.9137 - val_mse: 468838.6250\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 418247.6875 - mae: 429.3280 - mse: 418247.6875 - val_loss: 466194.6875 - val_mae: 452.1645 - val_mse: 466194.6875\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 417244.7188 - mae: 428.3768 - mse: 417244.7188 - val_loss: 468155.0938 - val_mae: 452.2571 - val_mse: 468155.0938\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 416879.9688 - mae: 428.5693 - mse: 416879.9688 - val_loss: 465595.3438 - val_mae: 451.7818 - val_mse: 465595.3438\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 416049.7812 - mae: 427.5500 - mse: 416049.7812 - val_loss: 468026.2500 - val_mae: 451.7226 - val_mse: 468026.2500\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 415860.9062 - mae: 428.0036 - mse: 415860.9062 - val_loss: 465319.5938 - val_mae: 451.3571 - val_mse: 465319.5938\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 414898.1250 - mae: 426.8578 - mse: 414898.1250 - val_loss: 465299.9688 - val_mae: 450.9721 - val_mse: 465299.9688\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 414469.2500 - mae: 427.1818 - mse: 414469.2500 - val_loss: 462318.2812 - val_mae: 450.3881 - val_mse: 462318.2812\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 413545.9062 - mae: 426.2300 - mse: 413545.9062 - val_loss: 462346.6250 - val_mae: 450.1194 - val_mse: 462346.6250\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 413088.4062 - mae: 426.2557 - mse: 413088.4062 - val_loss: 460215.9375 - val_mae: 449.3344 - val_mse: 460215.9375\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 412274.8125 - mae: 425.5511 - mse: 412274.8125 - val_loss: 460729.9688 - val_mae: 449.3543 - val_mse: 460729.9688\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Training fold 3\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 10ms/step - loss: 2434453.5000 - mae: 1122.8722 - mse: 2434453.5000 - val_loss: 1016152.8125 - val_mae: 793.9354 - val_mse: 1016152.8125\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 900076.1875 - mae: 664.4009 - mse: 900076.1875 - val_loss: 663925.1250 - val_mae: 586.1144 - val_mse: 663925.1250\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 768496.5625 - mae: 577.4415 - mse: 768496.5625 - val_loss: 612218.4375 - val_mae: 548.5892 - val_mse: 612218.4375\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 727694.8125 - mae: 555.4215 - mse: 727694.8125 - val_loss: 588412.5625 - val_mae: 532.9315 - val_mse: 588412.5625\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 698806.6875 - mae: 544.4452 - mse: 698806.6875 - val_loss: 571712.1250 - val_mae: 523.7924 - val_mse: 571712.1250\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 675138.3125 - mae: 536.1901 - mse: 675138.3125 - val_loss: 557624.5000 - val_mae: 516.3649 - val_mse: 557624.5000\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 653936.3750 - mae: 528.6361 - mse: 653936.3750 - val_loss: 544628.8750 - val_mae: 509.5845 - val_mse: 544628.8750\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 634369.6250 - mae: 521.5111 - mse: 634369.6250 - val_loss: 532167.6875 - val_mae: 503.1806 - val_mse: 532167.6875\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 615972.9375 - mae: 514.6331 - mse: 615972.9375 - val_loss: 520076.5625 - val_mae: 497.0835 - val_mse: 520076.5625\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 598558.0625 - mae: 508.0751 - mse: 598558.0625 - val_loss: 508323.6250 - val_mae: 491.1950 - val_mse: 508323.6250\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 582053.2500 - mae: 501.7746 - mse: 582053.2500 - val_loss: 497003.7500 - val_mae: 485.6046 - val_mse: 497003.7500\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 566431.4375 - mae: 495.7773 - mse: 566431.4375 - val_loss: 486164.9375 - val_mae: 480.2193 - val_mse: 486164.9375\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 551780.2500 - mae: 490.0440 - mse: 551780.2500 - val_loss: 475956.2812 - val_mae: 475.1245 - val_mse: 475956.2812\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 538149.3125 - mae: 484.6412 - mse: 538149.3125 - val_loss: 466378.1250 - val_mae: 470.3425 - val_mse: 466378.1250\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 525617.6875 - mae: 479.6753 - mse: 525617.6875 - val_loss: 457612.6250 - val_mae: 465.7758 - val_mse: 457612.6250\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 514193.8438 - mae: 475.1266 - mse: 514193.8438 - val_loss: 449732.7812 - val_mae: 461.4948 - val_mse: 449732.7812\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 503938.9375 - mae: 471.0815 - mse: 503938.9375 - val_loss: 442809.3438 - val_mae: 457.7671 - val_mse: 442809.3438\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 494809.3438 - mae: 467.5077 - mse: 494809.3438 - val_loss: 436841.9375 - val_mae: 454.4450 - val_mse: 436841.9375\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 486765.0625 - mae: 464.3571 - mse: 486765.0625 - val_loss: 431674.5625 - val_mae: 451.6644 - val_mse: 431674.5625\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 479648.2500 - mae: 461.6307 - mse: 479648.2500 - val_loss: 427258.7188 - val_mae: 449.3473 - val_mse: 427258.7188\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 473460.9688 - mae: 459.2935 - mse: 473460.9688 - val_loss: 423640.1250 - val_mae: 447.4177 - val_mse: 423640.1250\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 468000.9062 - mae: 457.3462 - mse: 468000.9062 - val_loss: 420595.0312 - val_mae: 445.6814 - val_mse: 420595.0312\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 463202.5000 - mae: 455.6629 - mse: 463202.5000 - val_loss: 418040.5938 - val_mae: 444.1180 - val_mse: 418040.5938\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 458876.2500 - mae: 454.1272 - mse: 458876.2500 - val_loss: 415901.1562 - val_mae: 442.6914 - val_mse: 415901.1562\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 454963.8438 - mae: 452.6237 - mse: 454963.8438 - val_loss: 414012.3438 - val_mae: 441.3574 - val_mse: 414012.3438\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 451364.1250 - mae: 451.1996 - mse: 451364.1250 - val_loss: 412395.5625 - val_mae: 440.1965 - val_mse: 412395.5625\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 448046.5000 - mae: 449.9548 - mse: 448046.5000 - val_loss: 410963.1250 - val_mae: 439.2779 - val_mse: 410963.1250\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 445139.2500 - mae: 448.9451 - mse: 445139.2500 - val_loss: 409766.1562 - val_mae: 438.4055 - val_mse: 409766.1562\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 442348.7500 - mae: 447.9444 - mse: 442348.7500 - val_loss: 408744.3750 - val_mae: 437.5695 - val_mse: 408744.3750\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 439719.3750 - mae: 446.8849 - mse: 439719.3750 - val_loss: 407820.7188 - val_mae: 436.6940 - val_mse: 407820.7188\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 437189.9062 - mae: 445.7794 - mse: 437189.9062 - val_loss: 407050.9062 - val_mae: 435.8579 - val_mse: 407050.9062\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 434788.8125 - mae: 444.7674 - mse: 434788.8125 - val_loss: 406417.3125 - val_mae: 435.1434 - val_mse: 406417.3125\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 432550.9375 - mae: 443.8453 - mse: 432550.9375 - val_loss: 405910.7500 - val_mae: 434.5219 - val_mse: 405910.7500\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 430395.9375 - mae: 442.9406 - mse: 430395.9375 - val_loss: 405584.4688 - val_mae: 433.8750 - val_mse: 405584.4688\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 428301.0625 - mae: 442.0068 - mse: 428301.0625 - val_loss: 405425.7188 - val_mae: 433.2195 - val_mse: 405425.7188\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 426309.8125 - mae: 441.0843 - mse: 426309.8125 - val_loss: 405515.6875 - val_mae: 432.5610 - val_mse: 405515.6875\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 424355.8750 - mae: 440.1726 - mse: 424355.8750 - val_loss: 405606.6562 - val_mae: 431.8657 - val_mse: 405606.6562\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 422518.0000 - mae: 439.2542 - mse: 422518.0000 - val_loss: 405977.6562 - val_mae: 431.3153 - val_mse: 405977.6562\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 420746.6875 - mae: 438.3258 - mse: 420746.6875 - val_loss: 406477.0938 - val_mae: 430.7540 - val_mse: 406477.0938\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 419025.2500 - mae: 437.3722 - mse: 419025.2500 - val_loss: 407183.5938 - val_mae: 430.2379 - val_mse: 407183.5938\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 417411.3438 - mae: 436.4858 - mse: 417411.3438 - val_loss: 408080.3438 - val_mae: 429.7515 - val_mse: 408080.3438\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 415882.7500 - mae: 435.6195 - mse: 415882.7500 - val_loss: 409152.6250 - val_mae: 429.4289 - val_mse: 409152.6250\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 414432.9688 - mae: 434.7572 - mse: 414432.9688 - val_loss: 410313.0938 - val_mae: 428.9708 - val_mse: 410313.0938\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 413060.5625 - mae: 433.8970 - mse: 413060.5625 - val_loss: 411604.4375 - val_mae: 428.6269 - val_mse: 411604.4375\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 411759.1250 - mae: 433.1047 - mse: 411759.1250 - val_loss: 412842.2500 - val_mae: 428.1949 - val_mse: 412842.2500\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 410515.1875 - mae: 432.3328 - mse: 410515.1875 - val_loss: 414226.0938 - val_mae: 427.8583 - val_mse: 414226.0938\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 409298.8125 - mae: 431.5711 - mse: 409298.8125 - val_loss: 415630.4062 - val_mae: 427.4405 - val_mse: 415630.4062\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 408155.5312 - mae: 430.8498 - mse: 408155.5312 - val_loss: 416888.5312 - val_mae: 427.0173 - val_mse: 416888.5312\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 407038.8125 - mae: 430.1684 - mse: 407038.8125 - val_loss: 418170.8438 - val_mae: 426.5721 - val_mse: 418170.8438\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 405947.4688 - mae: 429.4442 - mse: 405947.4688 - val_loss: 419490.9062 - val_mae: 426.1250 - val_mse: 419490.9062\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 404900.5312 - mae: 428.7289 - mse: 404900.5312 - val_loss: 420784.1562 - val_mae: 425.6411 - val_mse: 420784.1562\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 403917.9375 - mae: 428.0289 - mse: 403917.9375 - val_loss: 422106.5000 - val_mae: 425.2092 - val_mse: 422106.5000\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 403000.9062 - mae: 427.3791 - mse: 403000.9062 - val_loss: 423440.8750 - val_mae: 424.7242 - val_mse: 423440.8750\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 402091.0312 - mae: 426.7119 - mse: 402091.0312 - val_loss: 424746.7812 - val_mae: 424.2712 - val_mse: 424746.7812\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 401195.1250 - mae: 426.0882 - mse: 401195.1250 - val_loss: 426033.0938 - val_mae: 423.8451 - val_mse: 426033.0938\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 400357.0938 - mae: 425.4821 - mse: 400357.0938 - val_loss: 427325.9688 - val_mae: 423.4302 - val_mse: 427325.9688\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 399535.9062 - mae: 424.9168 - mse: 399535.9062 - val_loss: 428610.2500 - val_mae: 423.0684 - val_mse: 428610.2500\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 398711.1875 - mae: 424.3275 - mse: 398711.1875 - val_loss: 429724.9375 - val_mae: 422.7153 - val_mse: 429724.9375\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 397907.1875 - mae: 423.8011 - mse: 397907.1875 - val_loss: 430877.8438 - val_mae: 422.2802 - val_mse: 430877.8438\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 397106.8438 - mae: 423.2423 - mse: 397106.8438 - val_loss: 432045.9062 - val_mae: 421.9661 - val_mse: 432045.9062\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 396332.8750 - mae: 422.7295 - mse: 396332.8750 - val_loss: 433075.0938 - val_mae: 421.5450 - val_mse: 433075.0938\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 395545.1875 - mae: 422.2065 - mse: 395545.1875 - val_loss: 434043.8750 - val_mae: 421.1993 - val_mse: 434043.8750\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 394748.3125 - mae: 421.6820 - mse: 394748.3125 - val_loss: 435038.3750 - val_mae: 420.8860 - val_mse: 435038.3750\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 393974.2500 - mae: 421.1399 - mse: 393974.2500 - val_loss: 436124.8750 - val_mae: 420.5188 - val_mse: 436124.8750\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 393203.6250 - mae: 420.6255 - mse: 393203.6250 - val_loss: 437035.0312 - val_mae: 420.1234 - val_mse: 437035.0312\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 392420.4688 - mae: 420.0709 - mse: 392420.4688 - val_loss: 438206.9062 - val_mae: 419.8377 - val_mse: 438206.9062\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 391563.4688 - mae: 419.4536 - mse: 391563.4688 - val_loss: 439360.1250 - val_mae: 419.4503 - val_mse: 439360.1250\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 390733.5938 - mae: 418.8526 - mse: 390733.5938 - val_loss: 440591.7500 - val_mae: 419.1905 - val_mse: 440591.7500\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 389947.1250 - mae: 418.3121 - mse: 389947.1250 - val_loss: 441742.0312 - val_mae: 418.9780 - val_mse: 441742.0312\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 389154.6250 - mae: 417.7615 - mse: 389154.6250 - val_loss: 442939.7188 - val_mae: 418.6752 - val_mse: 442939.7188\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 388406.5625 - mae: 417.2991 - mse: 388406.5625 - val_loss: 444070.1562 - val_mae: 418.4204 - val_mse: 444070.1562\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 387674.9062 - mae: 416.8160 - mse: 387674.9062 - val_loss: 445061.9375 - val_mae: 418.0960 - val_mse: 445061.9375\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 386964.0312 - mae: 416.3605 - mse: 386964.0312 - val_loss: 446016.6875 - val_mae: 417.7882 - val_mse: 446016.6875\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 386257.5312 - mae: 415.8820 - mse: 386257.5312 - val_loss: 446910.9375 - val_mae: 417.3721 - val_mse: 446910.9375\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 385550.5938 - mae: 415.4006 - mse: 385550.5938 - val_loss: 447831.6562 - val_mae: 417.0347 - val_mse: 447831.6562\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 384876.2188 - mae: 414.9521 - mse: 384876.2188 - val_loss: 448706.8438 - val_mae: 416.6475 - val_mse: 448706.8438\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 384212.5625 - mae: 414.5351 - mse: 384212.5625 - val_loss: 449429.8125 - val_mae: 416.0350 - val_mse: 449429.8125\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 383559.9062 - mae: 414.0626 - mse: 383559.9062 - val_loss: 450052.8750 - val_mae: 415.7073 - val_mse: 450052.8750\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 382897.8125 - mae: 413.6369 - mse: 382897.8125 - val_loss: 450742.5938 - val_mae: 415.3465 - val_mse: 450742.5938\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 382251.1562 - mae: 413.1946 - mse: 382251.1562 - val_loss: 451629.5625 - val_mae: 414.9938 - val_mse: 451629.5625\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 381617.6875 - mae: 412.7884 - mse: 381617.6875 - val_loss: 452368.6250 - val_mae: 414.6109 - val_mse: 452368.6250\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 380993.0938 - mae: 412.3326 - mse: 380993.0938 - val_loss: 452931.7812 - val_mae: 414.4240 - val_mse: 452931.7812\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 380317.7812 - mae: 411.8802 - mse: 380317.7812 - val_loss: 453442.3750 - val_mae: 414.0788 - val_mse: 453442.3750\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 379661.4688 - mae: 411.4192 - mse: 379661.4688 - val_loss: 454050.2188 - val_mae: 413.8143 - val_mse: 454050.2188\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 379000.1875 - mae: 410.9951 - mse: 379000.1875 - val_loss: 454788.3438 - val_mae: 413.3060 - val_mse: 454788.3438\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 378354.6250 - mae: 410.5412 - mse: 378354.6250 - val_loss: 455498.2812 - val_mae: 412.9866 - val_mse: 455498.2812\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 377703.5938 - mae: 410.1404 - mse: 377703.5938 - val_loss: 455897.5312 - val_mae: 412.4748 - val_mse: 455897.5312\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 376963.0938 - mae: 409.5805 - mse: 376963.0938 - val_loss: 456000.6562 - val_mae: 412.1462 - val_mse: 456000.6562\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 376209.2812 - mae: 409.0904 - mse: 376209.2812 - val_loss: 456141.7500 - val_mae: 411.6028 - val_mse: 456141.7500\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 375456.7500 - mae: 408.5661 - mse: 375456.7500 - val_loss: 456481.2500 - val_mae: 411.1500 - val_mse: 456481.2500\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 374708.0938 - mae: 408.0854 - mse: 374708.0938 - val_loss: 456990.2188 - val_mae: 410.6677 - val_mse: 456990.2188\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 373982.6250 - mae: 407.5974 - mse: 373982.6250 - val_loss: 457821.0625 - val_mae: 410.2725 - val_mse: 457821.0625\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 373381.5625 - mae: 407.2388 - mse: 373381.5625 - val_loss: 458200.8438 - val_mae: 409.8374 - val_mse: 458200.8438\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 372644.3750 - mae: 406.7084 - mse: 372644.3750 - val_loss: 457921.2188 - val_mae: 409.4356 - val_mse: 457921.2188\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 371871.6562 - mae: 406.2187 - mse: 371871.6562 - val_loss: 457882.0000 - val_mae: 409.0204 - val_mse: 457882.0000\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 371103.1562 - mae: 405.7195 - mse: 371103.1562 - val_loss: 457815.7500 - val_mae: 408.5798 - val_mse: 457815.7500\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 370411.7188 - mae: 405.2966 - mse: 370411.7188 - val_loss: 457813.9375 - val_mae: 408.1492 - val_mse: 457813.9375\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 369741.4062 - mae: 404.8451 - mse: 369741.4062 - val_loss: 456784.5938 - val_mae: 407.6478 - val_mse: 456784.5938\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 369229.2500 - mae: 404.5229 - mse: 369229.2500 - val_loss: 455527.2188 - val_mae: 407.2857 - val_mse: 455527.2188\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 368496.6250 - mae: 404.0949 - mse: 368496.6250 - val_loss: 456740.3750 - val_mae: 406.7812 - val_mse: 456740.3750\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Training fold 4\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 9ms/step - loss: 2443912.2500 - mae: 1126.5402 - mse: 2443912.2500 - val_loss: 1130693.1250 - val_mae: 817.3197 - val_mse: 1130693.1250\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 874056.8750 - mae: 658.7674 - mse: 874056.8750 - val_loss: 768170.8750 - val_mae: 609.2209 - val_mse: 768170.8750\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 749566.1250 - mae: 576.2582 - mse: 749566.1250 - val_loss: 704285.9375 - val_mae: 572.1313 - val_mse: 704285.9375\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 711788.3125 - mae: 555.4839 - mse: 711788.3125 - val_loss: 675804.2500 - val_mae: 556.1544 - val_mse: 675804.2500\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 685904.2500 - mae: 544.7777 - mse: 685904.2500 - val_loss: 657214.3125 - val_mae: 547.2458 - val_mse: 657214.3125\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 665536.1250 - mae: 536.9963 - mse: 665536.1250 - val_loss: 642851.8125 - val_mae: 540.4876 - val_mse: 642851.8125\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 648399.5625 - mae: 530.6072 - mse: 648399.5625 - val_loss: 630771.6250 - val_mae: 534.7699 - val_mse: 630771.6250\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 633262.0000 - mae: 524.9253 - mse: 633262.0000 - val_loss: 619883.8125 - val_mae: 529.6729 - val_mse: 619883.8125\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 619497.0000 - mae: 519.7738 - mse: 619497.0000 - val_loss: 609837.3125 - val_mae: 524.8381 - val_mse: 609837.3125\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 606727.6250 - mae: 514.8264 - mse: 606727.6250 - val_loss: 600120.1250 - val_mae: 519.9882 - val_mse: 600120.1250\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 594726.0000 - mae: 510.0786 - mse: 594726.0000 - val_loss: 590736.1875 - val_mae: 515.1935 - val_mse: 590736.1875\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 583313.6250 - mae: 505.4612 - mse: 583313.6250 - val_loss: 581565.1875 - val_mae: 510.5529 - val_mse: 581565.1875\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 572453.5625 - mae: 500.9428 - mse: 572453.5625 - val_loss: 572528.8125 - val_mae: 505.9598 - val_mse: 572528.8125\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 562080.6875 - mae: 496.4908 - mse: 562080.6875 - val_loss: 563557.5000 - val_mae: 501.2595 - val_mse: 563557.5000\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 552198.3125 - mae: 492.2516 - mse: 552198.3125 - val_loss: 554929.9375 - val_mae: 496.8529 - val_mse: 554929.9375\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 542854.7500 - mae: 488.2521 - mse: 542854.7500 - val_loss: 546633.1875 - val_mae: 492.6787 - val_mse: 546633.1875\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 534070.3125 - mae: 484.4345 - mse: 534070.3125 - val_loss: 538748.9375 - val_mae: 488.7062 - val_mse: 538748.9375\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 525844.1250 - mae: 480.8737 - mse: 525844.1250 - val_loss: 531294.4375 - val_mae: 485.1485 - val_mse: 531294.4375\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 518208.1875 - mae: 477.6317 - mse: 518208.1875 - val_loss: 524312.3750 - val_mae: 482.0757 - val_mse: 524312.3750\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 511131.4062 - mae: 474.7237 - mse: 511131.4062 - val_loss: 518019.9375 - val_mae: 479.3152 - val_mse: 518019.9375\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 504638.0000 - mae: 472.0132 - mse: 504638.0000 - val_loss: 512290.3438 - val_mae: 476.7943 - val_mse: 512290.3438\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 498707.4688 - mae: 469.5894 - mse: 498707.4688 - val_loss: 507102.8125 - val_mae: 474.4966 - val_mse: 507102.8125\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 493374.9375 - mae: 467.4104 - mse: 493374.9375 - val_loss: 502477.9375 - val_mae: 472.4156 - val_mse: 502477.9375\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 488507.2812 - mae: 465.3955 - mse: 488507.2812 - val_loss: 498410.4688 - val_mae: 470.5722 - val_mse: 498410.4688\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 484149.1250 - mae: 463.6135 - mse: 484149.1250 - val_loss: 494804.9062 - val_mae: 469.0315 - val_mse: 494804.9062\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 480186.8125 - mae: 461.9723 - mse: 480186.8125 - val_loss: 491566.7500 - val_mae: 467.5531 - val_mse: 491566.7500\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 476691.1875 - mae: 460.4918 - mse: 476691.1875 - val_loss: 488777.7188 - val_mae: 466.2212 - val_mse: 488777.7188\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 473433.4062 - mae: 459.0797 - mse: 473433.4062 - val_loss: 486171.7188 - val_mae: 464.8730 - val_mse: 486171.7188\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 470432.8750 - mae: 457.6819 - mse: 470432.8750 - val_loss: 483793.4062 - val_mae: 463.8090 - val_mse: 483793.4062\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 467720.6562 - mae: 456.5119 - mse: 467720.6562 - val_loss: 481727.0938 - val_mae: 462.8608 - val_mse: 481727.0938\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 465318.1562 - mae: 455.4543 - mse: 465318.1562 - val_loss: 479926.6250 - val_mae: 462.0957 - val_mse: 479926.6250\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 463055.6562 - mae: 454.4501 - mse: 463055.6562 - val_loss: 478351.2188 - val_mae: 461.2971 - val_mse: 478351.2188\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 460958.0000 - mae: 453.5031 - mse: 460958.0000 - val_loss: 476980.6562 - val_mae: 460.5019 - val_mse: 476980.6562\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 459053.6875 - mae: 452.5599 - mse: 459053.6875 - val_loss: 475639.4375 - val_mae: 459.7558 - val_mse: 475639.4375\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 457313.3438 - mae: 451.6862 - mse: 457313.3438 - val_loss: 474503.6875 - val_mae: 459.2633 - val_mse: 474503.6875\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 455661.0000 - mae: 450.9612 - mse: 455661.0000 - val_loss: 473489.0625 - val_mae: 458.9328 - val_mse: 473489.0625\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 454234.4688 - mae: 450.3289 - mse: 454234.4688 - val_loss: 472702.7500 - val_mae: 458.5247 - val_mse: 472702.7500\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 452881.8750 - mae: 449.6813 - mse: 452881.8750 - val_loss: 471882.2188 - val_mae: 458.2379 - val_mse: 471882.2188\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 451641.6562 - mae: 449.0723 - mse: 451641.6562 - val_loss: 471223.3438 - val_mae: 457.7918 - val_mse: 471223.3438\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 450471.2500 - mae: 448.4444 - mse: 450471.2500 - val_loss: 470618.5625 - val_mae: 457.4289 - val_mse: 470618.5625\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 449392.3125 - mae: 447.9069 - mse: 449392.3125 - val_loss: 470027.1562 - val_mae: 457.1360 - val_mse: 470027.1562\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 448430.0000 - mae: 447.4795 - mse: 448430.0000 - val_loss: 469556.9688 - val_mae: 456.9303 - val_mse: 469556.9688\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 447509.1875 - mae: 447.0485 - mse: 447509.1875 - val_loss: 469055.8125 - val_mae: 456.7480 - val_mse: 469055.8125\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 446728.4688 - mae: 446.6856 - mse: 446728.4688 - val_loss: 468698.5625 - val_mae: 456.4687 - val_mse: 468698.5625\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 445852.9688 - mae: 446.2508 - mse: 445852.9688 - val_loss: 468291.7812 - val_mae: 456.2126 - val_mse: 468291.7812\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 445138.6250 - mae: 445.8856 - mse: 445138.6250 - val_loss: 467951.9688 - val_mae: 455.9820 - val_mse: 467951.9688\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 444464.2500 - mae: 445.4921 - mse: 444464.2500 - val_loss: 467694.8125 - val_mae: 455.6904 - val_mse: 467694.8125\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 443831.5312 - mae: 445.1093 - mse: 443831.5312 - val_loss: 467480.1250 - val_mae: 455.5104 - val_mse: 467480.1250\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 443154.3125 - mae: 444.7421 - mse: 443154.3125 - val_loss: 467232.9375 - val_mae: 455.3393 - val_mse: 467232.9375\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 442661.8438 - mae: 444.4529 - mse: 442661.8438 - val_loss: 467019.3750 - val_mae: 455.1657 - val_mse: 467019.3750\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 442157.2188 - mae: 444.1754 - mse: 442157.2188 - val_loss: 466790.5938 - val_mae: 455.0026 - val_mse: 466790.5938\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 441696.2812 - mae: 443.9252 - mse: 441696.2812 - val_loss: 466638.6562 - val_mae: 454.8346 - val_mse: 466638.6562\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 441243.5625 - mae: 443.6656 - mse: 441243.5625 - val_loss: 466545.6250 - val_mae: 454.7429 - val_mse: 466545.6250\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 440822.5312 - mae: 443.4032 - mse: 440822.5312 - val_loss: 466333.7188 - val_mae: 454.5642 - val_mse: 466333.7188\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 440479.4375 - mae: 443.2192 - mse: 440479.4375 - val_loss: 466096.0000 - val_mae: 454.4090 - val_mse: 466096.0000\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 440105.6875 - mae: 442.9751 - mse: 440105.6875 - val_loss: 465920.9062 - val_mae: 454.2503 - val_mse: 465920.9062\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439806.6250 - mae: 442.8255 - mse: 439806.6250 - val_loss: 465700.0000 - val_mae: 454.0571 - val_mse: 465700.0000\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439496.2188 - mae: 442.5894 - mse: 439496.2188 - val_loss: 465493.2188 - val_mae: 453.9679 - val_mse: 465493.2188\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439199.7188 - mae: 442.3657 - mse: 439199.7188 - val_loss: 465264.4688 - val_mae: 453.7896 - val_mse: 465264.4688\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438894.3750 - mae: 442.1947 - mse: 438894.3750 - val_loss: 465064.2188 - val_mae: 453.6324 - val_mse: 465064.2188\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 438593.5625 - mae: 441.9424 - mse: 438593.5625 - val_loss: 464773.1875 - val_mae: 453.3958 - val_mse: 464773.1875\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438300.8750 - mae: 441.7332 - mse: 438300.8750 - val_loss: 464597.9062 - val_mae: 453.3058 - val_mse: 464597.9062\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438046.6250 - mae: 441.5640 - mse: 438046.6250 - val_loss: 464416.8125 - val_mae: 453.1263 - val_mse: 464416.8125\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 437794.3750 - mae: 441.3694 - mse: 437794.3750 - val_loss: 464159.5000 - val_mae: 452.9666 - val_mse: 464159.5000\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 437552.9688 - mae: 441.2146 - mse: 437552.9688 - val_loss: 464015.8125 - val_mae: 452.7873 - val_mse: 464015.8125\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 437305.1875 - mae: 441.0060 - mse: 437305.1875 - val_loss: 463799.7812 - val_mae: 452.6205 - val_mse: 463799.7812\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 437108.4375 - mae: 440.9076 - mse: 437108.4375 - val_loss: 463598.5938 - val_mae: 452.4870 - val_mse: 463598.5938\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436889.0938 - mae: 440.7507 - mse: 436889.0938 - val_loss: 463379.1562 - val_mae: 452.3517 - val_mse: 463379.1562\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436691.2812 - mae: 440.6200 - mse: 436691.2812 - val_loss: 463280.2812 - val_mae: 452.0426 - val_mse: 463280.2812\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 436469.7812 - mae: 440.4477 - mse: 436469.7812 - val_loss: 463073.9375 - val_mae: 451.9299 - val_mse: 463073.9375\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436251.7812 - mae: 440.2728 - mse: 436251.7812 - val_loss: 462967.4688 - val_mae: 451.8304 - val_mse: 462967.4688\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 436072.2188 - mae: 440.1816 - mse: 436072.2188 - val_loss: 462841.5938 - val_mae: 451.6560 - val_mse: 462841.5938\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 435904.6250 - mae: 440.0486 - mse: 435904.6250 - val_loss: 462611.3750 - val_mae: 451.5618 - val_mse: 462611.3750\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 435728.1250 - mae: 439.9756 - mse: 435728.1250 - val_loss: 462545.2500 - val_mae: 451.4712 - val_mse: 462545.2500\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 435558.2812 - mae: 439.8408 - mse: 435558.2812 - val_loss: 462309.4062 - val_mae: 451.3456 - val_mse: 462309.4062\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 435392.4688 - mae: 439.7329 - mse: 435392.4688 - val_loss: 462216.5312 - val_mae: 451.2505 - val_mse: 462216.5312\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 435195.8750 - mae: 439.5746 - mse: 435195.8750 - val_loss: 462104.4062 - val_mae: 451.1396 - val_mse: 462104.4062\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 435017.8750 - mae: 439.4969 - mse: 435017.8750 - val_loss: 461953.8125 - val_mae: 451.0234 - val_mse: 461953.8125\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 434855.6250 - mae: 439.3593 - mse: 434855.6250 - val_loss: 461771.9062 - val_mae: 450.8890 - val_mse: 461771.9062\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 434670.5312 - mae: 439.2644 - mse: 434670.5312 - val_loss: 461785.6562 - val_mae: 450.7101 - val_mse: 461785.6562\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 434489.6562 - mae: 439.1075 - mse: 434489.6562 - val_loss: 461671.8750 - val_mae: 450.6085 - val_mse: 461671.8750\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 434340.9375 - mae: 439.0416 - mse: 434340.9375 - val_loss: 461584.9688 - val_mae: 450.5527 - val_mse: 461584.9688\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 434176.3438 - mae: 438.8861 - mse: 434176.3438 - val_loss: 461430.2500 - val_mae: 450.4377 - val_mse: 461430.2500\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433994.3438 - mae: 438.7769 - mse: 433994.3438 - val_loss: 461342.6250 - val_mae: 450.3661 - val_mse: 461342.6250\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433901.9062 - mae: 438.7083 - mse: 433901.9062 - val_loss: 461238.2500 - val_mae: 450.3720 - val_mse: 461238.2500\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433680.4688 - mae: 438.5491 - mse: 433680.4688 - val_loss: 461096.9375 - val_mae: 450.2708 - val_mse: 461096.9375\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433519.7812 - mae: 438.4457 - mse: 433519.7812 - val_loss: 460849.2500 - val_mae: 450.2317 - val_mse: 460849.2500\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 433399.5625 - mae: 438.4149 - mse: 433399.5625 - val_loss: 460698.9062 - val_mae: 450.1911 - val_mse: 460698.9062\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433245.8750 - mae: 438.3208 - mse: 433245.8750 - val_loss: 460526.4688 - val_mae: 450.1426 - val_mse: 460526.4688\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 433097.7812 - mae: 438.2169 - mse: 433097.7812 - val_loss: 460253.4375 - val_mae: 450.0416 - val_mse: 460253.4375\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 432942.8125 - mae: 438.1118 - mse: 432942.8125 - val_loss: 460056.8750 - val_mae: 449.9420 - val_mse: 460056.8750\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 432857.1250 - mae: 438.0545 - mse: 432857.1250 - val_loss: 459952.0625 - val_mae: 449.9501 - val_mse: 459952.0625\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 432595.4062 - mae: 437.9062 - mse: 432595.4062 - val_loss: 459705.7812 - val_mae: 449.9101 - val_mse: 459705.7812\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 432359.5938 - mae: 437.7893 - mse: 432359.5938 - val_loss: 459529.3125 - val_mae: 449.7619 - val_mse: 459529.3125\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 432247.6562 - mae: 437.7013 - mse: 432247.6562 - val_loss: 459596.8438 - val_mae: 449.6713 - val_mse: 459596.8438\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 431901.0625 - mae: 437.4927 - mse: 431901.0625 - val_loss: 459211.9062 - val_mae: 449.4804 - val_mse: 459211.9062\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 431570.7812 - mae: 437.3431 - mse: 431570.7812 - val_loss: 459028.8438 - val_mae: 449.3329 - val_mse: 459028.8438\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 431379.8750 - mae: 437.2361 - mse: 431379.8750 - val_loss: 458757.2500 - val_mae: 449.2413 - val_mse: 458757.2500\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 431040.0000 - mae: 437.0747 - mse: 431040.0000 - val_loss: 458485.0938 - val_mae: 449.1194 - val_mse: 458485.0938\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 430754.9062 - mae: 436.9424 - mse: 430754.9062 - val_loss: 458052.5625 - val_mae: 448.9870 - val_mse: 458052.5625\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "Training fold 5\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 9ms/step - loss: 2624135.5000 - mae: 1170.4108 - mse: 2624135.5000 - val_loss: 1198742.6250 - val_mae: 859.8882 - val_mse: 1198742.6250\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 941564.5000 - mae: 698.5248 - mse: 941564.5000 - val_loss: 748766.6875 - val_mae: 628.1661 - val_mse: 748766.6875\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 764324.4375 - mae: 588.0588 - mse: 764324.4375 - val_loss: 673043.4375 - val_mae: 574.1316 - val_mse: 673043.4375\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 719857.6875 - mae: 558.9747 - mse: 719857.6875 - val_loss: 643163.5000 - val_mae: 554.9227 - val_mse: 643163.5000\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 688738.9375 - mae: 544.5311 - mse: 688738.9375 - val_loss: 618027.3125 - val_mae: 541.1211 - val_mse: 618027.3125\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 660967.0625 - mae: 533.1147 - mse: 660967.0625 - val_loss: 594790.1250 - val_mae: 529.4285 - val_mse: 594790.1250\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 635323.9375 - mae: 522.5922 - mse: 635323.9375 - val_loss: 572851.8750 - val_mae: 518.3227 - val_mse: 572851.8750\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 610831.1875 - mae: 512.5042 - mse: 610831.1875 - val_loss: 552245.3750 - val_mae: 507.4620 - val_mse: 552245.3750\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 587877.8125 - mae: 503.2497 - mse: 587877.8125 - val_loss: 533305.5000 - val_mae: 497.5583 - val_mse: 533305.5000\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 566570.8125 - mae: 494.7574 - mse: 566570.8125 - val_loss: 516078.0000 - val_mae: 488.4525 - val_mse: 516078.0000\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 547138.1875 - mae: 487.1169 - mse: 547138.1875 - val_loss: 500562.1875 - val_mae: 480.2984 - val_mse: 500562.1875\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 529782.1875 - mae: 480.3485 - mse: 529782.1875 - val_loss: 486834.6250 - val_mae: 473.3544 - val_mse: 486834.6250\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 514512.8125 - mae: 474.4629 - mse: 514512.8125 - val_loss: 474810.4688 - val_mae: 467.5136 - val_mse: 474810.4688\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 501334.2812 - mae: 469.4560 - mse: 501334.2812 - val_loss: 464433.5312 - val_mae: 462.4537 - val_mse: 464433.5312\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 490164.2812 - mae: 465.2161 - mse: 490164.2812 - val_loss: 455567.8125 - val_mae: 457.9370 - val_mse: 455567.8125\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 480858.5625 - mae: 461.6712 - mse: 480858.5625 - val_loss: 448097.5312 - val_mae: 454.2091 - val_mse: 448097.5312\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 473155.0938 - mae: 458.7841 - mse: 473155.0938 - val_loss: 441894.8125 - val_mae: 451.1546 - val_mse: 441894.8125\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 466797.5625 - mae: 456.4253 - mse: 466797.5625 - val_loss: 436662.9375 - val_mae: 448.5047 - val_mse: 436662.9375\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 461502.3750 - mae: 454.4570 - mse: 461502.3750 - val_loss: 432279.0312 - val_mae: 446.2380 - val_mse: 432279.0312\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 457046.2500 - mae: 452.8347 - mse: 457046.2500 - val_loss: 428521.2500 - val_mae: 444.2874 - val_mse: 428521.2500\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 453207.5625 - mae: 451.4932 - mse: 453207.5625 - val_loss: 425316.8438 - val_mae: 442.7151 - val_mse: 425316.8438\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 449846.2500 - mae: 450.3195 - mse: 449846.2500 - val_loss: 422457.7500 - val_mae: 441.1793 - val_mse: 422457.7500\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 446827.5000 - mae: 449.2476 - mse: 446827.5000 - val_loss: 419911.4375 - val_mae: 439.9250 - val_mse: 419911.4375\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 444094.0625 - mae: 448.3020 - mse: 444094.0625 - val_loss: 417547.8125 - val_mae: 438.6336 - val_mse: 417547.8125\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 441555.1562 - mae: 447.3538 - mse: 441555.1562 - val_loss: 415431.0938 - val_mae: 437.6995 - val_mse: 415431.0938\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439207.0000 - mae: 446.4800 - mse: 439207.0000 - val_loss: 413369.5000 - val_mae: 436.5586 - val_mse: 413369.5000\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436950.5938 - mae: 445.5962 - mse: 436950.5938 - val_loss: 411785.7812 - val_mae: 435.8131 - val_mse: 411785.7812\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 434879.5625 - mae: 444.7846 - mse: 434879.5625 - val_loss: 409685.7500 - val_mae: 434.4749 - val_mse: 409685.7500\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 432779.7188 - mae: 443.8899 - mse: 432779.7188 - val_loss: 407890.9375 - val_mae: 433.4642 - val_mse: 407890.9375\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 430809.0000 - mae: 442.9960 - mse: 430809.0000 - val_loss: 405996.0625 - val_mae: 432.2461 - val_mse: 405996.0625\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 428889.2188 - mae: 442.1196 - mse: 428889.2188 - val_loss: 404329.0312 - val_mae: 431.3489 - val_mse: 404329.0312\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 427042.7500 - mae: 441.2610 - mse: 427042.7500 - val_loss: 402695.6250 - val_mae: 430.3043 - val_mse: 402695.6250\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 425212.2812 - mae: 440.3389 - mse: 425212.2812 - val_loss: 401126.8125 - val_mae: 429.3932 - val_mse: 401126.8125\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 423440.6250 - mae: 439.4332 - mse: 423440.6250 - val_loss: 399446.6875 - val_mae: 428.3647 - val_mse: 399446.6875\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 421627.0625 - mae: 438.5099 - mse: 421627.0625 - val_loss: 397784.7500 - val_mae: 427.4836 - val_mse: 397784.7500\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 419926.7500 - mae: 437.6187 - mse: 419926.7500 - val_loss: 396009.3438 - val_mae: 426.4077 - val_mse: 396009.3438\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 418236.4062 - mae: 436.6948 - mse: 418236.4062 - val_loss: 394442.6562 - val_mae: 425.4473 - val_mse: 394442.6562\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 416648.0938 - mae: 435.7786 - mse: 416648.0938 - val_loss: 392641.7812 - val_mae: 424.2794 - val_mse: 392641.7812\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 415058.1250 - mae: 434.8782 - mse: 415058.1250 - val_loss: 390891.1250 - val_mae: 423.2604 - val_mse: 390891.1250\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 413538.7188 - mae: 433.9802 - mse: 413538.7188 - val_loss: 389271.0938 - val_mae: 422.2607 - val_mse: 389271.0938\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 412070.6562 - mae: 433.1208 - mse: 412070.6562 - val_loss: 387821.0312 - val_mae: 421.3843 - val_mse: 387821.0312\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 410664.3125 - mae: 432.2463 - mse: 410664.3125 - val_loss: 386412.0938 - val_mae: 420.5190 - val_mse: 386412.0938\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 409275.8438 - mae: 431.3664 - mse: 409275.8438 - val_loss: 385008.3750 - val_mae: 419.6487 - val_mse: 385008.3750\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 407974.3438 - mae: 430.5171 - mse: 407974.3438 - val_loss: 383637.4375 - val_mae: 418.7201 - val_mse: 383637.4375\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 406675.2188 - mae: 429.6866 - mse: 406675.2188 - val_loss: 382405.7812 - val_mae: 417.8735 - val_mse: 382405.7812\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 405496.9688 - mae: 428.9480 - mse: 405496.9688 - val_loss: 381242.5000 - val_mae: 417.0817 - val_mse: 381242.5000\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 404277.0000 - mae: 428.2359 - mse: 404277.0000 - val_loss: 380069.0625 - val_mae: 416.2617 - val_mse: 380069.0625\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 403138.6250 - mae: 427.4987 - mse: 403138.6250 - val_loss: 378957.6250 - val_mae: 415.5089 - val_mse: 378957.6250\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 401980.9688 - mae: 426.8010 - mse: 401980.9688 - val_loss: 377830.6562 - val_mae: 414.7655 - val_mse: 377830.6562\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 400895.0312 - mae: 426.1144 - mse: 400895.0312 - val_loss: 376818.7812 - val_mae: 414.1177 - val_mse: 376818.7812\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 399810.7188 - mae: 425.4439 - mse: 399810.7188 - val_loss: 375667.2500 - val_mae: 413.3347 - val_mse: 375667.2500\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 398765.6562 - mae: 424.7442 - mse: 398765.6562 - val_loss: 374716.5312 - val_mae: 412.7088 - val_mse: 374716.5312\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 397738.4062 - mae: 424.0700 - mse: 397738.4062 - val_loss: 373672.2500 - val_mae: 412.0117 - val_mse: 373672.2500\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 396768.8750 - mae: 423.4386 - mse: 396768.8750 - val_loss: 372763.5000 - val_mae: 411.3853 - val_mse: 372763.5000\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 395783.3125 - mae: 422.8439 - mse: 395783.3125 - val_loss: 371885.9062 - val_mae: 410.7614 - val_mse: 371885.9062\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 394840.4062 - mae: 422.2313 - mse: 394840.4062 - val_loss: 371016.6250 - val_mae: 410.1663 - val_mse: 371016.6250\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 393861.1562 - mae: 421.6210 - mse: 393861.1562 - val_loss: 370104.8750 - val_mae: 409.5479 - val_mse: 370104.8750\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 392936.8125 - mae: 421.0000 - mse: 392936.8125 - val_loss: 369264.9688 - val_mae: 408.9176 - val_mse: 369264.9688\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 392013.0312 - mae: 420.4052 - mse: 392013.0312 - val_loss: 368288.6562 - val_mae: 408.2169 - val_mse: 368288.6562\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 391099.4062 - mae: 419.8037 - mse: 391099.4062 - val_loss: 367404.2500 - val_mae: 407.5742 - val_mse: 367404.2500\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 390143.0312 - mae: 419.2199 - mse: 390143.0312 - val_loss: 366687.6875 - val_mae: 407.1356 - val_mse: 366687.6875\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 4ms/step - loss: 389230.0000 - mae: 418.6623 - mse: 389230.0000 - val_loss: 365827.3438 - val_mae: 406.4854 - val_mse: 365827.3438\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 4ms/step - loss: 388272.4062 - mae: 418.0634 - mse: 388272.4062 - val_loss: 364884.1875 - val_mae: 405.8344 - val_mse: 364884.1875\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 387351.3438 - mae: 417.4899 - mse: 387351.3438 - val_loss: 364103.6562 - val_mae: 405.2993 - val_mse: 364103.6562\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 386402.9375 - mae: 416.9328 - mse: 386402.9375 - val_loss: 363012.7500 - val_mae: 404.5340 - val_mse: 363012.7500\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 385466.1250 - mae: 416.3462 - mse: 385466.1250 - val_loss: 362135.2188 - val_mae: 403.8923 - val_mse: 362135.2188\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 384489.1562 - mae: 415.7654 - mse: 384489.1562 - val_loss: 361141.1562 - val_mae: 403.1799 - val_mse: 361141.1562\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 383527.4375 - mae: 415.1695 - mse: 383527.4375 - val_loss: 360214.5312 - val_mae: 402.5210 - val_mse: 360214.5312\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 382551.1250 - mae: 414.5763 - mse: 382551.1250 - val_loss: 359147.8750 - val_mae: 401.7761 - val_mse: 359147.8750\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 381584.8125 - mae: 413.9758 - mse: 381584.8125 - val_loss: 358305.3438 - val_mae: 401.1827 - val_mse: 358305.3438\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 380616.8750 - mae: 413.3926 - mse: 380616.8750 - val_loss: 357358.3125 - val_mae: 400.5146 - val_mse: 357358.3125\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 379642.4688 - mae: 412.8155 - mse: 379642.4688 - val_loss: 356482.4688 - val_mae: 399.8951 - val_mse: 356482.4688\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 378633.4375 - mae: 412.2242 - mse: 378633.4375 - val_loss: 355486.9062 - val_mae: 399.1992 - val_mse: 355486.9062\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 377633.0000 - mae: 411.6178 - mse: 377633.0000 - val_loss: 354576.2812 - val_mae: 398.5907 - val_mse: 354576.2812\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 376641.6250 - mae: 411.0542 - mse: 376641.6250 - val_loss: 353375.0938 - val_mae: 397.7581 - val_mse: 353375.0938\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 375633.5938 - mae: 410.4450 - mse: 375633.5938 - val_loss: 352402.8750 - val_mae: 397.0826 - val_mse: 352402.8750\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 374587.0938 - mae: 409.8563 - mse: 374587.0938 - val_loss: 351328.9688 - val_mae: 396.3377 - val_mse: 351328.9688\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 373562.4688 - mae: 409.2644 - mse: 373562.4688 - val_loss: 350369.0625 - val_mae: 395.7263 - val_mse: 350369.0625\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 372569.5938 - mae: 408.7044 - mse: 372569.5938 - val_loss: 349280.9375 - val_mae: 395.0068 - val_mse: 349280.9375\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 371556.4375 - mae: 408.1172 - mse: 371556.4375 - val_loss: 348450.4062 - val_mae: 394.4911 - val_mse: 348450.4062\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 370550.1875 - mae: 407.5555 - mse: 370550.1875 - val_loss: 347348.8750 - val_mae: 393.7726 - val_mse: 347348.8750\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 369529.3750 - mae: 406.9547 - mse: 369529.3750 - val_loss: 346536.5625 - val_mae: 393.2407 - val_mse: 346536.5625\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 368508.9688 - mae: 406.3715 - mse: 368508.9688 - val_loss: 345319.5312 - val_mae: 392.4259 - val_mse: 345319.5312\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 367460.0625 - mae: 405.7426 - mse: 367460.0625 - val_loss: 344418.0625 - val_mae: 391.8310 - val_mse: 344418.0625\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 366419.0312 - mae: 405.1086 - mse: 366419.0312 - val_loss: 343437.5938 - val_mae: 391.0608 - val_mse: 343437.5938\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 365366.0000 - mae: 404.4575 - mse: 365366.0000 - val_loss: 342534.4062 - val_mae: 390.4746 - val_mse: 342534.4062\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 364302.5938 - mae: 403.8383 - mse: 364302.5938 - val_loss: 341537.6250 - val_mae: 389.7680 - val_mse: 341537.6250\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 363259.5625 - mae: 403.2111 - mse: 363259.5625 - val_loss: 340734.4062 - val_mae: 389.3136 - val_mse: 340734.4062\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 362197.2188 - mae: 402.6240 - mse: 362197.2188 - val_loss: 339615.3750 - val_mae: 388.5788 - val_mse: 339615.3750\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 361117.4375 - mae: 401.9868 - mse: 361117.4375 - val_loss: 338922.0625 - val_mae: 388.1158 - val_mse: 338922.0625\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 360026.5312 - mae: 401.3543 - mse: 360026.5312 - val_loss: 337641.7188 - val_mae: 387.2536 - val_mse: 337641.7188\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 358901.9688 - mae: 400.6639 - mse: 358901.9688 - val_loss: 336636.0000 - val_mae: 386.5742 - val_mse: 336636.0000\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 357796.0312 - mae: 400.0131 - mse: 357796.0312 - val_loss: 335379.7188 - val_mae: 385.6873 - val_mse: 335379.7188\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 356722.1250 - mae: 399.3789 - mse: 356722.1250 - val_loss: 334534.0938 - val_mae: 385.1679 - val_mse: 334534.0938\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 355665.4375 - mae: 398.7627 - mse: 355665.4375 - val_loss: 333352.6250 - val_mae: 384.3398 - val_mse: 333352.6250\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 354600.7500 - mae: 398.1166 - mse: 354600.7500 - val_loss: 332535.5000 - val_mae: 383.8565 - val_mse: 332535.5000\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 353534.5312 - mae: 397.4867 - mse: 353534.5312 - val_loss: 331402.8750 - val_mae: 383.1245 - val_mse: 331402.8750\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 352482.2188 - mae: 396.8554 - mse: 352482.2188 - val_loss: 330635.3125 - val_mae: 382.6513 - val_mse: 330635.3125\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 351426.0625 - mae: 396.2382 - mse: 351426.0625 - val_loss: 329374.3750 - val_mae: 381.8369 - val_mse: 329374.3750\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 350389.9062 - mae: 395.6145 - mse: 350389.9062 - val_loss: 328553.2188 - val_mae: 381.3182 - val_mse: 328553.2188\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Training fold 6\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 3s 9ms/step - loss: 2513176.0000 - mae: 1142.5323 - mse: 2513176.0000 - val_loss: 1414412.5000 - val_mae: 788.5374 - val_mse: 1414412.5000\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 925015.0625 - mae: 673.2801 - mse: 925015.0625 - val_loss: 1403078.0000 - val_mae: 602.3519 - val_mse: 1403078.0000\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 779827.8125 - mae: 583.1694 - mse: 779827.8125 - val_loss: 1364105.2500 - val_mae: 566.7786 - val_mse: 1364105.2500\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 738485.4375 - mae: 558.0610 - mse: 738485.4375 - val_loss: 1293622.5000 - val_mae: 551.4855 - val_mse: 1293622.5000\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 712384.8125 - mae: 546.1133 - mse: 712384.8125 - val_loss: 1221412.3750 - val_mae: 543.5267 - val_mse: 1221412.3750\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 692007.3125 - mae: 538.3057 - mse: 692007.3125 - val_loss: 1154386.0000 - val_mae: 537.1620 - val_mse: 1154386.0000\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 675013.3125 - mae: 532.4138 - mse: 675013.3125 - val_loss: 1091992.3750 - val_mae: 531.8474 - val_mse: 1091992.3750\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 660021.2500 - mae: 527.2817 - mse: 660021.2500 - val_loss: 1034528.0625 - val_mae: 527.0669 - val_mse: 1034528.0625\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 646445.5625 - mae: 522.7629 - mse: 646445.5625 - val_loss: 981629.5625 - val_mae: 522.8645 - val_mse: 981629.5625\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 633938.8125 - mae: 518.6791 - mse: 633938.8125 - val_loss: 932639.8125 - val_mae: 518.8761 - val_mse: 932639.8125\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 622215.8750 - mae: 514.8510 - mse: 622215.8750 - val_loss: 887255.7500 - val_mae: 515.0077 - val_mse: 887255.7500\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 611105.5625 - mae: 511.2061 - mse: 611105.5625 - val_loss: 845282.6250 - val_mae: 511.1664 - val_mse: 845282.6250\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 600514.6250 - mae: 507.7150 - mse: 600514.6250 - val_loss: 806388.4375 - val_mae: 507.3255 - val_mse: 806388.4375\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 590366.5000 - mae: 504.2392 - mse: 590366.5000 - val_loss: 770558.6875 - val_mae: 503.7180 - val_mse: 770558.6875\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 580623.1250 - mae: 500.8547 - mse: 580623.1250 - val_loss: 737444.6875 - val_mae: 500.0887 - val_mse: 737444.6875\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 571251.3125 - mae: 497.4870 - mse: 571251.3125 - val_loss: 706975.3750 - val_mae: 496.7283 - val_mse: 706975.3750\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 562279.5000 - mae: 494.2866 - mse: 562279.5000 - val_loss: 679086.1250 - val_mae: 493.3282 - val_mse: 679086.1250\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 553667.5625 - mae: 491.2103 - mse: 553667.5625 - val_loss: 653691.6250 - val_mae: 489.9612 - val_mse: 653691.6250\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 545447.0625 - mae: 488.1922 - mse: 545447.0625 - val_loss: 630893.1875 - val_mae: 486.6180 - val_mse: 630893.1875\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 537642.3125 - mae: 485.2630 - mse: 537642.3125 - val_loss: 610482.0625 - val_mae: 483.3395 - val_mse: 610482.0625\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 530297.4375 - mae: 482.4885 - mse: 530297.4375 - val_loss: 592520.9375 - val_mae: 480.2226 - val_mse: 592520.9375\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 523368.2188 - mae: 479.8899 - mse: 523368.2188 - val_loss: 576938.9375 - val_mae: 477.4879 - val_mse: 576938.9375\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 516898.2188 - mae: 477.3975 - mse: 516898.2188 - val_loss: 563594.7500 - val_mae: 474.8936 - val_mse: 563594.7500\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 510930.2812 - mae: 475.0890 - mse: 510930.2812 - val_loss: 552294.6250 - val_mae: 472.5426 - val_mse: 552294.6250\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 505448.2812 - mae: 472.9391 - mse: 505448.2812 - val_loss: 542809.0625 - val_mae: 470.2958 - val_mse: 542809.0625\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 500431.7500 - mae: 470.9533 - mse: 500431.7500 - val_loss: 535071.0625 - val_mae: 468.3301 - val_mse: 535071.0625\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 495838.0625 - mae: 469.1232 - mse: 495838.0625 - val_loss: 528191.1250 - val_mae: 466.5554 - val_mse: 528191.1250\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 491681.5000 - mae: 467.5317 - mse: 491681.5000 - val_loss: 522213.9375 - val_mae: 465.0268 - val_mse: 522213.9375\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 487886.8125 - mae: 466.0519 - mse: 487886.8125 - val_loss: 516899.9062 - val_mae: 463.6451 - val_mse: 516899.9062\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 484461.1562 - mae: 464.7127 - mse: 484461.1562 - val_loss: 512185.8750 - val_mae: 462.5385 - val_mse: 512185.8750\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 481348.0625 - mae: 463.5205 - mse: 481348.0625 - val_loss: 508066.8438 - val_mae: 461.6342 - val_mse: 508066.8438\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 478558.4688 - mae: 462.4984 - mse: 478558.4688 - val_loss: 504184.2812 - val_mae: 460.7702 - val_mse: 504184.2812\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 476010.5000 - mae: 461.5789 - mse: 476010.5000 - val_loss: 500625.6875 - val_mae: 460.0760 - val_mse: 500625.6875\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 473697.3438 - mae: 460.7787 - mse: 473697.3438 - val_loss: 497421.1562 - val_mae: 459.4363 - val_mse: 497421.1562\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 471556.7500 - mae: 459.9803 - mse: 471556.7500 - val_loss: 494305.3750 - val_mae: 458.8137 - val_mse: 494305.3750\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 469619.0000 - mae: 459.3191 - mse: 469619.0000 - val_loss: 491546.7812 - val_mae: 458.3214 - val_mse: 491546.7812\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 467852.0312 - mae: 458.7394 - mse: 467852.0312 - val_loss: 488906.6562 - val_mae: 457.9171 - val_mse: 488906.6562\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 466289.5625 - mae: 458.2808 - mse: 466289.5625 - val_loss: 486415.3125 - val_mae: 457.5558 - val_mse: 486415.3125\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 464821.7500 - mae: 457.8421 - mse: 464821.7500 - val_loss: 484044.8438 - val_mae: 457.2048 - val_mse: 484044.8438\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 463492.5000 - mae: 457.4995 - mse: 463492.5000 - val_loss: 481798.9375 - val_mae: 456.8757 - val_mse: 481798.9375\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 462237.6562 - mae: 457.1291 - mse: 462237.6562 - val_loss: 479682.1875 - val_mae: 456.5401 - val_mse: 479682.1875\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 461078.4375 - mae: 456.8167 - mse: 461078.4375 - val_loss: 477711.9688 - val_mae: 456.2059 - val_mse: 477711.9688\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 459980.1250 - mae: 456.4701 - mse: 459980.1250 - val_loss: 475839.7812 - val_mae: 455.8478 - val_mse: 475839.7812\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 458955.5000 - mae: 456.1642 - mse: 458955.5000 - val_loss: 474028.1250 - val_mae: 455.4798 - val_mse: 474028.1250\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 457942.0625 - mae: 455.7649 - mse: 457942.0625 - val_loss: 472397.6250 - val_mae: 455.1065 - val_mse: 472397.6250\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 456981.8750 - mae: 455.3759 - mse: 456981.8750 - val_loss: 470738.5312 - val_mae: 454.7576 - val_mse: 470738.5312\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 456034.6562 - mae: 454.9870 - mse: 456034.6562 - val_loss: 469249.3125 - val_mae: 454.4157 - val_mse: 469249.3125\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 455193.0938 - mae: 454.7097 - mse: 455193.0938 - val_loss: 467965.1875 - val_mae: 454.1688 - val_mse: 467965.1875\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 454415.1250 - mae: 454.4335 - mse: 454415.1250 - val_loss: 466591.9375 - val_mae: 453.8765 - val_mse: 466591.9375\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 453678.3125 - mae: 454.1849 - mse: 453678.3125 - val_loss: 465311.6875 - val_mae: 453.6009 - val_mse: 465311.6875\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 452948.6562 - mae: 453.8920 - mse: 452948.6562 - val_loss: 464045.1875 - val_mae: 453.3128 - val_mse: 464045.1875\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 452286.0312 - mae: 453.6636 - mse: 452286.0312 - val_loss: 462733.5000 - val_mae: 452.9795 - val_mse: 462733.5000\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 451584.6875 - mae: 453.3560 - mse: 451584.6875 - val_loss: 461717.7188 - val_mae: 452.7018 - val_mse: 461717.7188\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 450972.6562 - mae: 453.0974 - mse: 450972.6562 - val_loss: 460454.8438 - val_mae: 452.3521 - val_mse: 460454.8438\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 450321.7500 - mae: 452.7815 - mse: 450321.7500 - val_loss: 459627.3125 - val_mae: 452.0800 - val_mse: 459627.3125\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 449764.5312 - mae: 452.5016 - mse: 449764.5312 - val_loss: 458539.7188 - val_mae: 451.7520 - val_mse: 458539.7188\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 449157.0312 - mae: 452.1991 - mse: 449157.0312 - val_loss: 457556.6562 - val_mae: 451.4731 - val_mse: 457556.6562\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 448614.8750 - mae: 451.9352 - mse: 448614.8750 - val_loss: 456664.2812 - val_mae: 451.2039 - val_mse: 456664.2812\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 448062.2812 - mae: 451.6245 - mse: 448062.2812 - val_loss: 455737.1875 - val_mae: 450.9498 - val_mse: 455737.1875\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 447548.5938 - mae: 451.3477 - mse: 447548.5938 - val_loss: 454976.8125 - val_mae: 450.7439 - val_mse: 454976.8125\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 447041.4375 - mae: 451.0364 - mse: 447041.4375 - val_loss: 454163.0938 - val_mae: 450.4870 - val_mse: 454163.0938\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 446588.3125 - mae: 450.7671 - mse: 446588.3125 - val_loss: 453396.5000 - val_mae: 450.1951 - val_mse: 453396.5000\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 446123.8750 - mae: 450.4480 - mse: 446123.8750 - val_loss: 452648.0000 - val_mae: 449.9649 - val_mse: 452648.0000\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 445691.4688 - mae: 450.1840 - mse: 445691.4688 - val_loss: 452017.4375 - val_mae: 449.7502 - val_mse: 452017.4375\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 445249.1250 - mae: 449.8892 - mse: 445249.1250 - val_loss: 451408.6562 - val_mae: 449.5863 - val_mse: 451408.6562\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 444872.8438 - mae: 449.6557 - mse: 444872.8438 - val_loss: 450729.3750 - val_mae: 449.3523 - val_mse: 450729.3750\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 444458.6875 - mae: 449.3536 - mse: 444458.6875 - val_loss: 450188.6250 - val_mae: 449.1759 - val_mse: 450188.6250\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 444094.1562 - mae: 449.0961 - mse: 444094.1562 - val_loss: 449684.0000 - val_mae: 448.9884 - val_mse: 449684.0000\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 443711.0000 - mae: 448.7931 - mse: 443711.0000 - val_loss: 449193.0625 - val_mae: 448.8161 - val_mse: 449193.0625\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 443376.5938 - mae: 448.5479 - mse: 443376.5938 - val_loss: 448566.8438 - val_mae: 448.5560 - val_mse: 448566.8438\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 442998.3750 - mae: 448.2585 - mse: 442998.3750 - val_loss: 448080.2812 - val_mae: 448.3518 - val_mse: 448080.2812\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 442682.4375 - mae: 448.0196 - mse: 442682.4375 - val_loss: 447697.1250 - val_mae: 448.1622 - val_mse: 447697.1250\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 442343.9062 - mae: 447.7406 - mse: 442343.9062 - val_loss: 447279.7812 - val_mae: 447.9225 - val_mse: 447279.7812\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 442048.4375 - mae: 447.4916 - mse: 442048.4375 - val_loss: 446764.0000 - val_mae: 447.6684 - val_mse: 446764.0000\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 441680.6875 - mae: 447.2156 - mse: 441680.6875 - val_loss: 446541.4688 - val_mae: 447.4946 - val_mse: 446541.4688\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 441403.9688 - mae: 446.9979 - mse: 441403.9688 - val_loss: 446225.5000 - val_mae: 447.2661 - val_mse: 446225.5000\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 441095.7188 - mae: 446.7347 - mse: 441095.7188 - val_loss: 445971.9688 - val_mae: 447.0870 - val_mse: 445971.9688\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 440849.8750 - mae: 446.5218 - mse: 440849.8750 - val_loss: 445429.9062 - val_mae: 446.8046 - val_mse: 445429.9062\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 440518.0938 - mae: 446.2517 - mse: 440518.0938 - val_loss: 445319.6562 - val_mae: 446.6640 - val_mse: 445319.6562\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 440278.1562 - mae: 446.0167 - mse: 440278.1562 - val_loss: 444998.8750 - val_mae: 446.4155 - val_mse: 444998.8750\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 440002.7188 - mae: 445.7449 - mse: 440002.7188 - val_loss: 444727.0938 - val_mae: 446.2235 - val_mse: 444727.0938\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439705.7188 - mae: 445.4801 - mse: 439705.7188 - val_loss: 444672.5312 - val_mae: 446.0721 - val_mse: 444672.5312\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439482.6875 - mae: 445.2584 - mse: 439482.6875 - val_loss: 444391.1875 - val_mae: 445.9191 - val_mse: 444391.1875\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 439212.1875 - mae: 445.0580 - mse: 439212.1875 - val_loss: 444265.5312 - val_mae: 445.7961 - val_mse: 444265.5312\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438991.4375 - mae: 444.8869 - mse: 438991.4375 - val_loss: 444021.4062 - val_mae: 445.6948 - val_mse: 444021.4062\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438732.9688 - mae: 444.7107 - mse: 438732.9688 - val_loss: 444120.6562 - val_mae: 445.6420 - val_mse: 444120.6562\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438534.5625 - mae: 444.5600 - mse: 438534.5625 - val_loss: 443806.5938 - val_mae: 445.4943 - val_mse: 443806.5938\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 438298.7812 - mae: 444.3912 - mse: 438298.7812 - val_loss: 443777.2188 - val_mae: 445.4232 - val_mse: 443777.2188\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 438080.0000 - mae: 444.2231 - mse: 438080.0000 - val_loss: 443560.8125 - val_mae: 445.3201 - val_mse: 443560.8125\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 437842.0312 - mae: 444.0609 - mse: 437842.0312 - val_loss: 443702.9375 - val_mae: 445.2640 - val_mse: 443702.9375\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 437686.3438 - mae: 443.9361 - mse: 437686.3438 - val_loss: 443346.6250 - val_mae: 445.1403 - val_mse: 443346.6250\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 437468.0938 - mae: 443.8059 - mse: 437468.0938 - val_loss: 443231.6875 - val_mae: 445.0020 - val_mse: 443231.6875\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 437229.3125 - mae: 443.6419 - mse: 437229.3125 - val_loss: 443184.4688 - val_mae: 444.9522 - val_mse: 443184.4688\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 437026.6250 - mae: 443.5100 - mse: 437026.6250 - val_loss: 442896.1250 - val_mae: 444.7556 - val_mse: 442896.1250\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 436810.5312 - mae: 443.3650 - mse: 436810.5312 - val_loss: 442797.1875 - val_mae: 444.7202 - val_mse: 442797.1875\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436562.6875 - mae: 443.1981 - mse: 436562.6875 - val_loss: 443007.1250 - val_mae: 444.6704 - val_mse: 443007.1250\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436485.3125 - mae: 443.1203 - mse: 436485.3125 - val_loss: 442168.7500 - val_mae: 444.3844 - val_mse: 442168.7500\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 436123.0000 - mae: 442.9213 - mse: 436123.0000 - val_loss: 442780.8438 - val_mae: 444.4760 - val_mse: 442780.8438\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436110.6250 - mae: 442.8600 - mse: 436110.6250 - val_loss: 441915.8750 - val_mae: 444.2433 - val_mse: 441915.8750\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 435702.7812 - mae: 442.6640 - mse: 435702.7812 - val_loss: 442482.7500 - val_mae: 444.2780 - val_mse: 442482.7500\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Training fold 7\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 10ms/step - loss: 2582736.7500 - mae: 1163.8029 - mse: 2582736.7500 - val_loss: 1121929.8750 - val_mae: 820.2620 - val_mse: 1121929.8750\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 925832.1250 - mae: 681.5106 - mse: 925832.1250 - val_loss: 662567.5000 - val_mae: 583.6747 - val_mse: 662567.5000\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 764832.9375 - mae: 575.7733 - mse: 764832.9375 - val_loss: 614323.4375 - val_mae: 549.0130 - val_mse: 614323.4375\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 729209.5625 - mae: 556.6459 - mse: 729209.5625 - val_loss: 595722.3125 - val_mae: 537.4821 - val_mse: 595722.3125\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 704366.7500 - mae: 547.7598 - mse: 704366.7500 - val_loss: 583569.4375 - val_mae: 530.4515 - val_mse: 583569.4375\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 684875.5625 - mae: 541.4107 - mse: 684875.5625 - val_loss: 574158.2500 - val_mae: 524.8266 - val_mse: 574158.2500\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 668687.0000 - mae: 536.1995 - mse: 668687.0000 - val_loss: 565862.1250 - val_mae: 519.9357 - val_mse: 565862.1250\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 654462.0625 - mae: 531.5193 - mse: 654462.0625 - val_loss: 558586.7500 - val_mae: 515.6359 - val_mse: 558586.7500\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 641510.1250 - mae: 527.1241 - mse: 641510.1250 - val_loss: 551758.3750 - val_mae: 511.5331 - val_mse: 551758.3750\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 629435.6250 - mae: 522.9556 - mse: 629435.6250 - val_loss: 545242.0000 - val_mae: 507.4887 - val_mse: 545242.0000\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 618315.8750 - mae: 518.8918 - mse: 618315.8750 - val_loss: 538966.2500 - val_mae: 503.6959 - val_mse: 538966.2500\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 607772.2500 - mae: 514.8725 - mse: 607772.2500 - val_loss: 532761.3125 - val_mae: 500.0611 - val_mse: 532761.3125\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 597746.0625 - mae: 510.8833 - mse: 597746.0625 - val_loss: 526497.9375 - val_mae: 496.4832 - val_mse: 526497.9375\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 587991.5000 - mae: 506.7537 - mse: 587991.5000 - val_loss: 519619.2188 - val_mae: 492.3455 - val_mse: 519619.2188\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 576657.5000 - mae: 501.5600 - mse: 576657.5000 - val_loss: 510337.4688 - val_mae: 487.0695 - val_mse: 510337.4688\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 563197.0000 - mae: 495.2851 - mse: 563197.0000 - val_loss: 499892.8750 - val_mae: 481.3455 - val_mse: 499892.8750\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 548911.1250 - mae: 488.6797 - mse: 548911.1250 - val_loss: 489423.0625 - val_mae: 475.8625 - val_mse: 489423.0625\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 534806.3750 - mae: 482.3802 - mse: 534806.3750 - val_loss: 479620.4062 - val_mae: 470.6834 - val_mse: 479620.4062\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 521424.5938 - mae: 476.4937 - mse: 521424.5938 - val_loss: 470697.0938 - val_mae: 466.1074 - val_mse: 470697.0938\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 509090.8438 - mae: 471.2014 - mse: 509090.8438 - val_loss: 462899.2500 - val_mae: 462.1923 - val_mse: 462899.2500\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 497888.2500 - mae: 466.5930 - mse: 497888.2500 - val_loss: 456137.8125 - val_mae: 458.6731 - val_mse: 456137.8125\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 487967.8750 - mae: 462.6721 - mse: 487967.8750 - val_loss: 450514.0312 - val_mae: 455.7769 - val_mse: 450514.0312\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 479214.6250 - mae: 459.3205 - mse: 479214.6250 - val_loss: 445829.0312 - val_mae: 453.4902 - val_mse: 445829.0312\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 471600.7812 - mae: 456.5039 - mse: 471600.7812 - val_loss: 442125.6562 - val_mae: 451.7135 - val_mse: 442125.6562\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 464941.9062 - mae: 454.1035 - mse: 464941.9062 - val_loss: 438888.1250 - val_mae: 450.1243 - val_mse: 438888.1250\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 459124.1875 - mae: 452.0563 - mse: 459124.1875 - val_loss: 436302.4688 - val_mae: 449.0554 - val_mse: 436302.4688\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 454071.3750 - mae: 450.3367 - mse: 454071.3750 - val_loss: 434089.3438 - val_mae: 447.9781 - val_mse: 434089.3438\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 449675.1875 - mae: 448.8827 - mse: 449675.1875 - val_loss: 432258.5000 - val_mae: 446.9638 - val_mse: 432258.5000\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 445771.8750 - mae: 447.6652 - mse: 445771.8750 - val_loss: 430633.4688 - val_mae: 446.0923 - val_mse: 430633.4688\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 442340.2812 - mae: 446.5957 - mse: 442340.2812 - val_loss: 429213.1562 - val_mae: 445.3114 - val_mse: 429213.1562\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439247.5625 - mae: 445.6060 - mse: 439247.5625 - val_loss: 427923.5312 - val_mae: 444.5605 - val_mse: 427923.5312\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 436479.4688 - mae: 444.6472 - mse: 436479.4688 - val_loss: 426703.9375 - val_mae: 443.8819 - val_mse: 426703.9375\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 433890.6250 - mae: 443.6635 - mse: 433890.6250 - val_loss: 425604.0312 - val_mae: 443.0597 - val_mse: 425604.0312\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 431538.3750 - mae: 442.7108 - mse: 431538.3750 - val_loss: 424506.6250 - val_mae: 442.2282 - val_mse: 424506.6250\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 429389.4688 - mae: 441.8153 - mse: 429389.4688 - val_loss: 423478.5938 - val_mae: 441.4544 - val_mse: 423478.5938\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 427433.5938 - mae: 440.9445 - mse: 427433.5938 - val_loss: 422568.3125 - val_mae: 440.8131 - val_mse: 422568.3125\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 425609.6250 - mae: 440.0856 - mse: 425609.6250 - val_loss: 421643.8125 - val_mae: 440.1038 - val_mse: 421643.8125\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 423916.8125 - mae: 439.2227 - mse: 423916.8125 - val_loss: 420794.9375 - val_mae: 439.3992 - val_mse: 420794.9375\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 422277.5625 - mae: 438.3148 - mse: 422277.5625 - val_loss: 419802.0312 - val_mae: 438.5182 - val_mse: 419802.0312\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 420750.4688 - mae: 437.4352 - mse: 420750.4688 - val_loss: 418951.2500 - val_mae: 437.7581 - val_mse: 418951.2500\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 419272.3750 - mae: 436.5375 - mse: 419272.3750 - val_loss: 418046.1250 - val_mae: 436.9694 - val_mse: 418046.1250\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 417879.7188 - mae: 435.6259 - mse: 417879.7188 - val_loss: 417210.5625 - val_mae: 436.3133 - val_mse: 417210.5625\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 416572.5938 - mae: 434.7772 - mse: 416572.5938 - val_loss: 416445.4688 - val_mae: 435.6867 - val_mse: 416445.4688\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 415456.5000 - mae: 434.0488 - mse: 415456.5000 - val_loss: 415779.3438 - val_mae: 435.0765 - val_mse: 415779.3438\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 414449.9375 - mae: 433.4012 - mse: 414449.9375 - val_loss: 415021.1875 - val_mae: 434.5253 - val_mse: 415021.1875\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 413253.7812 - mae: 432.6882 - mse: 413253.7812 - val_loss: 414303.9688 - val_mae: 434.0235 - val_mse: 414303.9688\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 412159.4375 - mae: 432.0017 - mse: 412159.4375 - val_loss: 413603.6875 - val_mae: 433.4953 - val_mse: 413603.6875\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 411191.5312 - mae: 431.3576 - mse: 411191.5312 - val_loss: 412935.9375 - val_mae: 432.9684 - val_mse: 412935.9375\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 410195.2500 - mae: 430.7171 - mse: 410195.2500 - val_loss: 412261.1562 - val_mae: 432.5310 - val_mse: 412261.1562\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 409275.9062 - mae: 430.1085 - mse: 409275.9062 - val_loss: 411529.0938 - val_mae: 431.9557 - val_mse: 411529.0938\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 408328.9062 - mae: 429.5179 - mse: 408328.9062 - val_loss: 410840.6875 - val_mae: 431.4965 - val_mse: 410840.6875\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 407419.0000 - mae: 428.9041 - mse: 407419.0000 - val_loss: 410117.0625 - val_mae: 431.0709 - val_mse: 410117.0625\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 406468.0938 - mae: 428.3032 - mse: 406468.0938 - val_loss: 409380.2812 - val_mae: 430.5359 - val_mse: 409380.2812\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 405560.5312 - mae: 427.7054 - mse: 405560.5312 - val_loss: 408640.5625 - val_mae: 430.0363 - val_mse: 408640.5625\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 404631.9375 - mae: 427.1071 - mse: 404631.9375 - val_loss: 407936.2188 - val_mae: 429.5379 - val_mse: 407936.2188\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 403748.8750 - mae: 426.5277 - mse: 403748.8750 - val_loss: 407224.2188 - val_mae: 429.0454 - val_mse: 407224.2188\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 402825.7812 - mae: 425.9650 - mse: 402825.7812 - val_loss: 406476.5938 - val_mae: 428.5791 - val_mse: 406476.5938\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 401929.7500 - mae: 425.3914 - mse: 401929.7500 - val_loss: 405741.9688 - val_mae: 428.1582 - val_mse: 405741.9688\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 401028.6875 - mae: 424.8509 - mse: 401028.6875 - val_loss: 404954.5938 - val_mae: 427.6629 - val_mse: 404954.5938\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 400147.2500 - mae: 424.2748 - mse: 400147.2500 - val_loss: 404209.8750 - val_mae: 427.1531 - val_mse: 404209.8750\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 399273.3438 - mae: 423.7706 - mse: 399273.3438 - val_loss: 403413.9062 - val_mae: 426.6246 - val_mse: 403413.9062\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 398378.4688 - mae: 423.1991 - mse: 398378.4688 - val_loss: 402616.9688 - val_mae: 426.1427 - val_mse: 402616.9688\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 397484.3750 - mae: 422.6882 - mse: 397484.3750 - val_loss: 401744.3125 - val_mae: 425.6013 - val_mse: 401744.3125\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 396585.2188 - mae: 422.1281 - mse: 396585.2188 - val_loss: 400877.6250 - val_mae: 425.0440 - val_mse: 400877.6250\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 395694.0625 - mae: 421.5912 - mse: 395694.0625 - val_loss: 400074.8438 - val_mae: 424.5456 - val_mse: 400074.8438\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 394791.4688 - mae: 421.0319 - mse: 394791.4688 - val_loss: 399245.5312 - val_mae: 424.0480 - val_mse: 399245.5312\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 393875.3750 - mae: 420.5070 - mse: 393875.3750 - val_loss: 398314.2500 - val_mae: 423.4757 - val_mse: 398314.2500\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 392944.4375 - mae: 419.9406 - mse: 392944.4375 - val_loss: 397483.3125 - val_mae: 423.0201 - val_mse: 397483.3125\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 392025.7812 - mae: 419.4136 - mse: 392025.7812 - val_loss: 396628.3125 - val_mae: 422.4725 - val_mse: 396628.3125\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 391085.2812 - mae: 418.8331 - mse: 391085.2812 - val_loss: 395782.6875 - val_mae: 421.9826 - val_mse: 395782.6875\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 390187.0000 - mae: 418.3051 - mse: 390187.0000 - val_loss: 394875.3438 - val_mae: 421.4347 - val_mse: 394875.3438\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 389253.7812 - mae: 417.7369 - mse: 389253.7812 - val_loss: 393984.5312 - val_mae: 420.9798 - val_mse: 393984.5312\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 388279.6250 - mae: 417.1999 - mse: 388279.6250 - val_loss: 393060.3750 - val_mae: 420.4566 - val_mse: 393060.3750\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 387360.1250 - mae: 416.6528 - mse: 387360.1250 - val_loss: 392139.9062 - val_mae: 419.9386 - val_mse: 392139.9062\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 386364.7188 - mae: 416.1087 - mse: 386364.7188 - val_loss: 391145.2188 - val_mae: 419.3759 - val_mse: 391145.2188\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 385405.7188 - mae: 415.5202 - mse: 385405.7188 - val_loss: 390199.0938 - val_mae: 418.8512 - val_mse: 390199.0938\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 384362.8438 - mae: 414.9706 - mse: 384362.8438 - val_loss: 389247.7188 - val_mae: 418.3248 - val_mse: 389247.7188\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 383351.0000 - mae: 414.3741 - mse: 383351.0000 - val_loss: 388322.9375 - val_mae: 417.7777 - val_mse: 388322.9375\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 382337.7500 - mae: 413.8227 - mse: 382337.7500 - val_loss: 387312.8438 - val_mae: 417.2510 - val_mse: 387312.8438\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 381273.3125 - mae: 413.2248 - mse: 381273.3125 - val_loss: 386404.5625 - val_mae: 416.7096 - val_mse: 386404.5625\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 380298.3438 - mae: 412.7076 - mse: 380298.3438 - val_loss: 385349.1250 - val_mae: 416.0612 - val_mse: 385349.1250\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 379216.9062 - mae: 412.0910 - mse: 379216.9062 - val_loss: 384393.9062 - val_mae: 415.4721 - val_mse: 384393.9062\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 378181.5625 - mae: 411.5529 - mse: 378181.5625 - val_loss: 383479.2188 - val_mae: 414.8569 - val_mse: 383479.2188\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 377199.1562 - mae: 410.9960 - mse: 377199.1562 - val_loss: 382536.5938 - val_mae: 414.2773 - val_mse: 382536.5938\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 376122.8125 - mae: 410.3733 - mse: 376122.8125 - val_loss: 381590.7812 - val_mae: 413.6270 - val_mse: 381590.7812\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 375071.9375 - mae: 409.7602 - mse: 375071.9375 - val_loss: 380711.7500 - val_mae: 413.1107 - val_mse: 380711.7500\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 373975.6562 - mae: 409.1521 - mse: 373975.6562 - val_loss: 379757.8125 - val_mae: 412.5159 - val_mse: 379757.8125\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 372946.0000 - mae: 408.5760 - mse: 372946.0000 - val_loss: 378830.8750 - val_mae: 412.0229 - val_mse: 378830.8750\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 371810.0312 - mae: 407.9566 - mse: 371810.0312 - val_loss: 377958.6562 - val_mae: 411.3712 - val_mse: 377958.6562\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 370719.3125 - mae: 407.3206 - mse: 370719.3125 - val_loss: 376979.6250 - val_mae: 410.8257 - val_mse: 376979.6250\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 369639.3125 - mae: 406.7383 - mse: 369639.3125 - val_loss: 376070.4688 - val_mae: 410.2762 - val_mse: 376070.4688\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 368573.1875 - mae: 406.1077 - mse: 368573.1875 - val_loss: 375178.0938 - val_mae: 409.7640 - val_mse: 375178.0938\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 367479.7812 - mae: 405.5133 - mse: 367479.7812 - val_loss: 374283.0312 - val_mae: 409.2202 - val_mse: 374283.0312\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 366407.1562 - mae: 404.8820 - mse: 366407.1562 - val_loss: 373361.8750 - val_mae: 408.6492 - val_mse: 373361.8750\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 365332.8438 - mae: 404.2809 - mse: 365332.8438 - val_loss: 372503.4375 - val_mae: 408.1284 - val_mse: 372503.4375\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 364225.7812 - mae: 403.6026 - mse: 364225.7812 - val_loss: 371610.3750 - val_mae: 407.5636 - val_mse: 371610.3750\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 363126.0000 - mae: 402.9643 - mse: 363126.0000 - val_loss: 370681.2500 - val_mae: 406.9704 - val_mse: 370681.2500\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 362006.1562 - mae: 402.2687 - mse: 362006.1562 - val_loss: 369740.2500 - val_mae: 406.3329 - val_mse: 369740.2500\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 360894.5938 - mae: 401.6028 - mse: 360894.5938 - val_loss: 368692.0000 - val_mae: 405.7332 - val_mse: 368692.0000\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 359733.5625 - mae: 400.8627 - mse: 359733.5625 - val_loss: 367740.1875 - val_mae: 405.1669 - val_mse: 367740.1875\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Training fold 8\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 10ms/step - loss: 2426167.7500 - mae: 1122.7792 - mse: 2426167.7500 - val_loss: 1138827.2500 - val_mae: 831.6238 - val_mse: 1138827.2500\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 920715.8125 - mae: 686.3636 - mse: 920715.8125 - val_loss: 771240.8125 - val_mae: 633.8823 - val_mse: 771240.8125\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 768779.5000 - mae: 587.3995 - mse: 768779.5000 - val_loss: 710776.1250 - val_mae: 592.0001 - val_mse: 710776.1250\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 729678.9375 - mae: 562.4103 - mse: 729678.9375 - val_loss: 687149.0000 - val_mae: 577.1780 - val_mse: 687149.0000\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 704867.6250 - mae: 550.9451 - mse: 704867.6250 - val_loss: 669391.1875 - val_mae: 567.7975 - val_mse: 669391.1875\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 683032.8750 - mae: 541.7262 - mse: 683032.8750 - val_loss: 652951.4375 - val_mae: 559.3787 - val_mse: 652951.4375\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 662805.6250 - mae: 533.5513 - mse: 662805.6250 - val_loss: 638240.0000 - val_mae: 552.3240 - val_mse: 638240.0000\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 644354.5625 - mae: 526.2892 - mse: 644354.5625 - val_loss: 624719.2500 - val_mae: 546.2871 - val_mse: 624719.2500\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 627170.3750 - mae: 519.5256 - mse: 627170.3750 - val_loss: 611972.7500 - val_mae: 540.4547 - val_mse: 611972.7500\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 610839.8125 - mae: 513.0181 - mse: 610839.8125 - val_loss: 599616.8125 - val_mae: 534.6579 - val_mse: 599616.8125\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 595091.2500 - mae: 506.6347 - mse: 595091.2500 - val_loss: 587342.2500 - val_mae: 528.7328 - val_mse: 587342.2500\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 579508.1250 - mae: 500.1893 - mse: 579508.1250 - val_loss: 575000.9375 - val_mae: 522.5327 - val_mse: 575000.9375\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 563188.6875 - mae: 493.3534 - mse: 563188.6875 - val_loss: 562190.2500 - val_mae: 515.9357 - val_mse: 562190.2500\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 546782.5625 - mae: 486.5443 - mse: 546782.5625 - val_loss: 549508.0625 - val_mae: 509.6159 - val_mse: 549508.0625\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 531097.6875 - mae: 479.9535 - mse: 531097.6875 - val_loss: 537417.6250 - val_mae: 503.7312 - val_mse: 537417.6250\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 516311.9688 - mae: 473.8450 - mse: 516311.9688 - val_loss: 526250.0625 - val_mae: 498.1534 - val_mse: 526250.0625\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 502925.0312 - mae: 468.3530 - mse: 502925.0312 - val_loss: 516279.7500 - val_mae: 492.8622 - val_mse: 516279.7500\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 490943.8125 - mae: 463.5268 - mse: 490943.8125 - val_loss: 507498.1875 - val_mae: 488.1328 - val_mse: 507498.1875\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 480403.3750 - mae: 459.4538 - mse: 480403.3750 - val_loss: 500073.8750 - val_mae: 484.1388 - val_mse: 500073.8750\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 471193.8125 - mae: 456.0840 - mse: 471193.8125 - val_loss: 493927.5000 - val_mae: 480.7031 - val_mse: 493927.5000\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 463215.9062 - mae: 453.3160 - mse: 463215.9062 - val_loss: 488844.6250 - val_mae: 477.8841 - val_mse: 488844.6250\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 456301.7500 - mae: 451.0580 - mse: 456301.7500 - val_loss: 484709.9375 - val_mae: 475.6486 - val_mse: 484709.9375\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 450390.7188 - mae: 449.1394 - mse: 450390.7188 - val_loss: 481377.4688 - val_mae: 473.8510 - val_mse: 481377.4688\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 445272.7812 - mae: 447.4897 - mse: 445272.7812 - val_loss: 478658.7812 - val_mae: 472.2464 - val_mse: 478658.7812\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 440855.6875 - mae: 446.0823 - mse: 440855.6875 - val_loss: 476454.3750 - val_mae: 470.9350 - val_mse: 476454.3750\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 437013.3125 - mae: 444.8239 - mse: 437013.3125 - val_loss: 474454.7812 - val_mae: 469.6898 - val_mse: 474454.7812\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 433614.5000 - mae: 443.6532 - mse: 433614.5000 - val_loss: 472772.0312 - val_mae: 468.7777 - val_mse: 472772.0312\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 430634.2188 - mae: 442.6064 - mse: 430634.2188 - val_loss: 471272.5312 - val_mae: 467.7711 - val_mse: 471272.5312\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 427891.2188 - mae: 441.4826 - mse: 427891.2188 - val_loss: 470380.9062 - val_mae: 467.1744 - val_mse: 470380.9062\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 425428.7812 - mae: 440.3824 - mse: 425428.7812 - val_loss: 468784.9062 - val_mae: 466.0044 - val_mse: 468784.9062\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 423048.3438 - mae: 439.1816 - mse: 423048.3438 - val_loss: 467604.6250 - val_mae: 465.1087 - val_mse: 467604.6250\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 420918.0000 - mae: 438.0994 - mse: 420918.0000 - val_loss: 466290.1875 - val_mae: 464.0411 - val_mse: 466290.1875\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 418965.0938 - mae: 437.0826 - mse: 418965.0938 - val_loss: 465109.1562 - val_mae: 463.2035 - val_mse: 465109.1562\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 417197.2188 - mae: 436.0806 - mse: 417197.2188 - val_loss: 463882.3750 - val_mae: 462.3092 - val_mse: 463882.3750\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 415522.4688 - mae: 435.0748 - mse: 415522.4688 - val_loss: 462833.5000 - val_mae: 461.5475 - val_mse: 462833.5000\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 414010.0625 - mae: 434.1765 - mse: 414010.0625 - val_loss: 461710.8125 - val_mae: 460.6481 - val_mse: 461710.8125\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 412590.9062 - mae: 433.2534 - mse: 412590.9062 - val_loss: 460687.6250 - val_mae: 459.9290 - val_mse: 460687.6250\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 411268.6875 - mae: 432.3484 - mse: 411268.6875 - val_loss: 459629.8750 - val_mae: 459.1005 - val_mse: 459629.8750\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 409993.4688 - mae: 431.4802 - mse: 409993.4688 - val_loss: 458667.1250 - val_mae: 458.2705 - val_mse: 458667.1250\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 408811.8125 - mae: 430.5948 - mse: 408811.8125 - val_loss: 457539.1250 - val_mae: 457.3300 - val_mse: 457539.1250\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 407609.0312 - mae: 429.7226 - mse: 407609.0312 - val_loss: 456395.0312 - val_mae: 456.4370 - val_mse: 456395.0312\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 406449.7812 - mae: 428.8413 - mse: 406449.7812 - val_loss: 455274.6875 - val_mae: 455.5420 - val_mse: 455274.6875\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 405262.5938 - mae: 427.9190 - mse: 405262.5938 - val_loss: 454104.9375 - val_mae: 454.6656 - val_mse: 454104.9375\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 404126.0312 - mae: 427.0453 - mse: 404126.0312 - val_loss: 453075.0938 - val_mae: 453.8822 - val_mse: 453075.0938\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 403042.0000 - mae: 426.2864 - mse: 403042.0000 - val_loss: 451913.2188 - val_mae: 453.1539 - val_mse: 451913.2188\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 402037.6250 - mae: 425.5840 - mse: 402037.6250 - val_loss: 450925.1875 - val_mae: 452.4653 - val_mse: 450925.1875\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 401034.8125 - mae: 424.9087 - mse: 401034.8125 - val_loss: 449885.4062 - val_mae: 451.7487 - val_mse: 449885.4062\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 400074.2188 - mae: 424.2390 - mse: 400074.2188 - val_loss: 449000.2188 - val_mae: 451.1493 - val_mse: 449000.2188\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 399116.9062 - mae: 423.6257 - mse: 399116.9062 - val_loss: 447949.1562 - val_mae: 450.5038 - val_mse: 447949.1562\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 398197.9688 - mae: 423.0268 - mse: 398197.9688 - val_loss: 447056.9375 - val_mae: 450.0297 - val_mse: 447056.9375\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 397244.0625 - mae: 422.4660 - mse: 397244.0625 - val_loss: 446099.5938 - val_mae: 449.4372 - val_mse: 446099.5938\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 396319.9062 - mae: 421.8820 - mse: 396319.9062 - val_loss: 445313.7812 - val_mae: 448.9644 - val_mse: 445313.7812\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 395389.6875 - mae: 421.3252 - mse: 395389.6875 - val_loss: 444276.9688 - val_mae: 448.2809 - val_mse: 444276.9688\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 394488.8750 - mae: 420.7448 - mse: 394488.8750 - val_loss: 443419.8750 - val_mae: 447.7538 - val_mse: 443419.8750\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 393574.4688 - mae: 420.2034 - mse: 393574.4688 - val_loss: 442384.3125 - val_mae: 447.1115 - val_mse: 442384.3125\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 392677.5938 - mae: 419.6561 - mse: 392677.5938 - val_loss: 441548.2500 - val_mae: 446.6019 - val_mse: 441548.2500\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 391775.0312 - mae: 419.1138 - mse: 391775.0312 - val_loss: 440632.8125 - val_mae: 445.9865 - val_mse: 440632.8125\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 390914.7500 - mae: 418.5819 - mse: 390914.7500 - val_loss: 439843.9375 - val_mae: 445.5253 - val_mse: 439843.9375\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 390019.4062 - mae: 418.0665 - mse: 390019.4062 - val_loss: 438798.3750 - val_mae: 444.8438 - val_mse: 438798.3750\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 389124.5625 - mae: 417.5399 - mse: 389124.5625 - val_loss: 438070.0938 - val_mae: 444.4124 - val_mse: 438070.0938\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 388230.9688 - mae: 417.0087 - mse: 388230.9688 - val_loss: 437128.6250 - val_mae: 443.8289 - val_mse: 437128.6250\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 387334.5625 - mae: 416.4607 - mse: 387334.5625 - val_loss: 436359.1875 - val_mae: 443.3797 - val_mse: 436359.1875\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 386444.0938 - mae: 415.9074 - mse: 386444.0938 - val_loss: 435513.8750 - val_mae: 442.8039 - val_mse: 435513.8750\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 385580.8750 - mae: 415.3794 - mse: 385580.8750 - val_loss: 434828.8750 - val_mae: 442.4591 - val_mse: 434828.8750\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 384713.9375 - mae: 414.8621 - mse: 384713.9375 - val_loss: 433932.7500 - val_mae: 441.8547 - val_mse: 433932.7500\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 383837.4375 - mae: 414.3405 - mse: 383837.4375 - val_loss: 433279.8750 - val_mae: 441.5340 - val_mse: 433279.8750\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 382994.0625 - mae: 413.8613 - mse: 382994.0625 - val_loss: 432435.5000 - val_mae: 440.9525 - val_mse: 432435.5000\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 382129.1562 - mae: 413.3471 - mse: 382129.1562 - val_loss: 431902.9375 - val_mae: 440.6341 - val_mse: 431902.9375\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 381287.1875 - mae: 412.8610 - mse: 381287.1875 - val_loss: 431046.8750 - val_mae: 440.0993 - val_mse: 431046.8750\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 380460.6250 - mae: 412.3392 - mse: 380460.6250 - val_loss: 430558.6562 - val_mae: 439.7738 - val_mse: 430558.6562\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 379630.6562 - mae: 411.8337 - mse: 379630.6562 - val_loss: 429762.2188 - val_mae: 439.2806 - val_mse: 429762.2188\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 378817.4375 - mae: 411.3112 - mse: 378817.4375 - val_loss: 429260.3750 - val_mae: 438.9351 - val_mse: 429260.3750\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 378014.2500 - mae: 410.8433 - mse: 378014.2500 - val_loss: 428442.7500 - val_mae: 438.3812 - val_mse: 428442.7500\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 377176.9375 - mae: 410.3260 - mse: 377176.9375 - val_loss: 427935.3750 - val_mae: 438.0167 - val_mse: 427935.3750\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 376291.9688 - mae: 409.7982 - mse: 376291.9688 - val_loss: 427113.9062 - val_mae: 437.3738 - val_mse: 427113.9062\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 375404.8438 - mae: 409.2614 - mse: 375404.8438 - val_loss: 426573.4062 - val_mae: 437.0121 - val_mse: 426573.4062\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 374545.4062 - mae: 408.7830 - mse: 374545.4062 - val_loss: 425732.0625 - val_mae: 436.3632 - val_mse: 425732.0625\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 373658.6250 - mae: 408.2612 - mse: 373658.6250 - val_loss: 425239.9062 - val_mae: 436.0808 - val_mse: 425239.9062\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 372777.4688 - mae: 407.7676 - mse: 372777.4688 - val_loss: 424433.0625 - val_mae: 435.4774 - val_mse: 424433.0625\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 371847.7812 - mae: 407.2352 - mse: 371847.7812 - val_loss: 423781.1875 - val_mae: 435.0424 - val_mse: 423781.1875\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 370914.6875 - mae: 406.7346 - mse: 370914.6875 - val_loss: 422858.2812 - val_mae: 434.5587 - val_mse: 422858.2812\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 369932.7500 - mae: 406.1966 - mse: 369932.7500 - val_loss: 422247.6875 - val_mae: 434.2079 - val_mse: 422247.6875\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 368956.1250 - mae: 405.6787 - mse: 368956.1250 - val_loss: 421360.0312 - val_mae: 433.6001 - val_mse: 421360.0312\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 367982.7188 - mae: 405.1661 - mse: 367982.7188 - val_loss: 420829.4688 - val_mae: 433.3035 - val_mse: 420829.4688\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 367007.5938 - mae: 404.6487 - mse: 367007.5938 - val_loss: 419738.7500 - val_mae: 432.6270 - val_mse: 419738.7500\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 365972.0625 - mae: 404.1000 - mse: 365972.0625 - val_loss: 419124.6250 - val_mae: 432.2730 - val_mse: 419124.6250\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 364980.5938 - mae: 403.5538 - mse: 364980.5938 - val_loss: 418127.4688 - val_mae: 431.5882 - val_mse: 418127.4688\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 363952.6875 - mae: 402.9964 - mse: 363952.6875 - val_loss: 417419.7188 - val_mae: 431.1639 - val_mse: 417419.7188\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 362935.2812 - mae: 402.4557 - mse: 362935.2812 - val_loss: 416369.8125 - val_mae: 430.4084 - val_mse: 416369.8125\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 361890.0938 - mae: 401.9099 - mse: 361890.0938 - val_loss: 415720.1250 - val_mae: 430.0429 - val_mse: 415720.1250\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 360884.0000 - mae: 401.3397 - mse: 360884.0000 - val_loss: 414770.3438 - val_mae: 429.3777 - val_mse: 414770.3438\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 359856.7500 - mae: 400.7828 - mse: 359856.7500 - val_loss: 414146.0625 - val_mae: 429.0242 - val_mse: 414146.0625\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 358842.6562 - mae: 400.2151 - mse: 358842.6562 - val_loss: 413120.0625 - val_mae: 428.3591 - val_mse: 413120.0625\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 357794.0312 - mae: 399.6490 - mse: 357794.0312 - val_loss: 412453.1250 - val_mae: 427.9573 - val_mse: 412453.1250\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 356752.2812 - mae: 399.0522 - mse: 356752.2812 - val_loss: 411382.6250 - val_mae: 427.2156 - val_mse: 411382.6250\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 355670.0312 - mae: 398.4350 - mse: 355670.0312 - val_loss: 410618.2500 - val_mae: 426.7675 - val_mse: 410618.2500\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 354616.4375 - mae: 397.8276 - mse: 354616.4375 - val_loss: 409577.0312 - val_mae: 426.0907 - val_mse: 409577.0312\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 353511.2812 - mae: 397.1885 - mse: 353511.2812 - val_loss: 408937.7500 - val_mae: 425.6848 - val_mse: 408937.7500\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 352448.2188 - mae: 396.5661 - mse: 352448.2188 - val_loss: 407843.7500 - val_mae: 425.0269 - val_mse: 407843.7500\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 351355.1562 - mae: 395.9443 - mse: 351355.1562 - val_loss: 407243.4688 - val_mae: 424.6722 - val_mse: 407243.4688\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "Training fold 9\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 3s 9ms/step - loss: 2617716.2500 - mae: 1168.4702 - mse: 2617716.2500 - val_loss: 1162448.3750 - val_mae: 832.9977 - val_mse: 1162448.3750\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 930350.6250 - mae: 691.2021 - mse: 930350.6250 - val_loss: 738257.0625 - val_mae: 610.7932 - val_mse: 738257.0625\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 754983.2500 - mae: 582.8907 - mse: 754983.2500 - val_loss: 674594.1250 - val_mae: 560.6297 - val_mse: 674594.1250\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 714642.1250 - mae: 556.4326 - mse: 714642.1250 - val_loss: 654897.8750 - val_mae: 545.4404 - val_mse: 654897.8750\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 690868.1875 - mae: 545.9684 - mse: 690868.1875 - val_loss: 640841.6875 - val_mae: 536.5964 - val_mse: 640841.6875\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 670378.8750 - mae: 537.9190 - mse: 670378.8750 - val_loss: 628137.3750 - val_mae: 529.0974 - val_mse: 628137.3750\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 651053.1250 - mae: 530.3824 - mse: 651053.1250 - val_loss: 615730.8125 - val_mae: 521.8112 - val_mse: 615730.8125\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 631888.5000 - mae: 522.9082 - mse: 631888.5000 - val_loss: 603062.9375 - val_mae: 514.2709 - val_mse: 603062.9375\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 612158.3125 - mae: 514.8333 - mse: 612158.3125 - val_loss: 588478.8125 - val_mae: 505.4303 - val_mse: 588478.8125\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 590661.7500 - mae: 505.6796 - mse: 590661.7500 - val_loss: 572671.1875 - val_mae: 496.5198 - val_mse: 572671.1875\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 569138.5625 - mae: 496.6671 - mse: 569138.5625 - val_loss: 556852.2500 - val_mae: 487.8232 - val_mse: 556852.2500\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 548432.9375 - mae: 488.1082 - mse: 548432.9375 - val_loss: 541627.9375 - val_mae: 479.5880 - val_mse: 541627.9375\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 529535.6250 - mae: 480.3334 - mse: 529535.6250 - val_loss: 527768.8125 - val_mae: 472.7686 - val_mse: 527768.8125\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 512822.3125 - mae: 473.5752 - mse: 512822.3125 - val_loss: 515579.4688 - val_mae: 467.1736 - val_mse: 515579.4688\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 498535.9688 - mae: 467.7363 - mse: 498535.9688 - val_loss: 504973.5312 - val_mae: 462.6655 - val_mse: 504973.5312\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 486517.5938 - mae: 462.9927 - mse: 486517.5938 - val_loss: 495816.5625 - val_mae: 459.0643 - val_mse: 495816.5625\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 476512.4375 - mae: 459.1514 - mse: 476512.4375 - val_loss: 487992.0938 - val_mae: 456.1705 - val_mse: 487992.0938\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 468230.1875 - mae: 455.9419 - mse: 468230.1875 - val_loss: 481360.3750 - val_mae: 453.8965 - val_mse: 481360.3750\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 461389.4375 - mae: 453.2981 - mse: 461389.4375 - val_loss: 475792.0938 - val_mae: 452.1973 - val_mse: 475792.0938\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 455624.7500 - mae: 451.1447 - mse: 455624.7500 - val_loss: 470900.7812 - val_mae: 450.6312 - val_mse: 470900.7812\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 450715.3750 - mae: 449.2784 - mse: 450715.3750 - val_loss: 466681.0938 - val_mae: 449.3505 - val_mse: 466681.0938\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 446400.2812 - mae: 447.7085 - mse: 446400.2812 - val_loss: 462656.4062 - val_mae: 447.9709 - val_mse: 462656.4062\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 442533.8750 - mae: 446.2925 - mse: 442533.8750 - val_loss: 459170.3125 - val_mae: 446.8589 - val_mse: 459170.3125\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 439024.9375 - mae: 444.9463 - mse: 439024.9375 - val_loss: 455908.8125 - val_mae: 445.7378 - val_mse: 455908.8125\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 435841.3750 - mae: 443.6590 - mse: 435841.3750 - val_loss: 452817.6250 - val_mae: 444.5493 - val_mse: 452817.6250\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 432887.4062 - mae: 442.4541 - mse: 432887.4062 - val_loss: 449822.5312 - val_mae: 443.2863 - val_mse: 449822.5312\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 430121.2500 - mae: 441.2898 - mse: 430121.2500 - val_loss: 447097.6250 - val_mae: 442.2286 - val_mse: 447097.6250\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 427521.4062 - mae: 440.1124 - mse: 427521.4062 - val_loss: 444606.7812 - val_mae: 441.2078 - val_mse: 444606.7812\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 425139.2812 - mae: 439.0701 - mse: 425139.2812 - val_loss: 442349.1250 - val_mae: 440.4124 - val_mse: 442349.1250\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 422873.9062 - mae: 438.0248 - mse: 422873.9062 - val_loss: 440032.5000 - val_mae: 439.3504 - val_mse: 440032.5000\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 420738.5938 - mae: 436.9760 - mse: 420738.5938 - val_loss: 438076.9375 - val_mae: 438.6210 - val_mse: 438076.9375\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 418660.8438 - mae: 435.9536 - mse: 418660.8438 - val_loss: 436114.7812 - val_mae: 437.7642 - val_mse: 436114.7812\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 416698.2500 - mae: 434.8819 - mse: 416698.2500 - val_loss: 434101.5312 - val_mae: 436.6032 - val_mse: 434101.5312\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 414805.4375 - mae: 433.8939 - mse: 414805.4375 - val_loss: 432226.8438 - val_mae: 435.6506 - val_mse: 432226.8438\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 412980.9375 - mae: 432.8661 - mse: 412980.9375 - val_loss: 430510.0625 - val_mae: 434.7193 - val_mse: 430510.0625\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 411228.3125 - mae: 431.9048 - mse: 411228.3125 - val_loss: 428850.8125 - val_mae: 433.8726 - val_mse: 428850.8125\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 409614.5625 - mae: 430.9609 - mse: 409614.5625 - val_loss: 427049.4688 - val_mae: 432.8235 - val_mse: 427049.4688\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 408062.5938 - mae: 430.0963 - mse: 408062.5938 - val_loss: 425490.3125 - val_mae: 431.9894 - val_mse: 425490.3125\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 406587.9375 - mae: 429.1959 - mse: 406587.9375 - val_loss: 424043.9375 - val_mae: 431.1786 - val_mse: 424043.9375\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 405195.0625 - mae: 428.3813 - mse: 405195.0625 - val_loss: 422331.5312 - val_mae: 430.1033 - val_mse: 422331.5312\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 403809.5938 - mae: 427.5590 - mse: 403809.5938 - val_loss: 420952.2188 - val_mae: 429.3413 - val_mse: 420952.2188\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 402499.0625 - mae: 426.8031 - mse: 402499.0625 - val_loss: 419470.2188 - val_mae: 428.4153 - val_mse: 419470.2188\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 401105.4688 - mae: 425.9387 - mse: 401105.4688 - val_loss: 418252.6562 - val_mae: 427.6465 - val_mse: 418252.6562\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 399844.4688 - mae: 425.2084 - mse: 399844.4688 - val_loss: 417109.0938 - val_mae: 426.9648 - val_mse: 417109.0938\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 398622.0000 - mae: 424.4736 - mse: 398622.0000 - val_loss: 415930.7812 - val_mae: 426.0528 - val_mse: 415930.7812\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 397439.9688 - mae: 423.7817 - mse: 397439.9688 - val_loss: 414705.4062 - val_mae: 425.1282 - val_mse: 414705.4062\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 396225.0938 - mae: 423.0539 - mse: 396225.0938 - val_loss: 413672.8438 - val_mae: 424.3482 - val_mse: 413672.8438\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 395059.7188 - mae: 422.3394 - mse: 395059.7188 - val_loss: 412554.8750 - val_mae: 423.5044 - val_mse: 412554.8750\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 393883.0312 - mae: 421.5811 - mse: 393883.0312 - val_loss: 411630.2188 - val_mae: 422.7404 - val_mse: 411630.2188\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 392770.5000 - mae: 420.9157 - mse: 392770.5000 - val_loss: 410791.1250 - val_mae: 422.2360 - val_mse: 410791.1250\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 391686.4062 - mae: 420.2423 - mse: 391686.4062 - val_loss: 409907.4375 - val_mae: 421.4028 - val_mse: 409907.4375\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 390599.4688 - mae: 419.5980 - mse: 390599.4688 - val_loss: 409093.1562 - val_mae: 420.9176 - val_mse: 409093.1562\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 389501.3125 - mae: 418.9413 - mse: 389501.3125 - val_loss: 408556.0625 - val_mae: 420.4868 - val_mse: 408556.0625\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 388445.1562 - mae: 418.3033 - mse: 388445.1562 - val_loss: 407768.4688 - val_mae: 419.7382 - val_mse: 407768.4688\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 387347.5938 - mae: 417.6097 - mse: 387347.5938 - val_loss: 407120.8125 - val_mae: 419.2119 - val_mse: 407120.8125\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 386302.1875 - mae: 416.9922 - mse: 386302.1875 - val_loss: 406442.8125 - val_mae: 418.8660 - val_mse: 406442.8125\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 385237.7812 - mae: 416.3383 - mse: 385237.7812 - val_loss: 405766.1875 - val_mae: 418.1268 - val_mse: 405766.1875\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 384156.5625 - mae: 415.7157 - mse: 384156.5625 - val_loss: 405144.5312 - val_mae: 417.6595 - val_mse: 405144.5312\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 383120.7812 - mae: 415.0806 - mse: 383120.7812 - val_loss: 404620.3125 - val_mae: 417.3652 - val_mse: 404620.3125\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 382104.0312 - mae: 414.4598 - mse: 382104.0312 - val_loss: 403935.5938 - val_mae: 416.6363 - val_mse: 403935.5938\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 381074.9688 - mae: 413.8354 - mse: 381074.9688 - val_loss: 403399.9375 - val_mae: 416.3359 - val_mse: 403399.9375\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 380039.5938 - mae: 413.2343 - mse: 380039.5938 - val_loss: 402782.2188 - val_mae: 415.6424 - val_mse: 402782.2188\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 378944.0000 - mae: 412.5493 - mse: 378944.0000 - val_loss: 402300.4062 - val_mae: 415.2981 - val_mse: 402300.4062\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 377891.7500 - mae: 411.9417 - mse: 377891.7500 - val_loss: 401677.3438 - val_mae: 414.5600 - val_mse: 401677.3438\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 376758.8125 - mae: 411.2489 - mse: 376758.8125 - val_loss: 401245.2188 - val_mae: 414.2808 - val_mse: 401245.2188\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 375662.8125 - mae: 410.6300 - mse: 375662.8125 - val_loss: 400638.7500 - val_mae: 413.5179 - val_mse: 400638.7500\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 374530.1562 - mae: 409.9371 - mse: 374530.1562 - val_loss: 400211.3750 - val_mae: 413.2187 - val_mse: 400211.3750\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 373411.0625 - mae: 409.3097 - mse: 373411.0625 - val_loss: 399674.3438 - val_mae: 412.5213 - val_mse: 399674.3438\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 372215.8125 - mae: 408.6085 - mse: 372215.8125 - val_loss: 399222.0938 - val_mae: 412.2543 - val_mse: 399222.0938\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 371067.4062 - mae: 407.9464 - mse: 371067.4062 - val_loss: 398675.9062 - val_mae: 411.5175 - val_mse: 398675.9062\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 369861.8438 - mae: 407.2483 - mse: 369861.8438 - val_loss: 398432.7500 - val_mae: 411.3931 - val_mse: 398432.7500\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 368747.0312 - mae: 406.6023 - mse: 368747.0312 - val_loss: 398007.1875 - val_mae: 410.7149 - val_mse: 398007.1875\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 367572.8438 - mae: 405.8990 - mse: 367572.8438 - val_loss: 397728.5938 - val_mae: 410.5231 - val_mse: 397728.5938\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 366500.6875 - mae: 405.2805 - mse: 366500.6875 - val_loss: 397167.0625 - val_mae: 409.7106 - val_mse: 397167.0625\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 365338.7188 - mae: 404.5934 - mse: 365338.7188 - val_loss: 396840.3125 - val_mae: 409.5165 - val_mse: 396840.3125\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 364239.5312 - mae: 403.9603 - mse: 364239.5312 - val_loss: 396351.2188 - val_mae: 408.8586 - val_mse: 396351.2188\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 363090.4375 - mae: 403.2861 - mse: 363090.4375 - val_loss: 395947.1250 - val_mae: 408.5608 - val_mse: 395947.1250\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 361985.3438 - mae: 402.6435 - mse: 361985.3438 - val_loss: 395313.9062 - val_mae: 407.8937 - val_mse: 395313.9062\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 360787.0000 - mae: 401.9627 - mse: 360787.0000 - val_loss: 394903.6875 - val_mae: 407.7222 - val_mse: 394903.6875\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 359708.9062 - mae: 401.3519 - mse: 359708.9062 - val_loss: 394290.5312 - val_mae: 407.0828 - val_mse: 394290.5312\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 358466.7188 - mae: 400.5977 - mse: 358466.7188 - val_loss: 393771.0625 - val_mae: 406.6329 - val_mse: 393771.0625\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 357366.2188 - mae: 399.9440 - mse: 357366.2188 - val_loss: 393275.9062 - val_mae: 406.4027 - val_mse: 393275.9062\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 356097.0938 - mae: 399.1337 - mse: 356097.0938 - val_loss: 392596.7812 - val_mae: 405.6523 - val_mse: 392596.7812\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 354981.4375 - mae: 398.4717 - mse: 354981.4375 - val_loss: 392054.3125 - val_mae: 405.3248 - val_mse: 392054.3125\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 353763.5938 - mae: 397.6998 - mse: 353763.5938 - val_loss: 391467.2500 - val_mae: 404.6045 - val_mse: 391467.2500\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 352646.5625 - mae: 397.0359 - mse: 352646.5625 - val_loss: 390942.4062 - val_mae: 404.2501 - val_mse: 390942.4062\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 351401.0625 - mae: 396.2652 - mse: 351401.0625 - val_loss: 390403.0938 - val_mae: 403.6191 - val_mse: 390403.0938\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 350233.7812 - mae: 395.6458 - mse: 350233.7812 - val_loss: 389742.3750 - val_mae: 403.0821 - val_mse: 389742.3750\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 348949.5938 - mae: 394.8936 - mse: 348949.5938 - val_loss: 389148.6875 - val_mae: 402.6493 - val_mse: 389148.6875\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 347774.4688 - mae: 394.2375 - mse: 347774.4688 - val_loss: 388518.7812 - val_mae: 402.1940 - val_mse: 388518.7812\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 346447.5312 - mae: 393.4457 - mse: 346447.5312 - val_loss: 387912.5625 - val_mae: 401.5353 - val_mse: 387912.5625\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 345284.5000 - mae: 392.8301 - mse: 345284.5000 - val_loss: 387367.7500 - val_mae: 401.2151 - val_mse: 387367.7500\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 343953.1562 - mae: 392.0242 - mse: 343953.1562 - val_loss: 386770.2812 - val_mae: 400.5633 - val_mse: 386770.2812\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 342749.0312 - mae: 391.3523 - mse: 342749.0312 - val_loss: 386235.9062 - val_mae: 400.1460 - val_mse: 386235.9062\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 341438.5625 - mae: 390.5791 - mse: 341438.5625 - val_loss: 385790.6562 - val_mae: 399.8139 - val_mse: 385790.6562\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 340293.4688 - mae: 389.9417 - mse: 340293.4688 - val_loss: 385336.5938 - val_mae: 399.3120 - val_mse: 385336.5938\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 338994.4688 - mae: 389.1750 - mse: 338994.4688 - val_loss: 384971.2188 - val_mae: 398.8981 - val_mse: 384971.2188\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 337814.6562 - mae: 388.4803 - mse: 337814.6562 - val_loss: 384527.4375 - val_mae: 398.4453 - val_mse: 384527.4375\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 336485.7188 - mae: 387.6195 - mse: 336485.7188 - val_loss: 384185.8125 - val_mae: 397.9474 - val_mse: 384185.8125\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 335236.5000 - mae: 386.8940 - mse: 335236.5000 - val_loss: 383819.3125 - val_mae: 397.5012 - val_mse: 383819.3125\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "Training fold 10\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 4s 9ms/step - loss: 2669424.0000 - mae: 1181.7533 - mse: 2669424.0000 - val_loss: 1116166.6250 - val_mae: 818.5771 - val_mse: 1116166.6250\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 986568.6875 - mae: 721.4002 - mse: 986568.6875 - val_loss: 660678.4375 - val_mae: 585.9886 - val_mse: 660678.4375\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 778512.7500 - mae: 599.0379 - mse: 778512.7500 - val_loss: 588668.4375 - val_mae: 534.3670 - val_mse: 588668.4375\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 734248.6875 - mae: 568.0068 - mse: 734248.6875 - val_loss: 568828.5625 - val_mae: 519.2764 - val_mse: 568828.5625\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 709067.1875 - mae: 555.6885 - mse: 709067.1875 - val_loss: 556638.0625 - val_mae: 512.3319 - val_mse: 556638.0625\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 686793.3750 - mae: 546.2895 - mse: 686793.3750 - val_loss: 545061.8125 - val_mae: 506.0687 - val_mse: 545061.8125\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 665201.1875 - mae: 537.1942 - mse: 665201.1875 - val_loss: 533701.1250 - val_mae: 499.9442 - val_mse: 533701.1250\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 644460.1875 - mae: 528.4612 - mse: 644460.1875 - val_loss: 522573.4062 - val_mae: 493.7700 - val_mse: 522573.4062\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 624389.5000 - mae: 520.2148 - mse: 624389.5000 - val_loss: 511446.3125 - val_mae: 487.7544 - val_mse: 511446.3125\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 604889.2500 - mae: 512.2398 - mse: 604889.2500 - val_loss: 500465.5312 - val_mae: 481.7767 - val_mse: 500465.5312\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 586072.8125 - mae: 504.4452 - mse: 586072.8125 - val_loss: 489784.4688 - val_mae: 476.0156 - val_mse: 489784.4688\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 568067.6875 - mae: 497.0312 - mse: 568067.6875 - val_loss: 479595.3750 - val_mae: 470.5738 - val_mse: 479595.3750\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 551120.5625 - mae: 490.0069 - mse: 551120.5625 - val_loss: 470305.3125 - val_mae: 465.7272 - val_mse: 470305.3125\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 535590.3750 - mae: 483.5803 - mse: 535590.3750 - val_loss: 461912.1875 - val_mae: 461.4818 - val_mse: 461912.1875\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 521730.6875 - mae: 477.8871 - mse: 521730.6875 - val_loss: 454508.1875 - val_mae: 457.7017 - val_mse: 454508.1875\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 509566.5625 - mae: 472.9405 - mse: 509566.5625 - val_loss: 448195.7812 - val_mae: 454.5359 - val_mse: 448195.7812\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 499010.6250 - mae: 468.7537 - mse: 499010.6250 - val_loss: 442859.1875 - val_mae: 451.9268 - val_mse: 442859.1875\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 489929.3750 - mae: 465.1648 - mse: 489929.3750 - val_loss: 438371.4062 - val_mae: 449.7697 - val_mse: 438371.4062\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 482175.3125 - mae: 462.1885 - mse: 482175.3125 - val_loss: 434786.5000 - val_mae: 447.9292 - val_mse: 434786.5000\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 475536.5000 - mae: 459.6619 - mse: 475536.5000 - val_loss: 431836.5312 - val_mae: 446.3174 - val_mse: 431836.5312\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 469790.1250 - mae: 457.5478 - mse: 469790.1250 - val_loss: 429093.2188 - val_mae: 444.8524 - val_mse: 429093.2188\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 464754.5625 - mae: 455.8112 - mse: 464754.5625 - val_loss: 426820.5000 - val_mae: 443.7321 - val_mse: 426820.5000\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 460316.5625 - mae: 454.2761 - mse: 460316.5625 - val_loss: 424895.4688 - val_mae: 442.7646 - val_mse: 424895.4688\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 456423.5625 - mae: 452.9732 - mse: 456423.5625 - val_loss: 423394.4062 - val_mae: 441.9625 - val_mse: 423394.4062\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 452934.3438 - mae: 451.8361 - mse: 452934.3438 - val_loss: 421825.3125 - val_mae: 441.2112 - val_mse: 421825.3125\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 449737.7188 - mae: 450.7365 - mse: 449737.7188 - val_loss: 420473.1875 - val_mae: 440.5031 - val_mse: 420473.1875\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 446821.3125 - mae: 449.7384 - mse: 446821.3125 - val_loss: 419236.9375 - val_mae: 439.8718 - val_mse: 419236.9375\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 444107.3438 - mae: 448.8142 - mse: 444107.3438 - val_loss: 417897.4062 - val_mae: 439.2135 - val_mse: 417897.4062\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 441610.4375 - mae: 447.9758 - mse: 441610.4375 - val_loss: 416681.6250 - val_mae: 438.5920 - val_mse: 416681.6250\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 439195.9375 - mae: 447.1014 - mse: 439195.9375 - val_loss: 415412.3125 - val_mae: 437.9791 - val_mse: 415412.3125\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 436919.7812 - mae: 446.1954 - mse: 436919.7812 - val_loss: 414248.4688 - val_mae: 437.2388 - val_mse: 414248.4688\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 434740.0625 - mae: 445.3115 - mse: 434740.0625 - val_loss: 412950.9375 - val_mae: 436.4401 - val_mse: 412950.9375\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 432684.9062 - mae: 444.4940 - mse: 432684.9062 - val_loss: 411784.1875 - val_mae: 435.7765 - val_mse: 411784.1875\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 430746.5000 - mae: 443.7188 - mse: 430746.5000 - val_loss: 410650.6562 - val_mae: 435.2082 - val_mse: 410650.6562\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 428908.8438 - mae: 442.9508 - mse: 428908.8438 - val_loss: 409494.2500 - val_mae: 434.6521 - val_mse: 409494.2500\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 427139.6875 - mae: 442.1463 - mse: 427139.6875 - val_loss: 408410.0938 - val_mae: 434.1069 - val_mse: 408410.0938\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 425465.0000 - mae: 441.3401 - mse: 425465.0000 - val_loss: 407144.4688 - val_mae: 433.4406 - val_mse: 407144.4688\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 423836.7500 - mae: 440.5306 - mse: 423836.7500 - val_loss: 405999.8750 - val_mae: 432.7311 - val_mse: 405999.8750\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 422312.4062 - mae: 439.7452 - mse: 422312.4062 - val_loss: 404867.4375 - val_mae: 432.1199 - val_mse: 404867.4375\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 420818.9062 - mae: 438.9495 - mse: 420818.9062 - val_loss: 403914.8438 - val_mae: 431.5207 - val_mse: 403914.8438\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 419416.4688 - mae: 438.1636 - mse: 419416.4688 - val_loss: 402881.9375 - val_mae: 430.9529 - val_mse: 402881.9375\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 418035.7500 - mae: 437.3723 - mse: 418035.7500 - val_loss: 401837.1562 - val_mae: 430.3095 - val_mse: 401837.1562\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 416729.4688 - mae: 436.6105 - mse: 416729.4688 - val_loss: 400868.3125 - val_mae: 429.6801 - val_mse: 400868.3125\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 415498.7188 - mae: 435.8486 - mse: 415498.7188 - val_loss: 400005.4375 - val_mae: 429.1152 - val_mse: 400005.4375\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 414321.2812 - mae: 435.0932 - mse: 414321.2812 - val_loss: 399219.4688 - val_mae: 428.5812 - val_mse: 399219.4688\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 413142.8438 - mae: 434.3416 - mse: 413142.8438 - val_loss: 398344.9062 - val_mae: 428.0481 - val_mse: 398344.9062\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 412035.2500 - mae: 433.6057 - mse: 412035.2500 - val_loss: 397496.2500 - val_mae: 427.4790 - val_mse: 397496.2500\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 410946.7500 - mae: 432.9010 - mse: 410946.7500 - val_loss: 396566.8750 - val_mae: 426.9302 - val_mse: 396566.8750\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 409896.0938 - mae: 432.1795 - mse: 409896.0938 - val_loss: 395796.7812 - val_mae: 426.3553 - val_mse: 395796.7812\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 408918.6250 - mae: 431.5605 - mse: 408918.6250 - val_loss: 395005.9062 - val_mae: 425.8000 - val_mse: 395005.9062\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 407968.6875 - mae: 430.9277 - mse: 407968.6875 - val_loss: 394416.3125 - val_mae: 425.3427 - val_mse: 394416.3125\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 407029.9688 - mae: 430.3091 - mse: 407029.9688 - val_loss: 393665.7812 - val_mae: 424.8223 - val_mse: 393665.7812\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 406120.4688 - mae: 429.6974 - mse: 406120.4688 - val_loss: 392957.4375 - val_mae: 424.2896 - val_mse: 392957.4375\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 405223.8125 - mae: 429.0877 - mse: 405223.8125 - val_loss: 392281.8125 - val_mae: 423.8032 - val_mse: 392281.8125\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 404357.0938 - mae: 428.5029 - mse: 404357.0938 - val_loss: 391673.5000 - val_mae: 423.3463 - val_mse: 391673.5000\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 1s 2ms/step - loss: 403489.0000 - mae: 427.9210 - mse: 403489.0000 - val_loss: 390996.5000 - val_mae: 422.9196 - val_mse: 390996.5000\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 402661.5625 - mae: 427.3832 - mse: 402661.5625 - val_loss: 390398.5312 - val_mae: 422.5478 - val_mse: 390398.5312\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 401834.4688 - mae: 426.8619 - mse: 401834.4688 - val_loss: 389839.3438 - val_mae: 422.1859 - val_mse: 389839.3438\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 400985.1875 - mae: 426.2868 - mse: 400985.1875 - val_loss: 389252.5312 - val_mae: 421.7823 - val_mse: 389252.5312\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 400126.9375 - mae: 425.7463 - mse: 400126.9375 - val_loss: 388690.2500 - val_mae: 421.3754 - val_mse: 388690.2500\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 399287.5312 - mae: 425.1726 - mse: 399287.5312 - val_loss: 388179.2500 - val_mae: 420.9767 - val_mse: 388179.2500\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 398466.5312 - mae: 424.6389 - mse: 398466.5312 - val_loss: 387698.0312 - val_mae: 420.5870 - val_mse: 387698.0312\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 397648.8438 - mae: 424.1144 - mse: 397648.8438 - val_loss: 387178.6875 - val_mae: 420.1826 - val_mse: 387178.6875\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 396837.3750 - mae: 423.5937 - mse: 396837.3750 - val_loss: 386673.7188 - val_mae: 419.7313 - val_mse: 386673.7188\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 396023.5312 - mae: 423.0431 - mse: 396023.5312 - val_loss: 386134.1250 - val_mae: 419.2993 - val_mse: 386134.1250\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 395186.9688 - mae: 422.5159 - mse: 395186.9688 - val_loss: 385511.5938 - val_mae: 418.8683 - val_mse: 385511.5938\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 394371.3438 - mae: 421.9832 - mse: 394371.3438 - val_loss: 384983.2188 - val_mae: 418.4468 - val_mse: 384983.2188\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 393548.8750 - mae: 421.4704 - mse: 393548.8750 - val_loss: 384487.4375 - val_mae: 418.0263 - val_mse: 384487.4375\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 392732.5625 - mae: 420.9489 - mse: 392732.5625 - val_loss: 383868.6250 - val_mae: 417.6055 - val_mse: 383868.6250\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 391914.5938 - mae: 420.4513 - mse: 391914.5938 - val_loss: 383342.9062 - val_mae: 417.1956 - val_mse: 383342.9062\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 391091.5938 - mae: 419.9368 - mse: 391091.5938 - val_loss: 382827.9375 - val_mae: 416.8118 - val_mse: 382827.9375\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 390273.9688 - mae: 419.4245 - mse: 390273.9688 - val_loss: 382321.6250 - val_mae: 416.4280 - val_mse: 382321.6250\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 389446.6250 - mae: 418.8851 - mse: 389446.6250 - val_loss: 381842.3750 - val_mae: 416.0605 - val_mse: 381842.3750\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 388638.0625 - mae: 418.4057 - mse: 388638.0625 - val_loss: 381364.3438 - val_mae: 415.7012 - val_mse: 381364.3438\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 387807.5938 - mae: 417.8817 - mse: 387807.5938 - val_loss: 380880.6875 - val_mae: 415.2968 - val_mse: 380880.6875\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 386974.1875 - mae: 417.3822 - mse: 386974.1875 - val_loss: 380310.8750 - val_mae: 414.8785 - val_mse: 380310.8750\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 386146.0938 - mae: 416.8784 - mse: 386146.0938 - val_loss: 379755.9688 - val_mae: 414.5110 - val_mse: 379755.9688\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 385308.5938 - mae: 416.3846 - mse: 385308.5938 - val_loss: 379247.0625 - val_mae: 414.1035 - val_mse: 379247.0625\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 384449.0625 - mae: 415.8658 - mse: 384449.0625 - val_loss: 378731.1250 - val_mae: 413.7517 - val_mse: 378731.1250\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 383597.7812 - mae: 415.3807 - mse: 383597.7812 - val_loss: 378221.8125 - val_mae: 413.4010 - val_mse: 378221.8125\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 382741.0000 - mae: 414.8472 - mse: 382741.0000 - val_loss: 377783.4375 - val_mae: 413.0083 - val_mse: 377783.4375\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 381907.9688 - mae: 414.3523 - mse: 381907.9688 - val_loss: 377298.8438 - val_mae: 412.6675 - val_mse: 377298.8438\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 381061.4375 - mae: 413.8215 - mse: 381061.4375 - val_loss: 376800.6562 - val_mae: 412.2906 - val_mse: 376800.6562\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 380214.8125 - mae: 413.3326 - mse: 380214.8125 - val_loss: 376278.1250 - val_mae: 411.9405 - val_mse: 376278.1250\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 379343.1250 - mae: 412.8174 - mse: 379343.1250 - val_loss: 375729.0625 - val_mae: 411.5581 - val_mse: 375729.0625\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 378489.7812 - mae: 412.3321 - mse: 378489.7812 - val_loss: 375193.8125 - val_mae: 411.1983 - val_mse: 375193.8125\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 377604.5000 - mae: 411.8010 - mse: 377604.5000 - val_loss: 374620.6250 - val_mae: 410.8145 - val_mse: 374620.6250\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 376738.5938 - mae: 411.3000 - mse: 376738.5938 - val_loss: 374093.9688 - val_mae: 410.4464 - val_mse: 374093.9688\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 375857.7188 - mae: 410.7740 - mse: 375857.7188 - val_loss: 373439.6875 - val_mae: 410.0045 - val_mse: 373439.6875\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 374958.5312 - mae: 410.2647 - mse: 374958.5312 - val_loss: 372874.1875 - val_mae: 409.5832 - val_mse: 372874.1875\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 374051.5312 - mae: 409.7138 - mse: 374051.5312 - val_loss: 372201.6562 - val_mae: 409.1349 - val_mse: 372201.6562\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 373204.6250 - mae: 409.2343 - mse: 373204.6250 - val_loss: 371618.4062 - val_mae: 408.7417 - val_mse: 371618.4062\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 372309.0625 - mae: 408.6783 - mse: 372309.0625 - val_loss: 371012.8750 - val_mae: 408.3184 - val_mse: 371012.8750\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 371421.9062 - mae: 408.1644 - mse: 371421.9062 - val_loss: 370357.5000 - val_mae: 407.8959 - val_mse: 370357.5000\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 370518.9062 - mae: 407.6093 - mse: 370518.9062 - val_loss: 369734.6562 - val_mae: 407.4638 - val_mse: 369734.6562\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 369629.8750 - mae: 407.1076 - mse: 369629.8750 - val_loss: 369164.0625 - val_mae: 407.0720 - val_mse: 369164.0625\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 368689.1250 - mae: 406.5159 - mse: 368689.1250 - val_loss: 368592.5312 - val_mae: 406.6594 - val_mse: 368592.5312\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 367815.4375 - mae: 406.0242 - mse: 367815.4375 - val_loss: 367956.3750 - val_mae: 406.2491 - val_mse: 367956.3750\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 366902.3438 - mae: 405.4572 - mse: 366902.3438 - val_loss: 367322.5625 - val_mae: 405.7838 - val_mse: 367322.5625\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 3ms/step - loss: 365999.1875 - mae: 404.9506 - mse: 365999.1875 - val_loss: 366743.0938 - val_mae: 405.3337 - val_mse: 366743.0938\n",
      "29/29 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# run training\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=21)\n",
    "for fold_i, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "    print(f\"Training fold {fold_i + 1}\")\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # create dataset\n",
    "    train_ds = construct_tf_dataset(X_train, y_train)\n",
    "    test_ds = construct_tf_dataset(X_test, y_test)\n",
    "\n",
    "    # create model\n",
    "    model = create_tf_model(train_ds)\n",
    "    # model.summary()\n",
    "    # tf.keras.utils.plot_model(model, show_shapes=True, show_trainable=True, show_dtype=True, rankdir=\"LR\")\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "    # train model\n",
    "    fit_time_start = time.time()\n",
    "    model.fit(train_ds, epochs=100, validation_data=test_ds, verbose=0)\n",
    "    fit_time_end = time.time()\n",
    "\n",
    "    # run predictions\n",
    "    score_time_start = time.time()\n",
    "    y_pred = model.predict(test_ds).reshape(-1)\n",
    "    score_time_end = time.time()\n",
    "\n",
    "    # store metrics\n",
    "    cv_results.append({\n",
    "        \"fit_time\": fit_time_end - fit_time_start,\n",
    "        \"score_time\": score_time_end - score_time_start,\n",
    "        \"r2\": r2_score(y_test, y_pred),\n",
    "        \"mse\": mean_squared_error(y_test, y_pred),\n",
    "        \"mae\": mean_absolute_error(y_test, y_pred),\n",
    "        \"mape\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"category\": \"TensorFlow\",\n",
    "        \"name\": \"DNNRegressorV1\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096538</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.392106</td>\n",
       "      <td>991462.351233</td>\n",
       "      <td>530.215342</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>Linear</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.122072</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>0.598495</td>\n",
       "      <td>686327.115890</td>\n",
       "      <td>553.312329</td>\n",
       "      <td>0.530190</td>\n",
       "      <td>Linear</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128099</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.646759</td>\n",
       "      <td>559877.950274</td>\n",
       "      <td>512.482466</td>\n",
       "      <td>1.363745</td>\n",
       "      <td>Linear</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131772</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>0.639580</td>\n",
       "      <td>623993.178728</td>\n",
       "      <td>532.505482</td>\n",
       "      <td>0.536984</td>\n",
       "      <td>Linear</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127868</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.641780</td>\n",
       "      <td>584207.024868</td>\n",
       "      <td>520.310526</td>\n",
       "      <td>0.526457</td>\n",
       "      <td>Linear</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time        r2            mse         mae      mape  \\\n",
       "0  0.096538    0.011033  0.392106  991462.351233  530.215342  0.531833   \n",
       "1  0.122072    0.016042  0.598495  686327.115890  553.312329  0.530190   \n",
       "2  0.128099    0.016167  0.646759  559877.950274  512.482466  1.363745   \n",
       "3  0.131772    0.011631  0.639580  623993.178728  532.505482  0.536984   \n",
       "4  0.127868    0.013432  0.641780  584207.024868  520.310526  0.526457   \n",
       "\n",
       "  category              name  \n",
       "0   Linear  LinearRegression  \n",
       "1   Linear  LinearRegression  \n",
       "2   Linear  LinearRegression  \n",
       "3   Linear  LinearRegression  \n",
       "4   Linear  LinearRegression  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(cv_results)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e323_row0_col0, #T_0e323_row0_col1, #T_0e323_row0_col2, #T_0e323_row1_col0, #T_0e323_row1_col1, #T_0e323_row1_col2, #T_0e323_row2_col0, #T_0e323_row2_col1, #T_0e323_row2_col2, #T_0e323_row3_col0, #T_0e323_row3_col1, #T_0e323_row3_col2, #T_0e323_row4_col0, #T_0e323_row4_col1, #T_0e323_row4_col2, #T_0e323_row5_col0, #T_0e323_row5_col1, #T_0e323_row5_col2, #T_0e323_row6_col0, #T_0e323_row6_col1, #T_0e323_row6_col2, #T_0e323_row7_col0, #T_0e323_row7_col1, #T_0e323_row7_col2, #T_0e323_row8_col0, #T_0e323_row8_col1, #T_0e323_row8_col2, #T_0e323_row9_col0, #T_0e323_row9_col1, #T_0e323_row9_col2, #T_0e323_row10_col0, #T_0e323_row10_col1, #T_0e323_row10_col2, #T_0e323_row11_col0, #T_0e323_row11_col1, #T_0e323_row11_col2, #T_0e323_row12_col0, #T_0e323_row12_col1, #T_0e323_row12_col2, #T_0e323_row13_col0, #T_0e323_row13_col1, #T_0e323_row13_col2, #T_0e323_row14_col0, #T_0e323_row14_col1, #T_0e323_row14_col2, #T_0e323_row15_col3 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e323_row0_col3, #T_0e323_row1_col3, #T_0e323_row2_col3, #T_0e323_row3_col3, #T_0e323_row4_col3, #T_0e323_row5_col3, #T_0e323_row6_col3, #T_0e323_row7_col3, #T_0e323_row8_col3, #T_0e323_row9_col3, #T_0e323_row10_col3, #T_0e323_row11_col3, #T_0e323_row12_col3, #T_0e323_row13_col3, #T_0e323_row14_col3, #T_0e323_row15_col0, #T_0e323_row15_col1, #T_0e323_row15_col2 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e323\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e323_level0_col0\" class=\"col_heading level0 col0\" >mae</th>\n",
       "      <th id=\"T_0e323_level0_col1\" class=\"col_heading level0 col1\" >mape</th>\n",
       "      <th id=\"T_0e323_level0_col2\" class=\"col_heading level0 col2\" >mse</th>\n",
       "      <th id=\"T_0e323_level0_col3\" class=\"col_heading level0 col3\" >r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >category</th>\n",
       "      <th class=\"index_name level1\" >name</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row0\" class=\"row_heading level0 row0\" >CatBoost MultiHot</th>\n",
       "      <th id=\"T_0e323_level1_row0\" class=\"row_heading level1 row0\" >CatBoostRegressor with City</th>\n",
       "      <td id=\"T_0e323_row0_col0\" class=\"data row0 col0\" >288.230900</td>\n",
       "      <td id=\"T_0e323_row0_col1\" class=\"data row0 col1\" >0.446300</td>\n",
       "      <td id=\"T_0e323_row0_col2\" class=\"data row0 col2\" >210627.641100</td>\n",
       "      <td id=\"T_0e323_row0_col3\" class=\"data row0 col3\" >0.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row1\" class=\"row_heading level0 row1\" >Ensemble</th>\n",
       "      <th id=\"T_0e323_level1_row1\" class=\"row_heading level1 row1\" >RandomForestRegressor</th>\n",
       "      <td id=\"T_0e323_row1_col0\" class=\"data row1 col0\" >273.548500</td>\n",
       "      <td id=\"T_0e323_row1_col1\" class=\"data row1 col1\" >0.432000</td>\n",
       "      <td id=\"T_0e323_row1_col2\" class=\"data row1 col2\" >229367.832200</td>\n",
       "      <td id=\"T_0e323_row1_col3\" class=\"data row1 col3\" >0.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row2\" class=\"row_heading level0 row2\" >CatBoost</th>\n",
       "      <th id=\"T_0e323_level1_row2\" class=\"row_heading level1 row2\" >CatBoostRegressor V2</th>\n",
       "      <td id=\"T_0e323_row2_col0\" class=\"data row2 col0\" >315.219600</td>\n",
       "      <td id=\"T_0e323_row2_col1\" class=\"data row2 col1\" >0.456500</td>\n",
       "      <td id=\"T_0e323_row2_col2\" class=\"data row2 col2\" >248704.850500</td>\n",
       "      <td id=\"T_0e323_row2_col3\" class=\"data row2 col3\" >0.845700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row3\" class=\"row_heading level0 row3\" >CatBoost MultiHot</th>\n",
       "      <th id=\"T_0e323_level1_row3\" class=\"row_heading level1 row3\" >CatBoostRegressor</th>\n",
       "      <td id=\"T_0e323_row3_col0\" class=\"data row3 col0\" >319.480200</td>\n",
       "      <td id=\"T_0e323_row3_col1\" class=\"data row3 col1\" >0.507100</td>\n",
       "      <td id=\"T_0e323_row3_col2\" class=\"data row3 col2\" >250509.909700</td>\n",
       "      <td id=\"T_0e323_row3_col3\" class=\"data row3 col3\" >0.844400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"2\">CatBoost</th>\n",
       "      <th id=\"T_0e323_level1_row4\" class=\"row_heading level1 row4\" >CatBoostRegressor</th>\n",
       "      <td id=\"T_0e323_row4_col0\" class=\"data row4 col0\" >333.647200</td>\n",
       "      <td id=\"T_0e323_row4_col1\" class=\"data row4 col1\" >0.536900</td>\n",
       "      <td id=\"T_0e323_row4_col2\" class=\"data row4 col2\" >264625.157100</td>\n",
       "      <td id=\"T_0e323_row4_col3\" class=\"data row4 col3\" >0.835700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level1_row5\" class=\"row_heading level1 row5\" >CatBoostRegressor V4</th>\n",
       "      <td id=\"T_0e323_row5_col0\" class=\"data row5 col0\" >343.134900</td>\n",
       "      <td id=\"T_0e323_row5_col1\" class=\"data row5 col1\" >0.489900</td>\n",
       "      <td id=\"T_0e323_row5_col2\" class=\"data row5 col2\" >296346.600700</td>\n",
       "      <td id=\"T_0e323_row5_col3\" class=\"data row5 col3\" >0.816300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row6\" class=\"row_heading level0 row6\" >Ensemble</th>\n",
       "      <th id=\"T_0e323_level1_row6\" class=\"row_heading level1 row6\" >GradientBoostingRegressor</th>\n",
       "      <td id=\"T_0e323_row6_col0\" class=\"data row6 col0\" >359.892400</td>\n",
       "      <td id=\"T_0e323_row6_col1\" class=\"data row6 col1\" >0.555500</td>\n",
       "      <td id=\"T_0e323_row6_col2\" class=\"data row6 col2\" >300612.560800</td>\n",
       "      <td id=\"T_0e323_row6_col3\" class=\"data row6 col3\" >0.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row7\" class=\"row_heading level0 row7\" >TensorFlow</th>\n",
       "      <th id=\"T_0e323_level1_row7\" class=\"row_heading level1 row7\" >DNNRegressorV1</th>\n",
       "      <td id=\"T_0e323_row7_col0\" class=\"data row7 col0\" >418.189500</td>\n",
       "      <td id=\"T_0e323_row7_col1\" class=\"data row7 col1\" >0.881700</td>\n",
       "      <td id=\"T_0e323_row7_col2\" class=\"data row7 col2\" >407731.114900</td>\n",
       "      <td id=\"T_0e323_row7_col3\" class=\"data row7 col3\" >0.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row8\" class=\"row_heading level0 row8\" >Tree</th>\n",
       "      <th id=\"T_0e323_level1_row8\" class=\"row_heading level1 row8\" >DecisionTreeRegressor</th>\n",
       "      <td id=\"T_0e323_row8_col0\" class=\"data row8 col0\" >347.023000</td>\n",
       "      <td id=\"T_0e323_row8_col1\" class=\"data row8 col1\" >0.433600</td>\n",
       "      <td id=\"T_0e323_row8_col2\" class=\"data row8 col2\" >441138.639000</td>\n",
       "      <td id=\"T_0e323_row8_col3\" class=\"data row8 col3\" >0.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row9\" class=\"row_heading level0 row9\" >CatBoost</th>\n",
       "      <th id=\"T_0e323_level1_row9\" class=\"row_heading level1 row9\" >CatBoostRegressor V3</th>\n",
       "      <td id=\"T_0e323_row9_col0\" class=\"data row9 col0\" >554.379600</td>\n",
       "      <td id=\"T_0e323_row9_col1\" class=\"data row9 col1\" >0.933200</td>\n",
       "      <td id=\"T_0e323_row9_col2\" class=\"data row9 col2\" >569044.815100</td>\n",
       "      <td id=\"T_0e323_row9_col3\" class=\"data row9 col3\" >0.647600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row10\" class=\"row_heading level0 row10\" rowspan=\"3\">Linear</th>\n",
       "      <th id=\"T_0e323_level1_row10\" class=\"row_heading level1 row10\" >BayesianRidge</th>\n",
       "      <td id=\"T_0e323_row10_col0\" class=\"data row10 col0\" >524.512800</td>\n",
       "      <td id=\"T_0e323_row10_col1\" class=\"data row10 col1\" >0.676200</td>\n",
       "      <td id=\"T_0e323_row10_col2\" class=\"data row10 col2\" >648428.746200</td>\n",
       "      <td id=\"T_0e323_row10_col3\" class=\"data row10 col3\" >0.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level1_row11\" class=\"row_heading level1 row11\" >Ridge</th>\n",
       "      <td id=\"T_0e323_row11_col0\" class=\"data row11 col0\" >538.108800</td>\n",
       "      <td id=\"T_0e323_row11_col1\" class=\"data row11 col1\" >0.700600</td>\n",
       "      <td id=\"T_0e323_row11_col2\" class=\"data row11 col2\" >654750.314400</td>\n",
       "      <td id=\"T_0e323_row11_col3\" class=\"data row11 col3\" >0.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level1_row12\" class=\"row_heading level1 row12\" >Lasso</th>\n",
       "      <td id=\"T_0e323_row12_col0\" class=\"data row12 col0\" >536.537400</td>\n",
       "      <td id=\"T_0e323_row12_col1\" class=\"data row12 col1\" >0.700900</td>\n",
       "      <td id=\"T_0e323_row12_col2\" class=\"data row12 col2\" >656024.483100</td>\n",
       "      <td id=\"T_0e323_row12_col3\" class=\"data row12 col3\" >0.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row13\" class=\"row_heading level0 row13\" >Neural Network</th>\n",
       "      <th id=\"T_0e323_level1_row13\" class=\"row_heading level1 row13\" >MLPRegressor</th>\n",
       "      <td id=\"T_0e323_row13_col0\" class=\"data row13 col0\" >579.590300</td>\n",
       "      <td id=\"T_0e323_row13_col1\" class=\"data row13 col1\" >0.800500</td>\n",
       "      <td id=\"T_0e323_row13_col2\" class=\"data row13 col2\" >693656.486800</td>\n",
       "      <td id=\"T_0e323_row13_col3\" class=\"data row13 col3\" >0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row14\" class=\"row_heading level0 row14\" >KNN</th>\n",
       "      <th id=\"T_0e323_level1_row14\" class=\"row_heading level1 row14\" >KNeighborsRegressor</th>\n",
       "      <td id=\"T_0e323_row14_col0\" class=\"data row14 col0\" >577.324600</td>\n",
       "      <td id=\"T_0e323_row14_col1\" class=\"data row14 col1\" >0.687200</td>\n",
       "      <td id=\"T_0e323_row14_col2\" class=\"data row14 col2\" >822078.955400</td>\n",
       "      <td id=\"T_0e323_row14_col3\" class=\"data row14 col3\" >0.489900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e323_level0_row15\" class=\"row_heading level0 row15\" >Linear</th>\n",
       "      <th id=\"T_0e323_level1_row15\" class=\"row_heading level1 row15\" >LinearRegression</th>\n",
       "      <td id=\"T_0e323_row15_col0\" class=\"data row15 col0\" >447097148854.320984</td>\n",
       "      <td id=\"T_0e323_row15_col1\" class=\"data row15 col1\" >172490314.360900</td>\n",
       "      <td id=\"T_0e323_row15_col2\" class=\"data row15 col2\" >3639725729064349112398249984.000000</td>\n",
       "      <td id=\"T_0e323_row15_col3\" class=\"data row15 col3\" >-2268321804492019335168.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f51b51788d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = df_scores.pivot_table(index=[\"category\", \"name\"], values=[\"r2\", \"mse\", \"mae\", \"mape\"]).round(4).sort_values(by=\"mse\", ascending=True)\n",
    "rdf.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv(\"../dataset/raw_regression_scores.csv\", index=False)\n",
    "rdf.to_csv(\"../dataset/summary_regression_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
